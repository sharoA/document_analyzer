# 🔄 任务队列存储设计补充

## 🗄️ 任务队列存储架构

### 1. 队列存储选择：Redis + MySQL双存储

```python
# src/corder_integration/storage/task_queue_storage.py
"""
任务队列存储管理器
使用Redis作为任务队列，MySQL作为持久化存储
"""

import redis
import asyncio
from typing import Dict, List, Any, Optional
from enum import Enum
from dataclasses import dataclass
from datetime import datetime

class TaskStatus(Enum):
    PENDING = "pending"      # 待执行
    RUNNING = "running"      # 执行中
    COMPLETED = "completed"  # 已完成
    FAILED = "failed"        # 失败
    BLOCKED = "blocked"      # 依赖阻塞
    RETRY = "retry"          # 重试中

@dataclass
class TaskQueueItem:
    """任务队列项"""
    task_id: str                    # 任务ID
    service_name: str              # 服务名称
    task_type: str                 # 任务类型：coding/testing/review/commit
    priority: int                  # 优先级（1-10，10最高）
    dependencies: List[str]        # 依赖的任务ID列表
    status: TaskStatus             # 任务状态
    retry_count: int              # 重试次数
    max_retries: int              # 最大重试次数
    created_at: datetime          # 创建时间
    updated_at: datetime          # 更新时间
    execution_context: Dict[str, Any]  # 执行上下文
    estimated_duration: int       # 预估执行时间（秒）
    actual_duration: Optional[int] # 实际执行时间

class TaskQueueStorage:
    """任务队列存储管理器"""
    
    def __init__(self):
        # Redis连接（队列和缓存）
        self.redis_client = redis.Redis(
            host='localhost', 
            port=6379, 
            db=0, 
            decode_responses=True
        )
        
        # MySQL连接（持久化）
        self.mysql_connection = None  # 使用项目现有的MySQL连接
        
        # 队列前缀
        self.QUEUE_PREFIX = "task_queue"
        self.PRIORITY_QUEUE_PREFIX = "priority_queue"
        self.DEPENDENCY_PREFIX = "task_dependencies"
        self.STATUS_PREFIX = "task_status"
    
    async def enqueue_task(self, task: TaskQueueItem) -> bool:
        """入队任务"""
        try:
            # 1. 保存到MySQL（持久化）
            await self._save_task_to_mysql(task)
            
            # 2. 加入Redis队列
            queue_key = f"{self.QUEUE_PREFIX}:{task.task_type}"
            priority_score = self._calculate_priority_score(task)
            
            # 使用有序集合存储，支持优先级
            self.redis_client.zadd(
                queue_key, 
                {task.task_id: priority_score}
            )
            
            # 3. 存储任务详情
            task_key = f"task:{task.task_id}"
            self.redis_client.hset(task_key, mapping=task.__dict__)
            
            # 4. 存储依赖关系
            if task.dependencies:
                dep_key = f"{self.DEPENDENCY_PREFIX}:{task.task_id}"
                self.redis_client.sadd(dep_key, *task.dependencies)
            
            # 5. 更新状态
            await self._update_task_status(task.task_id, TaskStatus.PENDING)
            
            return True
            
        except Exception as e:
            logger.error(f"任务入队失败: {e}")
            return False
    
    async def dequeue_task(self, task_type: str) -> Optional[TaskQueueItem]:
        """出队任务（按优先级）"""
        queue_key = f"{self.QUEUE_PREFIX}:{task_type}"
        
        # 获取最高优先级的任务
        task_data = self.redis_client.zrevrange(queue_key, 0, 0, withscores=True)
        
        if not task_data:
            return None
        
        task_id, priority = task_data[0]
        
        # 检查依赖是否满足
        if not await self._check_dependencies_satisfied(task_id):
            return None
        
        # 从队列中移除
        self.redis_client.zrem(queue_key, task_id)
        
        # 获取任务详情
        task_key = f"task:{task_id}"
        task_data = self.redis_client.hgetall(task_key)
        
        if task_data:
            task = TaskQueueItem(**task_data)
            await self._update_task_status(task_id, TaskStatus.RUNNING)
            return task
        
        return None
    
    async def get_executable_tasks(self, task_type: str = None) -> List[TaskQueueItem]:
        """获取可执行的任务列表"""
        executable_tasks = []
        
        # 获取所有待执行任务
        if task_type:
            queue_keys = [f"{self.QUEUE_PREFIX}:{task_type}"]
        else:
            queue_keys = [
                f"{self.QUEUE_PREFIX}:coding",
                f"{self.QUEUE_PREFIX}:testing", 
                f"{self.QUEUE_PREFIX}:review",
                f"{self.QUEUE_PREFIX}:commit"
            ]
        
        for queue_key in queue_keys:
            # 获取队列中的所有任务
            task_ids = self.redis_client.zrevrange(queue_key, 0, -1)
            
            for task_id in task_ids:
                # 检查依赖是否满足
                if await self._check_dependencies_satisfied(task_id):
                    task_key = f"task:{task_id}"
                    task_data = self.redis_client.hgetall(task_key)
                    if task_data:
                        executable_tasks.append(TaskQueueItem(**task_data))
        
        # 按优先级排序
        executable_tasks.sort(key=lambda x: x.priority, reverse=True)
        return executable_tasks
    
    async def _check_dependencies_satisfied(self, task_id: str) -> bool:
        """检查任务依赖是否满足"""
        dep_key = f"{self.DEPENDENCY_PREFIX}:{task_id}"
        dependencies = self.redis_client.smembers(dep_key)
        
        if not dependencies:
            return True
        
        # 检查所有依赖任务是否已完成
        for dep_task_id in dependencies:
            status = await self._get_task_status(dep_task_id)
            if status != TaskStatus.COMPLETED:
                return False
        
        return True
    
    def _calculate_priority_score(self, task: TaskQueueItem) -> float:
        """计算优先级分数"""
        # 基础优先级
        base_score = task.priority * 100
        
        # 时间因子（越早创建优先级越高）
        time_factor = (datetime.now() - task.created_at).total_seconds() / 3600
        
        # 依赖因子（依赖越少优先级越高）
        dependency_factor = max(0, 10 - len(task.dependencies))
        
        # 重试因子（重试次数越多优先级越低）
        retry_factor = max(0, 5 - task.retry_count)
        
        return base_score + time_factor + dependency_factor + retry_factor

# 队列管理器
class TaskQueueManager:
    """任务队列管理器"""
    
    def __init__(self):
        self.storage = TaskQueueStorage()
        self.execution_pool = {}  # 执行中的任务池
    
    async def submit_task_batch(self, tasks: List[TaskQueueItem]) -> Dict[str, bool]:
        """批量提交任务"""
        results = {}
        
        # 依赖分析和拓扑排序
        sorted_tasks = self._topological_sort(tasks)
        
        # 批量入队
        for task in sorted_tasks:
            result = await self.storage.enqueue_task(task)
            results[task.task_id] = result
        
        return results
    
    async def get_next_executable_batch(self, batch_size: int = 5) -> List[TaskQueueItem]:
        """获取下一批可执行任务"""
        executable_tasks = await self.storage.get_executable_tasks()
        
        # 返回前batch_size个任务
        return executable_tasks[:batch_size]
    
    def _topological_sort(self, tasks: List[TaskQueueItem]) -> List[TaskQueueItem]:
        """拓扑排序任务"""
        # 构建任务图
        task_map = {task.task_id: task for task in tasks}
        in_degree = {task.task_id: 0 for task in tasks}
        
        # 计算入度
        for task in tasks:
            for dep in task.dependencies:
                if dep in in_degree:
                    in_degree[task.task_id] += 1
        
        # 拓扑排序
        queue = [task_id for task_id, degree in in_degree.items() if degree == 0]
        sorted_tasks = []
        
        while queue:
            current = queue.pop(0)
            sorted_tasks.append(task_map[current])
            
            # 更新依赖任务的入度
            for task in tasks:
                if current in task.dependencies:
                    in_degree[task.task_id] -= 1
                    if in_degree[task.task_id] == 0:
                        queue.append(task.task_id)
        
        return sorted_tasks
```

### 2. 与LangGraph状态集成

```python
# 在 workflow_orchestrator.py 中集成队列
class CodingAgentState(TypedDict):
    # ... 现有状态定义 ...
    
    # 🔄 任务队列状态
    task_queue_manager: TaskQueueManager      # 任务队列管理器
    pending_tasks: List[TaskQueueItem]        # 待执行任务
    running_tasks: List[TaskQueueItem]        # 执行中任务
    completed_tasks: List[TaskQueueItem]      # 已完成任务
    failed_tasks: List[TaskQueueItem]         # 失败任务
    task_execution_log: List[Dict[str, Any]]  # 任务执行日志
```

### 3. 队列可视化监控

```python
# src/corder_integration/monitoring/task_queue_monitor.py
"""
任务队列监控面板
"""

class TaskQueueMonitor:
    """任务队列监控"""
    
    async def get_queue_status(self) -> Dict[str, Any]:
        """获取队列状态"""
        return {
            "pending_count": await self._count_pending_tasks(),
            "running_count": await self._count_running_tasks(),
            "completed_count": await self._count_completed_tasks(),
            "failed_count": await self._count_failed_tasks(),
            "queue_health": await self._check_queue_health(),
            "average_wait_time": await self._calculate_average_wait_time(),
            "throughput": await self._calculate_throughput()
        }
    
    async def get_task_timeline(self, project_name: str) -> List[Dict[str, Any]]:
        """获取任务执行时间线"""
        # 返回任务执行的时间线视图
        pass
``` 