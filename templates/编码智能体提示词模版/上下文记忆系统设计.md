# ğŸ§  ä¸Šä¸‹æ–‡è®°å¿†ç³»ç»Ÿè¯¦ç»†è®¾è®¡

## ğŸ¯ è®°å¿†ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

ä¸Šä¸‹æ–‡è®°å¿†ç³»ç»Ÿæ˜¯ç¼–ç æ™ºèƒ½ä½“çš„"å¤§è„‘"ï¼Œè´Ÿè´£å­˜å‚¨ã€æ£€ç´¢å’Œåº”ç”¨å†å²ç»éªŒã€‚

### è®°å¿†å±‚æ¬¡ç»“æ„
```
ğŸ§  è®°å¿†å±‚æ¬¡ç»“æ„:
â”œâ”€â”€ å·¥ä½œè®°å¿† (Working Memory) - å½“å‰ä»»åŠ¡ä¸Šä¸‹æ–‡
â”œâ”€â”€ çŸ­æœŸè®°å¿† (Short-term Memory) - é¡¹ç›®çº§åˆ«è®°å¿†  
â”œâ”€â”€ é•¿æœŸè®°å¿† (Long-term Memory) - è·¨é¡¹ç›®æŒä¹…åŒ–
â””â”€â”€ çŸ¥è¯†å›¾è°± (Knowledge Graph) - å…³ç³»å‹çŸ¥è¯†

ğŸ“Š è®°å¿†ç±»å‹:
â”œâ”€â”€ ä»»åŠ¡è®°å¿† (Task Memory) - ä»»åŠ¡æ‹†åˆ†ç»éªŒ
â”œâ”€â”€ ä»£ç è®°å¿† (Code Memory) - ä»£ç æ¨¡å¼å’Œæ¨¡æ¿
â”œâ”€â”€ æ¨¡å¼è®°å¿† (Pattern Memory) - æ¶æ„æ¨¡å¼
â”œâ”€â”€ é¡¹ç›®è®°å¿† (Project Memory) - é¡¹ç›®ç‰¹å®šçŸ¥è¯†
â””â”€â”€ é”™è¯¯è®°å¿† (Error Memory) - é”™è¯¯å¤„ç†ç»éªŒ
```

## ğŸ“š è®°å¿†åˆ†å±‚è®¾è®¡

### 1. å·¥ä½œè®°å¿†ï¼ˆWorking Memoryï¼‰
```python
# src/corder_integration/memory/working_memory.py
"""
å·¥ä½œè®°å¿†ï¼šå½“å‰ä»»åŠ¡æ‰§è¡Œä¸­çš„ä¸´æ—¶ä¿¡æ¯
- ç”Ÿå‘½å‘¨æœŸï¼šå•æ¬¡ä»»åŠ¡æ‰§è¡ŒæœŸé—´
- å­˜å‚¨ï¼šå†…å­˜ + Redisç¼“å­˜
- å®¹é‡ï¼šæœ‰é™å®¹é‡ï¼ˆ50ä¸ªé¡¹ç›®ï¼‰
"""

from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime

@dataclass
class WorkingMemoryItem:
    memory_id: str
    memory_type: str  # context/instruction/result/error
    content: Dict[str, Any]
    importance: float  # 0-1é‡è¦æ€§è¯„åˆ†
    timestamp: datetime
    access_count: int = 0

class WorkingMemory:
    """å·¥ä½œè®°å¿†ç®¡ç†å™¨"""
    
    def __init__(self, max_items: int = 50):
        self.max_items = max_items
        self.memory_items: Dict[str, WorkingMemoryItem] = {}
    
    async def store_context(self, context_type: str, content: Dict[str, Any]) -> str:
        """å­˜å‚¨ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        memory_id = f"{context_type}_{datetime.now().timestamp()}"
        
        # è®¡ç®—é‡è¦æ€§è¯„åˆ†
        importance = self._calculate_importance(context_type, content)
        
        item = WorkingMemoryItem(
            memory_id=memory_id,
            memory_type=context_type,
            content=content,
            importance=importance,
            timestamp=datetime.now()
        )
        
        self.memory_items[memory_id] = item
        
        # å®¹é‡ç®¡ç†
        if len(self.memory_items) > self.max_items:
            await self._evict_low_importance_items()
        
        return memory_id
    
    async def get_relevant_context(self, query: str) -> List[Dict[str, Any]]:
        """è·å–ç›¸å…³ä¸Šä¸‹æ–‡"""
        relevant_items = []
        
        for item in self.memory_items.values():
            relevance = self._calculate_relevance(query, item.content)
            if relevance > 0.3:  # ç›¸å…³åº¦é˜ˆå€¼
                relevant_items.append({
                    "content": item.content,
                    "relevance": relevance,
                    "importance": item.importance,
                    "timestamp": item.timestamp
                })
        
        # æŒ‰ç›¸å…³åº¦å’Œé‡è¦æ€§æ’åº
        relevant_items.sort(key=lambda x: x["relevance"] * x["importance"], reverse=True)
        return relevant_items[:10]  # è¿”å›å‰10ä¸ªæœ€ç›¸å…³çš„
    
    def _calculate_importance(self, context_type: str, content: Dict[str, Any]) -> float:
        """è®¡ç®—é‡è¦æ€§è¯„åˆ†"""
        base_scores = {
            "task_result": 0.8,
            "error": 0.9,
            "success_pattern": 0.7,
            "user_feedback": 0.8,
            "intermediate_result": 0.4
        }
        
        base_score = base_scores.get(context_type, 0.5)
        
        # æ ¹æ®å†…å®¹è°ƒæ•´è¯„åˆ†
        if "error" in content:
            base_score += 0.1
        if "success" in content and content["success"]:
            base_score += 0.1
        
        return min(base_score, 1.0)
```

### 2. çŸ­æœŸè®°å¿†ï¼ˆShort-term Memoryï¼‰
```python
# src/corder_integration/memory/short_term_memory.py
"""
çŸ­æœŸè®°å¿†ï¼šé¡¹ç›®æ‰§è¡ŒæœŸé—´çš„è®°å¿†
- ç”Ÿå‘½å‘¨æœŸï¼šæ•´ä¸ªé¡¹ç›®æ‰§è¡ŒæœŸé—´
- å­˜å‚¨ï¼šRedis + éƒ¨åˆ†MySQL
- å®¹é‡ï¼šæŒ‰é¡¹ç›®åˆ†åŒº
"""

import redis
import json
from typing import Dict, List, Any

class ShortTermMemory:
    """çŸ­æœŸè®°å¿†ç®¡ç†å™¨"""
    
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379, db=1)
        self.memory_prefix = "short_term_memory"
    
    async def store_project_context(self, project_id: str, context: Dict[str, Any]):
        """å­˜å‚¨é¡¹ç›®ä¸Šä¸‹æ–‡"""
        key = f"{self.memory_prefix}:project:{project_id}"
        self.redis_client.setex(key, 86400, json.dumps(context))  # 24å°æ—¶TTL
    
    async def store_task_history(self, task_id: str, task_data: Dict[str, Any]):
        """å­˜å‚¨ä»»åŠ¡å†å²"""
        key = f"{self.memory_prefix}:task:{task_id}"
        self.redis_client.setex(key, 86400, json.dumps(task_data))
        
        # æ·»åŠ åˆ°ä»»åŠ¡ç´¢å¼•
        index_key = f"{self.memory_prefix}:task_index"
        self.redis_client.sadd(index_key, task_id)
    
    async def get_similar_tasks(self, current_task: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è·å–ç›¸ä¼¼ä»»åŠ¡"""
        index_key = f"{self.memory_prefix}:task_index"
        task_ids = self.redis_client.smembers(index_key)
        
        similar_tasks = []
        for task_id in task_ids:
            task_key = f"{self.memory_prefix}:task:{task_id}"
            task_data = self.redis_client.get(task_key)
            if task_data:
                task_info = json.loads(task_data)
                similarity = self._calculate_task_similarity(current_task, task_info)
                if similarity > 0.6:
                    similar_tasks.append({
                        "task_id": task_id,
                        "task_data": task_info,
                        "similarity": similarity
                    })
        
        return sorted(similar_tasks, key=lambda x: x["similarity"], reverse=True)
```

### 3. é•¿æœŸè®°å¿†ï¼ˆLong-term Memoryï¼‰
```python
# src/corder_integration/memory/long_term_memory.py
"""
é•¿æœŸè®°å¿†ï¼šè·¨é¡¹ç›®çš„æŒä¹…åŒ–è®°å¿†
- ç”Ÿå‘½å‘¨æœŸï¼šæ°¸ä¹…å­˜å‚¨
- å­˜å‚¨ï¼šMySQL + å‘é‡æ•°æ®åº“
- åŠŸèƒ½ï¼šä»£ç æ¨¡å¼ã€é¡¹ç›®æ¨¡æ¿ã€é”™è¯¯è§£å†³æ–¹æ¡ˆ
"""

from typing import Dict, List, Any
import mysql.connector
from sentence_transformers import SentenceTransformer

class LongTermMemory:
    """é•¿æœŸè®°å¿†ç®¡ç†å™¨"""
    
    def __init__(self, mysql_connection):
        self.mysql = mysql_connection
        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')
        self._init_tables()
    
    def _init_tables(self):
        """åˆå§‹åŒ–é•¿æœŸè®°å¿†è¡¨"""
        cursor = self.mysql.cursor()
        
        # ä»£ç æ¨¡å¼è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS code_patterns (
                pattern_id VARCHAR(255) PRIMARY KEY,
                pattern_type VARCHAR(100),
                description TEXT,
                code_template TEXT,
                usage_count INT DEFAULT 0,
                success_rate FLOAT DEFAULT 0.0,
                tags JSON,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # é¡¹ç›®æ¨¡æ¿è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS project_templates (
                template_id VARCHAR(255) PRIMARY KEY,
                project_type VARCHAR(100),
                tech_stack JSON,
                structure_template JSON,
                usage_count INT DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # é”™è¯¯è§£å†³æ–¹æ¡ˆè¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS error_solutions (
                solution_id VARCHAR(255) PRIMARY KEY,
                error_type VARCHAR(100),
                error_pattern TEXT,
                solution_description TEXT,
                solution_code TEXT,
                success_count INT DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        self.mysql.commit()
    
    async def store_code_pattern(self, pattern: Dict[str, Any]) -> str:
        """å­˜å‚¨ä»£ç æ¨¡å¼"""
        cursor = self.mysql.cursor()
        
        pattern_id = f"pattern_{datetime.now().timestamp()}"
        
        cursor.execute("""
            INSERT INTO code_patterns 
            (pattern_id, pattern_type, description, code_template, tags)
            VALUES (%s, %s, %s, %s, %s)
        """, (
            pattern_id,
            pattern["type"],
            pattern["description"],
            pattern["code_template"],
            json.dumps(pattern.get("tags", []))
        ))
        
        self.mysql.commit()
        return pattern_id
    
    async def retrieve_similar_patterns(self, description: str, limit: int = 5) -> List[Dict[str, Any]]:
        """æ£€ç´¢ç›¸ä¼¼ä»£ç æ¨¡å¼"""
        cursor = self.mysql.cursor()
        
        # ç®€å•çš„æ–‡æœ¬ç›¸ä¼¼åº¦æœç´¢
        cursor.execute("""
            SELECT * FROM code_patterns 
            WHERE description LIKE %s
            ORDER BY usage_count DESC, success_rate DESC
            LIMIT %s
        """, (f"%{description}%", limit))
        
        patterns = []
        for row in cursor.fetchall():
            patterns.append({
                "pattern_id": row[0],
                "pattern_type": row[1],
                "description": row[2],
                "code_template": row[3],
                "usage_count": row[4],
                "success_rate": row[5],
                "tags": json.loads(row[6] or "[]")
            })
        
        return patterns
    
    async def learn_from_success(self, pattern_id: str):
        """ä»æˆåŠŸä¸­å­¦ä¹ """
        cursor = self.mysql.cursor()
        cursor.execute("""
            UPDATE code_patterns 
            SET usage_count = usage_count + 1,
                success_rate = (success_rate * usage_count + 1.0) / (usage_count + 1)
            WHERE pattern_id = %s
        """, (pattern_id,))
        self.mysql.commit()
```

### 4. çŸ¥è¯†å›¾è°±ï¼ˆKnowledge Graphï¼‰
```python
# src/corder_integration/memory/knowledge_graph.py
"""
çŸ¥è¯†å›¾è°±ï¼šå…³ç³»å‹çŸ¥è¯†å­˜å‚¨
- å­˜å‚¨ï¼šç®€åŒ–ç‰ˆæœ¬ä½¿ç”¨MySQLï¼Œå¤æ‚ç‰ˆæœ¬ä½¿ç”¨Neo4j
- åŠŸèƒ½ï¼šæœåŠ¡å…³ç³»ã€ä¾èµ–å…³ç³»ã€æ¶æ„æ¨¡å¼
"""

class KnowledgeGraph:
    """çŸ¥è¯†å›¾è°±ç®¡ç†å™¨"""
    
    def __init__(self, mysql_connection):
        self.mysql = mysql_connection
        self._init_tables()
    
    def _init_tables(self):
        """åˆå§‹åŒ–çŸ¥è¯†å›¾è°±è¡¨"""
        cursor = self.mysql.cursor()
        
        # æœåŠ¡å…³ç³»è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS service_relationships (
                id INT AUTO_INCREMENT PRIMARY KEY,
                source_service VARCHAR(255),
                target_service VARCHAR(255),
                relationship_type VARCHAR(100),
                properties JSON,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # æ¶æ„æ¨¡å¼è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS architecture_patterns (
                pattern_id VARCHAR(255) PRIMARY KEY,
                pattern_name VARCHAR(255),
                services JSON,
                relationships JSON,
                usage_count INT DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        self.mysql.commit()
    
    async def add_service_relationship(self, source: str, target: str, 
                                     rel_type: str, properties: Dict[str, Any]):
        """æ·»åŠ æœåŠ¡å…³ç³»"""
        cursor = self.mysql.cursor()
        cursor.execute("""
            INSERT INTO service_relationships 
            (source_service, target_service, relationship_type, properties)
            VALUES (%s, %s, %s, %s)
        """, (source, target, rel_type, json.dumps(properties)))
        self.mysql.commit()
    
    async def get_service_dependencies(self, service_name: str) -> List[Dict[str, Any]]:
        """è·å–æœåŠ¡ä¾èµ–"""
        cursor = self.mysql.cursor()
        cursor.execute("""
            SELECT target_service, relationship_type, properties
            FROM service_relationships
            WHERE source_service = %s
        """, (service_name,))
        
        dependencies = []
        for row in cursor.fetchall():
            dependencies.append({
                "dependency": row[0],
                "relationship_type": row[1],
                "properties": json.loads(row[2] or "{}")
            })
        
        return dependencies
```

## ğŸ” è®°å¿†æ£€ç´¢å¼•æ“

```python
# src/corder_integration/memory/memory_retrieval_engine.py
"""
è®°å¿†æ£€ç´¢å¼•æ“ï¼šæ™ºèƒ½æ£€ç´¢ç›¸å…³è®°å¿†
"""

class MemoryRetrievalEngine:
    """è®°å¿†æ£€ç´¢å¼•æ“"""
    
    def __init__(self):
        self.working_memory = WorkingMemory()
        self.short_term_memory = ShortTermMemory()
        self.long_term_memory = LongTermMemory()
        self.knowledge_graph = KnowledgeGraph()
    
    async def retrieve_coding_context(self, task_description: str) -> Dict[str, Any]:
        """æ£€ç´¢ç¼–ç ä»»åŠ¡çš„ä¸Šä¸‹æ–‡"""
        context = {}
        
        # 1. è·å–å·¥ä½œè®°å¿†ä¸­çš„ç›¸å…³ä¸Šä¸‹æ–‡
        context["current_context"] = await self.working_memory.get_relevant_context(task_description)
        
        # 2. è·å–ç›¸ä¼¼çš„å†å²ä»»åŠ¡
        context["similar_tasks"] = await self.short_term_memory.get_similar_tasks({
            "description": task_description,
            "type": "coding"
        })
        
        # 3. è·å–ç›¸å…³çš„ä»£ç æ¨¡å¼
        context["code_patterns"] = await self.long_term_memory.retrieve_similar_patterns(
            task_description, limit=3
        )
        
        # 4. è·å–æ¶æ„å…³ç³»
        if "service" in task_description.lower():
            service_name = self._extract_service_name(task_description)
            context["dependencies"] = await self.knowledge_graph.get_service_dependencies(service_name)
        
        return context
    
    async def adaptive_retrieval(self, task_context: Dict[str, Any]) -> Dict[str, Any]:
        """è‡ªé€‚åº”æ£€ç´¢ï¼šæ ¹æ®ä»»åŠ¡ç‰¹å¾æ™ºèƒ½é€‰æ‹©è®°å¿†ç­–ç•¥"""
        task_type = task_context.get("type", "unknown")
        complexity = task_context.get("complexity", 0.5)
        
        if task_type == "coding":
            return await self._retrieve_coding_memories(task_context, complexity)
        elif task_type == "testing":
            return await self._retrieve_testing_memories(task_context, complexity)
        elif task_type == "review":
            return await self._retrieve_review_memories(task_context, complexity)
        else:
            return await self.retrieve_coding_context(str(task_context))
    
    async def _retrieve_coding_memories(self, task_context: Dict[str, Any], complexity: float):
        """æ£€ç´¢ç¼–ç ç›¸å…³è®°å¿†"""
        memories = {}
        
        # é«˜å¤æ‚åº¦ä»»åŠ¡éœ€è¦æ›´å¤šå†å²ç»éªŒ
        pattern_limit = 5 if complexity > 0.7 else 3
        
        memories["patterns"] = await self.long_term_memory.retrieve_similar_patterns(
            task_context.get("description", ""), limit=pattern_limit
        )
        
        # è·å–ç›¸å…³çš„é¡¹ç›®æ¨¡æ¿
        if "project_type" in task_context:
            memories["templates"] = await self.long_term_memory.get_project_templates(
                task_context["project_type"]
            )
        
        return memories
```

## ğŸ¯ è®°å¿†ç®¡ç†å™¨é›†æˆ

```python
# src/corder_integration/memory/memory_manager.py
"""
è®°å¿†ç®¡ç†å™¨ï¼šç»Ÿä¸€çš„è®°å¿†ç®¡ç†æ¥å£
"""

class MemoryManager:
    """ç»Ÿä¸€è®°å¿†ç®¡ç†å™¨"""
    
    def __init__(self):
        self.working_memory = WorkingMemory()
        self.short_term_memory = ShortTermMemory()
        self.long_term_memory = LongTermMemory()
        self.knowledge_graph = KnowledgeGraph()
        self.retrieval_engine = MemoryRetrievalEngine()
    
    async def store_context(self, context_type: str, content: Dict[str, Any], 
                          persistence_level: str = "working") -> str:
        """å­˜å‚¨ä¸Šä¸‹æ–‡"""
        if persistence_level == "working":
            return await self.working_memory.store_context(context_type, content)
        elif persistence_level == "short_term":
            return await self.short_term_memory.store_project_context(
                content.get("project_id", "default"), content
            )
        elif persistence_level == "long_term":
            return await self.long_term_memory.store_code_pattern(content)
        
    async def retrieve_context(self, query: str, context_type: str = "coding") -> Dict[str, Any]:
        """æ£€ç´¢ä¸Šä¸‹æ–‡"""
        if context_type == "coding":
            return await self.retrieval_engine.retrieve_coding_context(query)
        elif context_type == "adaptive":
            return await self.retrieval_engine.adaptive_retrieval({"description": query})
        else:
            return await self.retrieval_engine.retrieve_coding_context(query)
    
    async def learn_from_experience(self, experience: Dict[str, Any]):
        """ä»ç»éªŒä¸­å­¦ä¹ """
        # å­˜å‚¨æˆåŠŸçš„ä»£ç æ¨¡å¼
        if experience.get("success") and "code_pattern" in experience:
            await self.long_term_memory.store_code_pattern(experience["code_pattern"])
        
        # æ›´æ–°æ¨¡å¼æˆåŠŸç‡
        if "pattern_id" in experience:
            if experience.get("success"):
                await self.long_term_memory.learn_from_success(experience["pattern_id"])
        
        # å­˜å‚¨æœåŠ¡å…³ç³»
        if "service_relationship" in experience:
            rel = experience["service_relationship"]
            await self.knowledge_graph.add_service_relationship(
                rel["source"], rel["target"], rel["type"], rel.get("properties", {})
            )
```

## ğŸ’¡ è®°å¿†ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹

```python
# åœ¨æ™ºèƒ½ä½“ä¸­ä½¿ç”¨è®°å¿†ç³»ç»Ÿ
class CodingAgentWithMemory:
    """å¸¦è®°å¿†çš„ç¼–ç æ™ºèƒ½ä½“"""
    
    def __init__(self):
        self.memory_manager = MemoryManager()
    
    async def execute_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œä»»åŠ¡"""
        
        # 1. æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
        context = await self.memory_manager.retrieve_context(
            task["description"], 
            context_type="adaptive"
        )
        
        # 2. ä½¿ç”¨ä¸Šä¸‹æ–‡æ‰§è¡Œä»»åŠ¡
        result = await self._execute_with_context(task, context)
        
        # 3. å­˜å‚¨æ‰§è¡Œç»“æœ
        await self.memory_manager.store_context(
            "task_result", 
            {
                "task_id": task["id"],
                "result": result,
                "success": result.get("success", False)
            },
            persistence_level="working"
        )
        
        # 4. ä»ç»éªŒä¸­å­¦ä¹ 
        if result.get("success"):
            await self.memory_manager.learn_from_experience({
                "success": True,
                "task_type": task["type"],
                "code_pattern": result.get("pattern_used")
            })
        
        return result
    
    async def _execute_with_context(self, task: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨ä¸Šä¸‹æ–‡æ‰§è¡Œä»»åŠ¡"""
        # åˆ©ç”¨å†å²æ¨¡å¼å’Œç»éªŒ
        patterns = context.get("patterns", [])
        similar_tasks = context.get("similar_tasks", [])
        
        # é€‰æ‹©æœ€ä½³æ¨¡å¼
        best_pattern = self._select_best_pattern(patterns, task)
        
        # ç”Ÿæˆä»£ç 
        code = await self._generate_code_with_pattern(task, best_pattern)
        
        return {
            "code": code,
            "pattern_used": best_pattern,
            "success": True
        }
```

## ğŸ“Š è®°å¿†ç³»ç»Ÿç‰¹æ€§æ€»ç»“

### æ ¸å¿ƒç‰¹æ€§
1. **åˆ†å±‚è®°å¿†æ¶æ„** - å·¥ä½œè®°å¿†ã€çŸ­æœŸè®°å¿†ã€é•¿æœŸè®°å¿†ã€çŸ¥è¯†å›¾è°±
2. **æ™ºèƒ½æ£€ç´¢** - è¯­ä¹‰æœç´¢ã€ç›¸ä¼¼åº¦åŒ¹é…ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥
3. **è‡ªé€‚åº”å­¦ä¹ ** - ä»æˆåŠŸå’Œå¤±è´¥ä¸­å­¦ä¹ ï¼ŒåŠ¨æ€è°ƒæ•´
4. **å…³ç³»å»ºæ¨¡** - æœåŠ¡ä¾èµ–ã€æ¶æ„æ¨¡å¼çš„å›¾è°±å­˜å‚¨
5. **ä¸Šä¸‹æ–‡æ„ŸçŸ¥** - æ ¹æ®ä»»åŠ¡ç±»å‹å’Œå¤æ‚åº¦è°ƒæ•´è®°å¿†ç­–ç•¥

### æŠ€æœ¯å®ç°
- **å­˜å‚¨**: å†…å­˜ + Redis + MySQL + (å¯é€‰)å‘é‡æ•°æ®åº“
- **æ£€ç´¢**: æ–‡æœ¬åŒ¹é… + è¯­ä¹‰æœç´¢ + å›¾è°±æŸ¥è¯¢
- **å­¦ä¹ **: æˆåŠŸç‡ç»Ÿè®¡ + æ¨¡å¼æå– + å…³ç³»æ›´æ–°

è¿™ä¸ªè®°å¿†ç³»ç»Ÿå°†è®©ç¼–ç æ™ºèƒ½ä½“å…·å¤‡çœŸæ­£çš„"è®°å¿†"å’Œ"å­¦ä¹ "èƒ½åŠ›ï¼ 