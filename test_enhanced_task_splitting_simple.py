#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å¢å¼ºçš„ä»»åŠ¡æ‹†åˆ†æç¤ºè¯æ¨¡æ¿
éªŒè¯æ˜¯å¦èƒ½ç”ŸæˆåŒ…å«GitLabä»£ç ä¸‹è½½å’Œç»“æ„åˆ†æçš„ä»»åŠ¡
"""

import asyncio
import logging
import sys
import os
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('test_enhanced_task_splitting_simple.log', encoding='utf-8')
    ]
)

logger = logging.getLogger(__name__)

async def test_task_splitting_with_git():
    """æµ‹è¯•åŒ…å«GitLabä»£ç ä¸‹è½½çš„ä»»åŠ¡æ‹†åˆ†"""
    
    try:
        # è¯»å–è®¾è®¡æ–‡æ¡£
        design_doc_path = "combined_document_demo.txt"
        if not os.path.exists(design_doc_path):
            logger.error(f"è®¾è®¡æ–‡æ¡£ä¸å­˜åœ¨: {design_doc_path}")
            return False
        
        with open(design_doc_path, 'r', encoding='utf-8') as f:
            design_doc = f.read()
        
        logger.info(f"âœ… æˆåŠŸè¯»å–è®¾è®¡æ–‡æ¡£ï¼Œé•¿åº¦: {len(design_doc)} å­—ç¬¦")
        
        # æ£€æŸ¥ç«å±±å¼•æ“å®¢æˆ·ç«¯
        try:
            from src.utils.volcengine_client import get_volcengine_client
            client = get_volcengine_client()
            logger.info("âœ… ç«å±±å¼•æ“å®¢æˆ·ç«¯è¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ ç«å±±å¼•æ“å®¢æˆ·ç«¯è¿æ¥å¤±è´¥: {e}")
            return False
        
        # å¯¼å…¥ä»»åŠ¡æ‹†åˆ†èŠ‚ç‚¹å’Œæç¤ºè¯ç®¡ç†å™¨
        from src.corder_integration.langgraph.nodes.task_splitting_node import TaskSplittingPrompts
        
        # åˆå§‹åŒ–æç¤ºè¯ç®¡ç†å™¨
        prompts = TaskSplittingPrompts()
        logger.info("âœ… æç¤ºè¯ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æ¨¡æ‹Ÿæ‰§è¡Œè®¡åˆ’æ•°æ®
        execution_plan = {
            "execution_phases": [
                {"phase": "preparation", "tasks": ["ç¯å¢ƒé…ç½®", "ä»£ç ä¸‹è½½"]},
                {"phase": "development", "tasks": ["æ¥å£å¼€å‘", "æ•°æ®åº“æ“ä½œ"]},
                {"phase": "testing", "tasks": ["é›†æˆæµ‹è¯•", "éƒ¨ç½²"]}
            ]
        }
        
        services_summary = "åŒ…å«ç”¨æˆ·æœåŠ¡(zqyl-user-center-service)å’Œç¡®æƒå¼€ç«‹æœåŠ¡(crcl-open)ä¸¤ä¸ªå¾®æœåŠ¡ï¼Œéœ€è¦ä»GitLabä¸‹è½½ç°æœ‰ä»£ç ï¼Œåˆ†æé¡¹ç›®ç»“æ„ï¼Œç„¶ååœ¨ç›¸åº”ä½ç½®æ·»åŠ æ–°çš„æ¥å£åŠŸèƒ½ã€‚"
        
        # ç”Ÿæˆä»»åŠ¡æ‹†åˆ†æç¤ºè¯
        logger.info("ğŸ”§ ç”Ÿæˆä»»åŠ¡æ‹†åˆ†æç¤ºè¯...")
        task_generation_prompt = prompts.get_prompt(
            "generate_sqlite_tasks",
            execution_plan=json.dumps(execution_plan, ensure_ascii=False, indent=2),
            services_summary=services_summary
        )
        
        logger.info(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(task_generation_prompt)}")
        logger.info("ğŸ“ æç¤ºè¯é¢„è§ˆ:")
        logger.info(task_generation_prompt[:500] + "...")
        
        # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆä»»åŠ¡
        logger.info("ğŸ¤– è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆä»»åŠ¡...")
        
        response = client.chat(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä»»åŠ¡ç®¡ç†ä¸“å®¶ï¼ŒåŸºäºè®¾è®¡æ–‡æ¡£å’Œä»£ç ç»“æ„ç”Ÿæˆå…·ä½“çš„å¼€å‘ä»»åŠ¡ã€‚"},
                {"role": "user", "content": task_generation_prompt}
            ],
            temperature=0.1
        )
        
        logger.info(f"âœ… å¤§æ¨¡å‹å“åº”é•¿åº¦: {len(response)}")
        
        # å°è¯•è§£æå“åº”ä¸­çš„JSON
        try:
            # æŸ¥æ‰¾JSONå—
            import re
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response, re.DOTALL)
            if json_match:
                task_json = json_match.group(1)
            else:
                # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªJSONå¯¹è±¡
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    task_json = json_match.group(0)
                else:
                    logger.warning("âš ï¸ æ— æ³•ä»å“åº”ä¸­æå–JSON")
                    task_json = "{}"
            
            # è§£æJSON
            task_data = json.loads(task_json)
            tasks = task_data.get('tasks', [])
            
            logger.info(f"âœ… æˆåŠŸè§£æä»»åŠ¡ï¼Œå…± {len(tasks)} ä¸ªä»»åŠ¡:")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«é¢„æœŸçš„Gitç›¸å…³ä»»åŠ¡
            git_extraction_found = False
            git_clone_found = False
            code_analysis_found = False
            
            for i, task in enumerate(tasks[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ªä»»åŠ¡
                task_id = task.get('task_id', 'unknown')
                task_type = task.get('task_type', 'unknown')
                description = task.get('description', 'no description')
                
                logger.info(f"  {i+1}. {task_id} ({task_type}): {description}")
                
                # æ£€æŸ¥Gitç›¸å…³ä»»åŠ¡ç±»å‹
                if task_type == 'git_extraction':
                    git_extraction_found = True
                    logger.info("    âœ… æ‰¾åˆ°Gitåœ°å€æå–ä»»åŠ¡")
                elif task_type == 'git_clone':
                    git_clone_found = True
                    logger.info("    âœ… æ‰¾åˆ°Gitä»£ç ä¸‹è½½ä»»åŠ¡")
                elif task_type == 'code_analysis':
                    code_analysis_found = True
                    logger.info("    âœ… æ‰¾åˆ°ä»£ç ç»“æ„åˆ†æä»»åŠ¡")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«çœŸå®çš„GitLabåœ°å€
                if 'gitlab.local' in description or 'zqyl-user-center-service' in description or 'crcl-open' in description:
                    logger.info("    âœ… åŒ…å«çœŸå®çš„GitLabä»“åº“ä¿¡æ¯")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«çœŸå®çš„æ¥å£è·¯å¾„
                if '/general/multiorgManage/queryCompanyUnitList' in description or '/crcl-open-api/lsLimit/' in description:
                    logger.info("    âœ… åŒ…å«çœŸå®çš„æ¥å£è·¯å¾„")
            
            # éªŒè¯ä»»åŠ¡æµç¨‹çš„å®Œæ•´æ€§
            logger.info("\nğŸ“Š ä»»åŠ¡æµç¨‹éªŒè¯:")
            logger.info(f"  Gitåœ°å€æå–ä»»åŠ¡: {'âœ…' if git_extraction_found else 'âŒ'}")
            logger.info(f"  Gitä»£ç ä¸‹è½½ä»»åŠ¡: {'âœ…' if git_clone_found else 'âŒ'}")
            logger.info(f"  ä»£ç ç»“æ„åˆ†æä»»åŠ¡: {'âœ…' if code_analysis_found else 'âŒ'}")
            
            # æ£€æŸ¥ä»»åŠ¡æ‘˜è¦
            if 'task_summary' in task_data:
                summary = task_data['task_summary']
                logger.info(f"\nğŸ“ˆ ä»»åŠ¡æ‘˜è¦:")
                logger.info(f"  æ€»ä»»åŠ¡æ•°: {summary.get('total_tasks', 0)}")
                logger.info(f"  æŒ‰æœåŠ¡åˆ†ç±»: {summary.get('by_service', {})}")
                logger.info(f"  æŒ‰ç±»å‹åˆ†ç±»: {summary.get('by_type', {})}")
            
            if git_extraction_found and git_clone_found and code_analysis_found:
                logger.info("âœ… ä»»åŠ¡æ‹†åˆ†å¢å¼ºåŠŸèƒ½éªŒè¯æˆåŠŸï¼")
                return True
            else:
                logger.warning("âš ï¸ éƒ¨åˆ†Gitç›¸å…³ä»»åŠ¡ç¼ºå¤±")
                return False
                
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSONè§£æå¤±è´¥: {e}")
            logger.error(f"å“åº”å†…å®¹: {response[:1000]}...")
            return False
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•å¢å¼ºçš„ä»»åŠ¡æ‹†åˆ†åŠŸèƒ½ï¼ˆç®€åŒ–ç‰ˆï¼‰")
    
    success = await test_task_splitting_with_git()
    
    logger.info("\n" + "="*50)
    logger.info("æµ‹è¯•æ€»ç»“")
    logger.info("="*50)
    
    if success:
        logger.info("âœ… å¢å¼ºçš„ä»»åŠ¡æ‹†åˆ†åŠŸèƒ½æµ‹è¯•é€šè¿‡!")
        logger.info("âœ¨ ä»»åŠ¡æ‹†åˆ†ç°åœ¨èƒ½ç”ŸæˆåŒ…å«GitLabä»£ç ä¸‹è½½å’Œç»“æ„åˆ†æçš„å®Œæ•´æµç¨‹")
    else:
        logger.error("âŒ å¢å¼ºçš„ä»»åŠ¡æ‹†åˆ†åŠŸèƒ½æµ‹è¯•å¤±è´¥")

if __name__ == "__main__":
    asyncio.run(main()) 