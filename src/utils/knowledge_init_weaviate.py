#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†åº“åˆå§‹åŒ–è„šæœ¬ - Weaviate ç‰ˆæœ¬
å°† D:\knowledge_base ä¸‹çš„çŸ¥è¯†åº“å†…å®¹è½¬æ¢ä¸ºå‘é‡å¹¶å­˜å‚¨åˆ° Weaviate ä¸­
"""

import os
import re
import uuid
import json
import logging
import hashlib
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime

# æ–‡ä»¶å¤„ç†ç›¸å…³
import docx
from openpyxl import load_workbook
from PIL import Image
import pytesseract
from transformers import BlipProcessor, BlipForConditionalGeneration

# å‘é‡åŒ–å’ŒåµŒå…¥
from sentence_transformers import SentenceTransformer

# Weaviate å’Œ LangChain
import weaviate
import weaviate.classes as wvc
from weaviate.auth import AuthApiKey
from langchain_community.vectorstores import Weaviate
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document

# é¡¹ç›®é…ç½®å’Œ Redis
try:
    from ..resource.config import get_config
    from .redis_util import get_redis_manager
    from .weaviate_helper import get_weaviate_client
except ImportError:
    import sys
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    from src.resource.config import get_config
    from src.utils.redis_util import get_redis_manager
    from src.utils.weaviate_helper import get_weaviate_client

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class KnowledgeBaseInitializer:
    """çŸ¥è¯†åº“åˆå§‹åŒ–å™¨"""
    
    def __init__(self, knowledge_base_path: str = "D:\\knowledge_base"):
        """
        åˆå§‹åŒ–çŸ¥è¯†åº“å¤„ç†å™¨
        
        Args:
            knowledge_base_path: çŸ¥è¯†åº“æ ¹ç›®å½•è·¯å¾„
        """
        self.knowledge_base_path = Path(knowledge_base_path)
        self.weaviate_client = None
        self.redis_manager = None
        self.embeddings_model = None
        self.text_splitter = None
        self.blip_processor = None
        self.blip_model = None
        
        # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        self.supported_extensions = {'.docx', '.xlsx', '.java', '.xml'}
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._initialize_components()
    
    def _initialize_components(self):
        """åˆå§‹åŒ–å„ç§ç»„ä»¶"""
        try:
            # åˆå§‹åŒ– Weaviate å®¢æˆ·ç«¯
            self.weaviate_client = get_weaviate_client()
            logger.info("âœ… Weaviate å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ– Redis ç®¡ç†å™¨
            self.redis_manager = get_redis_manager()
            logger.info("âœ… Redis ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
            self.embeddings_model = SentenceTransformer('all-MiniLM-L6-v2')
            logger.info("âœ… åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨
            self.text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=50,
                length_function=len,
                separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", " ", ""]
            )
            logger.info("âœ… æ–‡æœ¬åˆ†å‰²å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–å›¾ç‰‡æè¿°æ¨¡å‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
            logger.info("âœ… ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _load_image_caption_model(self):
        """å»¶è¿ŸåŠ è½½å›¾ç‰‡æè¿°æ¨¡å‹"""
        if self.blip_processor is None:
            try:
                self.blip_processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
                self.blip_model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
                logger.info("âœ… å›¾ç‰‡æè¿°æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ å›¾ç‰‡æè¿°æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                self.blip_processor = None
                self.blip_model = None
    
    def _get_cache_key(self, file_path: str, cache_type: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        file_hash = hashlib.md5(file_path.encode()).hexdigest()
        return f"knowledge_base:{file_hash}:{cache_type}"
    
    def _get_cached_result(self, file_path: str, cache_type: str) -> Optional[Any]:
        """è·å–ç¼“å­˜ç»“æœ"""
        try:
            cache_key = self._get_cache_key(file_path, cache_type)
            return self.redis_manager.get(cache_key, use_prefix=False)
        except Exception as e:
            logger.warning(f"è·å–ç¼“å­˜å¤±è´¥ {file_path}:{cache_type} - {e}")
            return None
    
    def _set_cached_result(self, file_path: str, cache_type: str, result: Any, ttl: int = 86400):
        """è®¾ç½®ç¼“å­˜ç»“æœ"""
        try:
            cache_key = self._get_cache_key(file_path, cache_type)
            self.redis_manager.set(cache_key, result, ttl=ttl, use_prefix=False)
        except Exception as e:
            logger.warning(f"è®¾ç½®ç¼“å­˜å¤±è´¥ {file_path}:{cache_type} - {e}")
    
    def _extract_project_name(self, file_path: Path) -> str:
        """ä»æ–‡ä»¶è·¯å¾„æå–é¡¹ç›®åç§°"""
        try:
            # è·å–ç›¸å¯¹äºçŸ¥è¯†åº“æ ¹ç›®å½•çš„è·¯å¾„
            relative_path = file_path.relative_to(self.knowledge_base_path)
            parts = relative_path.parts
            
            # å¦‚æœè·¯å¾„åŒ…å«å¤šä¸ªéƒ¨åˆ†ï¼Œå°è¯•æå–é¡¹ç›®åç§°
            if len(parts) >= 2:
                # ä¾‹å¦‚: ä»£ç /é“¾æ•°åç«¯ä»£ç /zqyl-ls/... -> zqyl-ls
                for part in parts:
                    if part not in ['ä»£ç ', 'æ–‡æ¡£', 'éœ€æ±‚', 'æ•°æ®åº“', 'é“¾æ•°åç«¯ä»£ç ', 'é“¾æ•°å‰ç«¯ä»£ç ']:
                        return part
            
            # é»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ªç›®å½•ä½œä¸ºé¡¹ç›®åç§°
            return parts[0] if parts else "unknown"
            
        except Exception as e:
            logger.warning(f"æå–é¡¹ç›®åç§°å¤±è´¥ {file_path}: {e}")
            return "unknown"
    
    def _process_docx_file(self, file_path: Path) -> List[Dict[str, Any]]:
        """å¤„ç† DOCX æ–‡ä»¶"""
        results = []
        
        try:
            # æ£€æŸ¥ç¼“å­˜
            cached_result = self._get_cached_result(str(file_path), "docx_content")
            if cached_result:
                logger.info(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ DOCX å†…å®¹: {file_path.name}")
                return cached_result
            
            doc = docx.Document(file_path)
            
            # æå–æ–‡æœ¬å†…å®¹
            text_content = []
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    text_content.append(paragraph.text.strip())
            
            full_text = "\n".join(text_content)
            
            if full_text.strip():
                # åˆ†å‰²æ–‡æœ¬
                text_chunks = self.text_splitter.split_text(full_text)
                
                for i, chunk in enumerate(text_chunks):
                    results.append({
                        'content': chunk,
                        'file_path': str(file_path),
                        'file_name': file_path.name,
                        'project': self._extract_project_name(file_path),
                        'file_type': 'docx',
                        'source_type': 'text',
                        'chunk_index': i,
                        'image_path': None
                    })
            
            # å¤„ç†å›¾ç‰‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            try:
                # æå–æ–‡æ¡£ä¸­çš„å›¾ç‰‡
                for rel in doc.part.rels.values():
                    if "image" in rel.target_ref:
                        # è¿™é‡Œå¯ä»¥æ·»åŠ å›¾ç‰‡å¤„ç†é€»è¾‘
                        # ç”±äº python-docx æå–å›¾ç‰‡æ¯”è¾ƒå¤æ‚ï¼Œæš‚æ—¶è·³è¿‡
                        pass
            except Exception as e:
                logger.warning(f"å¤„ç† DOCX å›¾ç‰‡å¤±è´¥ {file_path}: {e}")
            
            # ç¼“å­˜ç»“æœ
            self._set_cached_result(str(file_path), "docx_content", results)
            logger.info(f"âœ… DOCX æ–‡ä»¶å¤„ç†å®Œæˆ: {file_path.name} ({len(results)} ä¸ªå—)")
            
        except Exception as e:
            logger.error(f"âŒ DOCX æ–‡ä»¶å¤„ç†å¤±è´¥ {file_path}: {e}")
        
        return results
    
    def _process_xlsx_file(self, file_path: Path) -> List[Dict[str, Any]]:
        """å¤„ç† XLSX æ–‡ä»¶"""
        results = []
        
        try:
            # æ£€æŸ¥ç¼“å­˜
            cached_result = self._get_cached_result(str(file_path), "xlsx_content")
            if cached_result:
                logger.info(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ XLSX å†…å®¹: {file_path.name}")
                return cached_result
            
            workbook = load_workbook(file_path, read_only=True)
            
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                
                # æå–è¡¨æ ¼å†…å®¹
                sheet_content = []
                headers = []
                
                # è·å–è¡¨å¤´
                for cell in sheet[1]:
                    if cell.value:
                        headers.append(str(cell.value))
                
                if headers:
                    sheet_content.append("è¡¨å¤´: " + " | ".join(headers))
                
                # è·å–æ•°æ®è¡Œ
                for row in sheet.iter_rows(min_row=2, values_only=True):
                    row_data = []
                    for cell_value in row:
                        if cell_value is not None:
                            row_data.append(str(cell_value))
                    
                    if row_data:
                        sheet_content.append(" | ".join(row_data))
                
                if sheet_content:
                    full_content = f"å·¥ä½œè¡¨: {sheet_name}\n" + "\n".join(sheet_content)
                    
                    # åˆ†å‰²å†…å®¹
                    text_chunks = self.text_splitter.split_text(full_content)
                    
                    for i, chunk in enumerate(text_chunks):
                        results.append({
                            'content': chunk,
                            'file_path': str(file_path),
                            'file_name': file_path.name,
                            'project': self._extract_project_name(file_path),
                            'file_type': 'xlsx',
                            'source_type': 'excel',
                            'chunk_index': i,
                            'sheet_name': sheet_name,
                            'image_path': None
                        })
            
            workbook.close()
            
            # ç¼“å­˜ç»“æœ
            self._set_cached_result(str(file_path), "xlsx_content", results)
            logger.info(f"âœ… XLSX æ–‡ä»¶å¤„ç†å®Œæˆ: {file_path.name} ({len(results)} ä¸ªå—)")
            
        except Exception as e:
            logger.error(f"âŒ XLSX æ–‡ä»¶å¤„ç†å¤±è´¥ {file_path}: {e}")
        
        return results
    
    def _process_java_file(self, file_path: Path) -> List[Dict[str, Any]]:
        """å¤„ç† Java æ–‡ä»¶"""
        results = []
        
        try:
            # æ£€æŸ¥ç¼“å­˜
            cached_result = self._get_cached_result(str(file_path), "java_content")
            if cached_result:
                logger.info(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ Java å†…å®¹: {file_path.name}")
                return cached_result
            
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # ç®€å•çš„ Java ä»£ç åˆ†å‰²ï¼ˆæŒ‰ç±»å’Œæ–¹æ³•ï¼‰
            # è¿™é‡Œä½¿ç”¨ç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œå®é™…é¡¹ç›®ä¸­å¯ä»¥ä½¿ç”¨ tree-sitter è·å¾—æ›´å¥½çš„è§£æ
            
            # åˆ†å‰²ä¸ºç±»
            class_pattern = r'(public\s+class\s+\w+.*?(?=public\s+class|\Z))'
            classes = re.findall(class_pattern, content, re.DOTALL)
            
            if not classes:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç±»ï¼ŒæŒ‰æ–¹æ³•åˆ†å‰²
                method_pattern = r'(public\s+\w+.*?\{.*?\n\s*\})'
                methods = re.findall(method_pattern, content, re.DOTALL)
                
                if methods:
                    for i, method in enumerate(methods):
                        if len(method.strip()) > 50:  # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
                            results.append({
                                'content': method.strip(),
                                'file_path': str(file_path),
                                'file_name': file_path.name,
                                'project': self._extract_project_name(file_path),
                                'file_type': 'java',
                                'source_type': 'code_method',
                                'chunk_index': i,
                                'image_path': None
                            })
                else:
                    # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼ŒæŒ‰æ–‡æœ¬åˆ†å‰²
                    text_chunks = self.text_splitter.split_text(content)
                    for i, chunk in enumerate(text_chunks):
                        results.append({
                            'content': chunk,
                            'file_path': str(file_path),
                            'file_name': file_path.name,
                            'project': self._extract_project_name(file_path),
                            'file_type': 'java',
                            'source_type': 'code_text',
                            'chunk_index': i,
                            'image_path': None
                        })
            else:
                for i, class_content in enumerate(classes):
                    if len(class_content.strip()) > 100:  # è¿‡æ»¤å¤ªçŸ­çš„ç±»
                        results.append({
                            'content': class_content.strip(),
                            'file_path': str(file_path),
                            'file_name': file_path.name,
                            'project': self._extract_project_name(file_path),
                            'file_type': 'java',
                            'source_type': 'code_class',
                            'chunk_index': i,
                            'image_path': None
                        })
            
            # ç¼“å­˜ç»“æœ
            self._set_cached_result(str(file_path), "java_content", results)
            logger.info(f"âœ… Java æ–‡ä»¶å¤„ç†å®Œæˆ: {file_path.name} ({len(results)} ä¸ªå—)")
            
        except Exception as e:
            logger.error(f"âŒ Java æ–‡ä»¶å¤„ç†å¤±è´¥ {file_path}: {e}")
        
        return results
    
    def _process_xml_file(self, file_path: Path) -> List[Dict[str, Any]]:
        """å¤„ç† XML æ–‡ä»¶"""
        results = []
        
        try:
            # æ£€æŸ¥ç¼“å­˜
            cached_result = self._get_cached_result(str(file_path), "xml_content")
            if cached_result:
                logger.info(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ XML å†…å®¹: {file_path.name}")
                return cached_result
            
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # æŒ‰æ–‡æœ¬åˆ†å‰² XML å†…å®¹
            text_chunks = self.text_splitter.split_text(content)
            
            for i, chunk in enumerate(text_chunks):
                results.append({
                    'content': chunk,
                    'file_path': str(file_path),
                    'file_name': file_path.name,
                    'project': self._extract_project_name(file_path),
                    'file_type': 'xml',
                    'source_type': 'config',
                    'chunk_index': i,
                    'image_path': None
                })
            
            # ç¼“å­˜ç»“æœ
            self._set_cached_result(str(file_path), "xml_content", results)
            logger.info(f"âœ… XML æ–‡ä»¶å¤„ç†å®Œæˆ: {file_path.name} ({len(results)} ä¸ªå—)")
            
        except Exception as e:
            logger.error(f"âŒ XML æ–‡ä»¶å¤„ç†å¤±è´¥ {file_path}: {e}")
        
        return results
    
    def _create_weaviate_schema(self):
        """åˆ›å»º Weaviate æ¨¡å¼"""
        try:
            collection_name = "KnowledgeDocument"
            
            # æ£€æŸ¥é›†åˆæ˜¯å¦å·²å­˜åœ¨
            if self.weaviate_client.collections.exists(collection_name):
                logger.info(f"ğŸ“‹ é›†åˆ {collection_name} å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
                return collection_name
            
            # åˆ›å»ºé›†åˆ
            self.weaviate_client.collections.create(
                name=collection_name,
                vectorizer_config=wvc.config.Configure.Vectorizer.none(),
                properties=[
                    wvc.config.Property(name="content", data_type=wvc.config.DataType.TEXT),
                    wvc.config.Property(name="file_path", data_type=wvc.config.DataType.TEXT),
                    wvc.config.Property(name="file_name", data_type=wvc.config.DataType.TEXT),
                    wvc.config.Property(name="project", data_type=wvc.config.DataType.TEXT),
                    wvc.config.Property(name="file_type", data_type=wvc.config.DataType.TEXT),
                    wvc.config.Property(name="source_type", data_type=wvc.config.DataType.TEXT),
                    wvc.config.Property(name="chunk_index", data_type=wvc.config.DataType.INT),
                    wvc.config.Property(name="image_path", data_type=wvc.config.DataType.TEXT),
                    wvc.config.Property(name="created_at", data_type=wvc.config.DataType.DATE),
                    wvc.config.Property(name="file_size", data_type=wvc.config.DataType.INT)
                ]
            )
            
            logger.info(f"âœ… Weaviate é›†åˆåˆ›å»ºæˆåŠŸ: {collection_name}")
            return collection_name
            
        except Exception as e:
            logger.error(f"âŒ Weaviate é›†åˆåˆ›å»ºå¤±è´¥: {e}")
            raise
    
    def _generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """ç”Ÿæˆæ–‡æœ¬åµŒå…¥"""
        try:
            embeddings = self.embeddings_model.encode(texts, convert_to_tensor=False)
            return embeddings.tolist()
        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆåµŒå…¥å¤±è´¥: {e}")
            return []
    
    def _batch_insert_to_weaviate(self, documents: List[Dict[str, Any]], collection_name: str, batch_size: int = 100):
        """æ‰¹é‡æ’å…¥æ–‡æ¡£åˆ° Weaviate"""
        try:
            collection = self.weaviate_client.collections.get(collection_name)
            
            for i in range(0, len(documents), batch_size):
                batch = documents[i:i + batch_size]
                
                # ç”ŸæˆåµŒå…¥
                texts = [doc['content'] for doc in batch]
                embeddings = self._generate_embeddings(texts)
                
                if not embeddings:
                    logger.warning(f"è·³è¿‡æ‰¹æ¬¡ {i//batch_size + 1}ï¼ŒåµŒå…¥ç”Ÿæˆå¤±è´¥")
                    continue
                
                # å‡†å¤‡æ‰¹é‡æ’å…¥æ•°æ®
                batch_data = []
                for j, doc in enumerate(batch):
                    if j < len(embeddings):
                        # æ·»åŠ æ—¶é—´æˆ³å’Œæ–‡ä»¶å¤§å°
                        doc['created_at'] = datetime.now()
                        doc['file_size'] = len(doc['content'])
                        
                        batch_data.append({
                            'properties': doc,
                            'vector': embeddings[j]
                        })
                
                # æ‰¹é‡æ’å…¥
                if batch_data:
                    try:
                        with collection.batch.dynamic() as batch_client:
                            for item in batch_data:
                                batch_client.add_object(
                                    properties=item['properties'],
                                    vector=item['vector']
                                )
                        
                        logger.info(f"âœ… æ‰¹æ¬¡ {i//batch_size + 1}/{(len(documents) + batch_size - 1)//batch_size} æ’å…¥æˆåŠŸ ({len(batch_data)} ä¸ªæ–‡æ¡£)")
                        
                    except Exception as e:
                        logger.error(f"âŒ æ‰¹æ¬¡ {i//batch_size + 1} æ’å…¥å¤±è´¥: {e}")
            
            logger.info(f"ğŸ‰ æ‰€æœ‰æ–‡æ¡£æ’å…¥å®Œæˆï¼Œæ€»è®¡: {len(documents)} ä¸ªæ–‡æ¡£")
            
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡æ’å…¥å¤±è´¥: {e}")
            raise
    
    def scan_knowledge_base(self) -> List[Path]:
        """æ‰«æçŸ¥è¯†åº“ç›®å½•ï¼Œè·å–æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶"""
        files = []
        
        try:
            for file_path in self.knowledge_base_path.rglob("*"):
                if file_path.is_file() and file_path.suffix.lower() in self.supported_extensions:
                    files.append(file_path)
            
            logger.info(f"ğŸ“ æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(files)} ä¸ªæ”¯æŒçš„æ–‡ä»¶")
            
            # æŒ‰æ–‡ä»¶ç±»å‹ç»Ÿè®¡
            stats = {}
            for file_path in files:
                ext = file_path.suffix.lower()
                stats[ext] = stats.get(ext, 0) + 1
            
            for ext, count in stats.items():
                logger.info(f"   {ext}: {count} ä¸ªæ–‡ä»¶")
            
        except Exception as e:
            logger.error(f"âŒ æ‰«æçŸ¥è¯†åº“å¤±è´¥: {e}")
        
        return files
    
    def process_files(self, files: List[Path]) -> List[Dict[str, Any]]:
        """å¤„ç†æ‰€æœ‰æ–‡ä»¶"""
        all_documents = []
        
        for i, file_path in enumerate(files, 1):
            logger.info(f"ğŸ”„ å¤„ç†æ–‡ä»¶ {i}/{len(files)}: {file_path.name}")
            
            try:
                documents = []
                
                if file_path.suffix.lower() == '.docx':
                    documents = self._process_docx_file(file_path)
                elif file_path.suffix.lower() == '.xlsx':
                    documents = self._process_xlsx_file(file_path)
                elif file_path.suffix.lower() == '.java':
                    documents = self._process_java_file(file_path)
                elif file_path.suffix.lower() == '.xml':
                    documents = self._process_xml_file(file_path)
                
                all_documents.extend(documents)
                
            except Exception as e:
                logger.error(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        logger.info(f"ğŸ“Š æ–‡ä»¶å¤„ç†å®Œæˆï¼Œæ€»è®¡ç”Ÿæˆ {len(all_documents)} ä¸ªæ–‡æ¡£å—")
        return all_documents
    
    def initialize_knowledge_base(self):
        """åˆå§‹åŒ–çŸ¥è¯†åº“"""
        try:
            logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–çŸ¥è¯†åº“...")
            
            # 1. æ£€æŸ¥çŸ¥è¯†åº“ç›®å½•
            if not self.knowledge_base_path.exists():
                raise FileNotFoundError(f"çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨: {self.knowledge_base_path}")
            
            # 2. æ‰«ææ–‡ä»¶
            files = self.scan_knowledge_base()
            if not files:
                logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„æ–‡ä»¶")
                return
            
            # 3. åˆ›å»º Weaviate æ¨¡å¼
            collection_name = self._create_weaviate_schema()
            
            # 4. å¤„ç†æ–‡ä»¶
            documents = self.process_files(files)
            if not documents:
                logger.warning("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•æ–‡æ¡£")
                return
            
            # 5. æ’å…¥åˆ° Weaviate
            self._batch_insert_to_weaviate(documents, collection_name)
            
            logger.info("ğŸ‰ çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def query_knowledge_base(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """æŸ¥è¯¢çŸ¥è¯†åº“"""
        try:
            collection = self.weaviate_client.collections.get("KnowledgeDocument")
            
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_embedding = self._generate_embeddings([query])[0]
            
            # å‘é‡æœç´¢
            result = collection.query.near_vector(
                near_vector=query_embedding,
                limit=limit,
                return_metadata=['distance']
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            results = []
            for obj in result.objects:
                results.append({
                    'content': obj.properties.get('content', ''),
                    'file_name': obj.properties.get('file_name', ''),
                    'project': obj.properties.get('project', ''),
                    'file_type': obj.properties.get('file_type', ''),
                    'source_type': obj.properties.get('source_type', ''),
                    'distance': obj.metadata.distance,
                    'file_path': obj.properties.get('file_path', '')
                })
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢çŸ¥è¯†åº“å¤±è´¥: {e}")
            return []
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.weaviate_client:
            self.weaviate_client.close()
        if self.redis_manager:
            self.redis_manager.close()

def main():
    """ä¸»å‡½æ•°"""
    initializer = None
    
    try:
        # åˆ›å»ºåˆå§‹åŒ–å™¨
        initializer = KnowledgeBaseInitializer()
        
        # åˆå§‹åŒ–çŸ¥è¯†åº“
        initializer.initialize_knowledge_base()
        
        # ç¤ºä¾‹æŸ¥è¯¢
        print("\n" + "="*50)
        print("ğŸ” ç¤ºä¾‹æŸ¥è¯¢æµ‹è¯•")
        print("="*50)
        
        queries = [
            "LSä¸­çš„æ•°æ®åº“è¡¨ç»“æ„",
            "ç”¨æˆ·ç®¡ç†ç›¸å…³çš„ä»£ç ",
            "é“¾æ•°åç«¯çš„é…ç½®æ–‡ä»¶",
            "Javaç±»çš„å®šä¹‰"
        ]
        
        for query in queries:
            print(f"\næŸ¥è¯¢: {query}")
            print("-" * 30)
            
            results = initializer.query_knowledge_base(query, limit=3)
            
            if results:
                for i, result in enumerate(results, 1):
                    print(f"{i}. æ–‡ä»¶: {result['file_name']} (é¡¹ç›®: {result['project']})")
                    print(f"   ç±»å‹: {result['file_type']} | æ¥æº: {result['source_type']}")
                    print(f"   ç›¸ä¼¼åº¦: {1 - result['distance']:.3f}")
                    print(f"   å†…å®¹é¢„è§ˆ: {result['content'][:100]}...")
                    print()
            else:
                print("   æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æœ")
        
        print("ğŸ‰ ç¤ºä¾‹æŸ¥è¯¢å®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        raise
    
    finally:
        if initializer:
            initializer.close()

if __name__ == "__main__":
    main()
