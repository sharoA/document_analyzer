#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Javaä»£ç ç»“æ„åˆ†æå·¥å…·
ä½¿ç”¨javalangè¿›è¡ŒJava ASTè§£æï¼Œæ”¯æŒé¡¹ç›®ç»“æ„åˆ†æã€æ³¨è§£æå–ã€åˆ†å±‚è¯†åˆ«ç­‰åŠŸèƒ½
é’ˆå¯¹ä¼ä¸šçº§å¾®æœåŠ¡æ¶æ„ï¼ˆinterfaces â†’ application â†’ domainï¼‰ä¼˜åŒ–
"""

import os
import re
import json
import logging
from typing import Dict, List, Any, Optional, Set
from pathlib import Path
import javalang
import xml.etree.ElementTree as ET
from datetime import datetime

logger = logging.getLogger(__name__)

class JavaCodeAnalyzer:
    """Javaä»£ç ç»“æ„åˆ†æå™¨ - ä¼ä¸šçº§å¾®æœåŠ¡æ¶æ„ä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self):
        self.spring_annotations = {
            '@Controller', '@RestController', '@Service', '@Repository', 
            '@Component', '@Configuration', '@Entity', '@Table',
            '@FeignClient', '@Mapper', '@RequestMapping', '@GetMapping',
            '@PostMapping', '@PutMapping', '@DeleteMapping', '@Autowired',
            '@Value', '@ConfigurationProperties', '@Validated'
        }
        
        # ä¼˜åŒ–åˆ†å±‚æ¨¡å¼ - é’ˆå¯¹ interfaces â†’ application â†’ domain æ¶æ„
        self.layer_patterns = {
            'interfaces': ['interfaces', 'facade', 'controller', 'web', 'api', 'rest'],
            'application': ['application', 'app', 'service', 'business'],
            'domain': ['domain', 'entity', 'model', 'po', 'mapper', 'persistence'],
            'dto': ['dto', 'req', 'resp', 'request', 'response', 'vo'],
            'config': ['config', 'configuration'],
            'exception': ['exception', 'error'],
            'util': ['util', 'utils', 'helper', 'tool', 'base'],
            'feign': ['feign', 'client', 'api']
        }
        
        # ä¼˜åŒ–å‘½åæ¨¡å¼ - é’ˆå¯¹ä¼ä¸šé¡¹ç›®ç‰¹ç‚¹
        self.naming_patterns = {
            'request': r'.*Request$|.*Req$',
            'response': r'.*Response$|.*Resp$',
            'dto': r'.*DTO$|.*Dto$',
            'vo': r'.*VO$|.*Vo$',
            'po': r'.*PO$|.*Po$',
            'entity': r'.*Entity$',
            'exception': r'.*Exception$',
            'mapper': r'.*Mapper$',
            'service': r'.*Service$',
            'controller': r'.*Controller$',
            'feign': r'.*Feign$|.*FeignClient$|.*Client$'
        }
        
        # ä¼ä¸šé¡¹ç›®ç‰¹æœ‰æ¨¡å¼
        self.enterprise_patterns = {
            'crcl_package': r'com\.yljr\.crcl\.',
            'mybatis_plus': ['@TableId', '@TableField', '@TableName', 'BaseMapper'],
            'dto_patterns': ['Dto', 'DTO', 'Req', 'Resp', 'Request', 'Response', 'Po', 'PO'],
            'layer_markers': ['interfaces', 'application', 'domain']
        }
    
    def analyze_project(self, project_path: str, service_name: str = None) -> Dict[str, Any]:
        """åˆ†ææ•´ä¸ªJavaé¡¹ç›® - ä¼ä¸šçº§æ¶æ„ä¼˜åŒ–ç‰ˆæœ¬"""
        logger.info(f"ğŸ” å¼€å§‹åˆ†æä¼ä¸šçº§Javaé¡¹ç›®: {project_path}")
        
        project_path = Path(project_path)
        if not project_path.exists():
            raise FileNotFoundError(f"é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: {project_path}")
        
        analysis_result = {
            'project_path': str(project_path),
            'service_name': service_name or project_path.name,
            'analysis_time': datetime.now().isoformat(),
            'project_structure': {},
            'java_files': [],
            'xml_files': [],
            'spring_boot_detected': False,
            'mybatis_plus_detected': False,
            'enterprise_architecture': {},
            'components_detected': {},
            'layer_analysis': {},
            'naming_analysis': {},
            'dependencies': {},
            'package_analysis': {},
            'summary': {}
        }
        
        # æ‰«æé¡¹ç›®æ–‡ä»¶
        java_files = self._scan_java_files(project_path)
        xml_files = self._scan_xml_files(project_path)
        
        # åˆ†æJavaæ–‡ä»¶
        for java_file in java_files:
            try:
                file_analysis = self._analyze_java_file(java_file)
                analysis_result['java_files'].append(file_analysis)
            except Exception as e:
                logger.warning(f"âš ï¸ åˆ†æJavaæ–‡ä»¶å¤±è´¥ {java_file}: {e}")
        
        # åˆ†æXMLæ–‡ä»¶
        for xml_file in xml_files:
            try:
                xml_analysis = self._analyze_xml_file(xml_file)
                analysis_result['xml_files'].append(xml_analysis)
            except Exception as e:
                logger.warning(f"âš ï¸ åˆ†æXMLæ–‡ä»¶å¤±è´¥ {xml_file}: {e}")
        
        # ä¼ä¸šçº§é¡¹ç›®ç‰¹æœ‰åˆ†æ
        analysis_result['spring_boot_detected'] = self._detect_spring_boot(analysis_result['java_files'])
        analysis_result['mybatis_plus_detected'] = self._detect_mybatis_plus(analysis_result['java_files'])
        analysis_result['enterprise_architecture'] = self._analyze_enterprise_architecture(analysis_result['java_files'])
        analysis_result['components_detected'] = self._analyze_enterprise_components(analysis_result['java_files'])
        analysis_result['layer_analysis'] = self._analyze_enterprise_layers(analysis_result['java_files'])
        analysis_result['naming_analysis'] = self._analyze_naming_patterns(analysis_result['java_files'])
        analysis_result['package_analysis'] = self._analyze_crcl_packages(analysis_result['java_files'])
        analysis_result['dependencies'] = self._analyze_dependencies(analysis_result['java_files'])
        analysis_result['project_structure'] = self._build_project_structure(analysis_result['java_files'])
        
        # æ·»åŠ é¡¹ç›®ç›®å½•ç»“æ„åˆ†æ
        analysis_result['directory_structure'] = self._analyze_directory_structure(project_path)
        analysis_result['file_distribution'] = self._analyze_file_distribution(project_path)
        
        analysis_result['summary'] = self._generate_enterprise_summary(analysis_result)
        
        logger.info(f"âœ… ä¼ä¸šçº§é¡¹ç›®åˆ†æå®Œæˆï¼Œå…±åˆ†æ {len(java_files)} ä¸ªJavaæ–‡ä»¶")
        return analysis_result
    
    def _detect_mybatis_plus(self, java_files: List[Dict[str, Any]]) -> bool:
        """æ£€æµ‹æ˜¯å¦ä½¿ç”¨MyBatis Plus"""
        mybatis_plus_indicators = [
            '@TableId', '@TableField', '@TableName', 
            'BaseMapper', 'IService', 'ServiceImpl'
        ]
        
        for file_info in java_files:
            # æ£€æŸ¥å¯¼å…¥è¯­å¥
            for import_path in file_info.get('imports', []):
                if 'mybatisplus' in import_path.lower() or 'baomidou' in import_path.lower():
                    return True
            
            # æ£€æŸ¥æ³¨è§£
            for annotation in file_info.get('annotations_used', []):
                if any(indicator in annotation for indicator in mybatis_plus_indicators):
                    return True
            
            # æ£€æŸ¥ç±»ä¿¡æ¯
            for class_info in file_info.get('classes', []):
                for annotation in class_info.get('annotations', []):
                    if any(indicator in annotation for indicator in mybatis_plus_indicators):
                        return True
                
                # æ£€æŸ¥ç»§æ‰¿å…³ç³»
                if class_info.get('extends') and 'BaseMapper' in class_info.get('extends', ''):
                    return True
        
        return False
    
    def _analyze_enterprise_architecture(self, java_files: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æä¼ä¸šçº§æ¶æ„ç‰¹å¾"""
        architecture = {
            'architecture_type': 'enterprise_microservice',
            'layer_compliance': True,
            'package_structure': 'com.yljr.crcl.*',
            'dto_usage': 0,
            'feign_usage': 0,
            'mapper_usage': 0,
            'layer_distribution': {},
            'business_domains': set()
        }
        
        total_files = len(java_files)
        dto_count = 0
        feign_count = 0
        mapper_count = 0
        
        for file_info in java_files:
            package_name = file_info.get('package', '')
            
            # ç»Ÿè®¡DTOä½¿ç”¨
            if any(pattern in file_info.get('file_path', '') for pattern in self.enterprise_patterns['dto_patterns']):
                dto_count += 1
            
            # ç»Ÿè®¡Feignä½¿ç”¨
            if '@FeignClient' in str(file_info.get('annotations_used', [])):
                feign_count += 1
            
            # ç»Ÿè®¡Mapperä½¿ç”¨
            if '@Mapper' in str(file_info.get('annotations_used', [])):
                mapper_count += 1
            
            # æå–ä¸šåŠ¡åŸŸ
            if package_name.startswith('com.yljr.crcl.'):
                parts = package_name.split('.')
                if len(parts) >= 4:
                    business_domain = parts[3]  # com.yljr.crcl.{domain}
                    architecture['business_domains'].add(business_domain)
        
        if total_files > 0:
            architecture['dto_usage'] = round((dto_count / total_files) * 100, 1)
            architecture['feign_usage'] = round((feign_count / total_files) * 100, 1)
            architecture['mapper_usage'] = round((mapper_count / total_files) * 100, 1)
        
        architecture['business_domains'] = list(architecture['business_domains'])
        return architecture
    
    def _analyze_enterprise_components(self, java_files: List[Dict[str, Any]]) -> Dict[str, int]:
        """åˆ†æä¼ä¸šçº§ç»„ä»¶ä½¿ç”¨æƒ…å†µ"""
        components = {
            'rest_controllers': 0,
            'feign_clients': 0,
            'services': 0,
            'mappers': 0,
            'entities': 0,
            'dtos': 0,
            'pos': 0,
            'configurations': 0,
            'exceptions': 0
        }
        
        component_patterns = {
            'rest_controllers': ['@RestController', '@Controller'],
            'feign_clients': ['@FeignClient'],
            'services': ['@Service'],
            'mappers': ['@Mapper'],
            'entities': ['@Entity', '@Table'],
            'configurations': ['@Configuration'],
            'exceptions': ['Exception']
        }
        
        for file_info in java_files:
            all_annotations = file_info.get('annotations_used', [])
            file_path = file_info.get('file_path', '')
            file_name = Path(file_path).stem
            
            # æ ‡å‡†ç»„ä»¶æ£€æµ‹
            for class_info in file_info.get('classes', []):
                all_annotations.extend(class_info.get('annotations', []))
            
            for component, patterns in component_patterns.items():
                if any(pattern in str(all_annotations) for pattern in patterns):
                    components[component] += 1
            
            # DTOæ£€æµ‹
            if any(pattern in file_name for pattern in ['Dto', 'DTO', 'Req', 'Resp']):
                components['dtos'] += 1
            
            # POæ£€æµ‹
            if any(pattern in file_name for pattern in ['Po', 'PO']) or 'po' in file_path.lower():
                components['pos'] += 1
        
        return components
    
    def _analyze_enterprise_layers(self, java_files: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """åˆ†æä¼ä¸šçº§åˆ†å±‚ç»“æ„ - interfaces â†’ application â†’ domain"""
        layers = {
            'interfaces': [],
            'application': [],
            'domain': [],
            'dto': [],
            'config': [],
            'exception': [],
            'util': [],
            'feign': [],
            'unknown': []
        }
        
        for file_info in java_files:
            file_path = file_info.get('file_path', '')
            package_name = file_info.get('package', '')
            file_name = Path(file_path).stem
            
            layer_classified = False
            
            # åŸºäºåŒ…è·¯å¾„åˆ†å±‚
            for layer, patterns in self.layer_patterns.items():
                if any(pattern in package_name.lower() or pattern in file_path.lower() for pattern in patterns):
                    layers[layer].append(file_name)
                    layer_classified = True
                    break
            
            if not layer_classified:
                layers['unknown'].append(file_name)
        
        return layers
    
    def _analyze_crcl_packages(self, java_files: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æCRCLé¡¹ç›®åŒ…ç»“æ„"""
        package_analysis = {
            'total_packages': 0,
            'crcl_packages': 0,
            'business_domains': {},
            'layer_distribution': {},
            'package_depth': {},
            'naming_compliance': 0
        }
        
        packages = set()
        crcl_packages = set()
        
        for file_info in java_files:
            package_name = file_info.get('package', '')
            if package_name:
                packages.add(package_name)
                
                if package_name.startswith('com.yljr.crcl.'):
                    crcl_packages.add(package_name)
                    
                    # åˆ†æä¸šåŠ¡åŸŸ
                    parts = package_name.split('.')
                    if len(parts) >= 4:
                        domain = parts[3]  # com.yljr.crcl.{domain}
                        if domain not in package_analysis['business_domains']:
                            package_analysis['business_domains'][domain] = {
                                'package_count': 0,
                                'file_count': 0,
                                'layers': set()
                            }
                        
                        package_analysis['business_domains'][domain]['package_count'] += 1
                        package_analysis['business_domains'][domain]['file_count'] += 1
                        
                        # åˆ†æå±‚æ¬¡
                        if len(parts) >= 5:
                            layer = parts[4]  # com.yljr.crcl.{domain}.{layer}
                            package_analysis['business_domains'][domain]['layers'].add(layer)
                    
                    # åŒ…æ·±åº¦åˆ†æ
                    depth = len(parts)
                    package_analysis['package_depth'][depth] = package_analysis['package_depth'].get(depth, 0) + 1
        
        package_analysis['total_packages'] = len(packages)
        package_analysis['crcl_packages'] = len(crcl_packages)
        package_analysis['naming_compliance'] = round((len(crcl_packages) / len(packages)) * 100, 1) if packages else 0
        
        # è½¬æ¢setä¸ºlist
        for domain_info in package_analysis['business_domains'].values():
            domain_info['layers'] = list(domain_info['layers'])
        
        return package_analysis
    
    def _determine_enterprise_architecture_style(self, analysis_result: Dict[str, Any]) -> str:
        """åˆ¤æ–­ä¼ä¸šçº§æ¶æ„é£æ ¼"""
        components = analysis_result['components_detected']
        enterprise_arch = analysis_result.get('enterprise_architecture', {})
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ ‡å‡†çš„ä¼ä¸šå¾®æœåŠ¡æ¶æ„
        has_interfaces = components.get('rest_controllers', 0) > 0
        has_application = components.get('services', 0) > 0
        has_domain = components.get('mappers', 0) > 0 or components.get('entities', 0) > 0
        has_feign = components.get('feign_clients', 0) > 0
        high_dto_usage = enterprise_arch.get('dto_usage', 0) > 30
        
        if has_interfaces and has_application and has_domain:
            if has_feign and high_dto_usage:
                return 'enterprise_microservice_ddd'
            else:
                return 'enterprise_layered_architecture'
        elif has_feign and high_dto_usage:
            return 'microservice_with_feign'
        elif has_interfaces and has_application:
            return 'mvc_with_service_layer'
        else:
            return 'traditional_architecture'
    
    def _generate_enterprise_summary(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆä¼ä¸šçº§é¡¹ç›®åˆ†ææ‘˜è¦"""
        java_files_count = len(analysis_result['java_files'])
        xml_files_count = len(analysis_result['xml_files'])
        enterprise_arch = analysis_result.get('enterprise_architecture', {})
        package_analysis = analysis_result.get('package_analysis', {})
        
        return {
            'total_java_files': java_files_count,
            'total_xml_files': xml_files_count,
            'is_spring_boot': analysis_result['spring_boot_detected'],
            'is_mybatis_plus': analysis_result['mybatis_plus_detected'],
            'architecture_type': self._determine_enterprise_architecture_style(analysis_result),
            'components_summary': analysis_result['components_detected'],
            'layer_distribution': {k: len(v) for k, v in analysis_result['layer_analysis'].items()},
            'naming_pattern_distribution': {k: len(v) for k, v in analysis_result['naming_analysis'].items()},
            'business_domains': enterprise_arch.get('business_domains', []),
            'dto_usage_rate': enterprise_arch.get('dto_usage', 0),
            'package_compliance': package_analysis.get('naming_compliance', 0),
            'complexity_score': self._calculate_complexity_score(analysis_result),
            'maintainability_index': self._calculate_enterprise_maintainability_index(analysis_result)
        }
    
    def _calculate_enterprise_maintainability_index(self, analysis_result: Dict[str, Any]) -> float:
        """è®¡ç®—ä¼ä¸šçº§é¡¹ç›®å¯ç»´æŠ¤æ€§æŒ‡æ•°"""
        score = 0
        
        # åˆ†å±‚æ¶æ„åˆ†æ•° (40åˆ†)
        layers = analysis_result['layer_analysis']
        if layers.get('interfaces') and layers.get('application') and layers.get('domain'):
            score += 40
        elif layers.get('interfaces') and layers.get('application'):
            score += 25
        
        # åŒ…å‘½åè§„èŒƒåˆ†æ•° (25åˆ†)
        package_analysis = analysis_result.get('package_analysis', {})
        compliance = package_analysis.get('naming_compliance', 0)
        score += (compliance / 100) * 25
        
        # DTOä½¿ç”¨è§„èŒƒåˆ†æ•° (20åˆ†)
        enterprise_arch = analysis_result.get('enterprise_architecture', {})
        dto_usage = enterprise_arch.get('dto_usage', 0)
        if dto_usage >= 50:
            score += 20
        elif dto_usage >= 30:
            score += 15
        elif dto_usage >= 10:
            score += 10
        
        # æŠ€æœ¯æ ˆç°ä»£åŒ–åˆ†æ•° (15åˆ†)
        if analysis_result.get('spring_boot_detected'):
            score += 8
        if analysis_result.get('mybatis_plus_detected'):
            score += 7
        
        return round(min(score, 100), 1)
    
    def _generate_enterprise_markdown_report(self, analysis_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¼ä¸šçº§é¡¹ç›®Markdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        service_name = analysis_result.get('service_name', 'Unknown Service')
        summary = analysis_result.get('summary', {})
        enterprise_arch = analysis_result.get('enterprise_architecture', {})
        package_analysis = analysis_result.get('package_analysis', {})
        
        report = f"""# ä¼ä¸šçº§Javaå¾®æœåŠ¡æ¶æ„åˆ†ææŠ¥å‘Š

## ğŸ¢ é¡¹ç›®æ¦‚è§ˆ
- **æœåŠ¡åç§°**: {service_name}
- **åˆ†ææ—¶é—´**: {analysis_result.get('analysis_time', 'Unknown')}
- **é¡¹ç›®è·¯å¾„**: {analysis_result.get('project_path', 'Unknown')}
- **æ¶æ„ç±»å‹**: {summary.get('architecture_type', 'Unknown')}
- **Spring Boot**: {'âœ… æ˜¯' if summary.get('is_spring_boot') else 'âŒ å¦'}
- **MyBatis Plus**: {'âœ… æ˜¯' if summary.get('is_mybatis_plus') else 'âŒ å¦'}

## ğŸ“Š ç»Ÿè®¡æ‘˜è¦
- **Javaæ–‡ä»¶æ€»æ•°**: {summary.get('total_java_files', 0)}
- **XMLé…ç½®æ–‡ä»¶**: {summary.get('total_xml_files', 0)}
- **ä¸šåŠ¡åŸŸæ•°é‡**: {len(summary.get('business_domains', []))}
- **DTOä½¿ç”¨ç‡**: {summary.get('dto_usage_rate', 0)}%
- **åŒ…å‘½åè§„èŒƒåº¦**: {summary.get('package_compliance', 0)}%
- **å¤æ‚åº¦åˆ†æ•°**: {summary.get('complexity_score', 0)}/10
- **å¯ç»´æŠ¤æ€§æŒ‡æ•°**: {summary.get('maintainability_index', 0)}/100

## ğŸ—ï¸ ä¼ä¸šçº§æ¶æ„ç‰¹å¾

### åˆ†å±‚æ¶æ„ (interfaces â†’ application â†’ domain)
"""
        
        layers = analysis_result.get('layer_analysis', {})
        for layer_name, layer_files in layers.items():
            if layer_files:
                report += f"\n### {layer_name.title()}å±‚ ({len(layer_files)}ä¸ªæ–‡ä»¶)\n"
                # æ˜¾ç¤ºå‰10ä¸ªæ–‡ä»¶
                for file in layer_files[:10]:
                    report += f"- {file}\n"
                if len(layer_files) > 10:
                    report += f"- ... è¿˜æœ‰{len(layer_files) - 10}ä¸ªæ–‡ä»¶\n"
        
        report += f"""
### ä¸šåŠ¡åŸŸåˆ†å¸ƒ
"""
        
        business_domains = package_analysis.get('business_domains', {})
        for domain, domain_info in business_domains.items():
            report += f"- **{domain}**: {domain_info['file_count']}ä¸ªæ–‡ä»¶ï¼Œå±‚æ¬¡ï¼š{', '.join(domain_info['layers'])}\n"
        
        report += f"""
## ğŸ”§ ç»„ä»¶åˆ†å¸ƒç»Ÿè®¡
"""
        
        components = analysis_result.get('components_detected', {})
        component_mapping = {
            'rest_controllers': 'RESTæ§åˆ¶å™¨',
            'feign_clients': 'Feignå®¢æˆ·ç«¯',
            'services': 'ä¸šåŠ¡æœåŠ¡',
            'mappers': 'MyBatisæ˜ å°„å™¨',
            'entities': 'JPAå®ä½“',
            'dtos': 'æ•°æ®ä¼ è¾“å¯¹è±¡',
            'pos': 'æŒä¹…åŒ–å¯¹è±¡',
            'configurations': 'é…ç½®ç±»',
            'exceptions': 'å¼‚å¸¸ç±»'
        }
        
        for component, count in components.items():
            if count > 0:
                chinese_name = component_mapping.get(component, component)
                report += f"- **{chinese_name}**: {count}ä¸ª\n"
        
        report += f"""
## ğŸ“¦ åŒ…ç»“æ„åˆ†æ

### CRCLåŒ…å‘½åè§„èŒƒ
- **æ€»åŒ…æ•°**: {package_analysis.get('total_packages', 0)}
- **CRCLåŒ…æ•°**: {package_analysis.get('crcl_packages', 0)}
- **å‘½åè§„èŒƒåº¦**: {package_analysis.get('naming_compliance', 0)}%

### åŒ…æ·±åº¦åˆ†å¸ƒ
"""
        
        for depth, count in package_analysis.get('package_depth', {}).items():
            report += f"- **{depth}å±‚åŒ…**: {count}ä¸ª\n"
        
        report += """
## ğŸ¯ å‘½åæ¨¡å¼åˆ†æ
"""
        
        patterns = analysis_result.get('naming_analysis', {})
        pattern_mapping = {
            'request': 'è¯·æ±‚å¯¹è±¡',
            'response': 'å“åº”å¯¹è±¡', 
            'dto': 'æ•°æ®ä¼ è¾“å¯¹è±¡',
            'vo': 'è§†å›¾å¯¹è±¡',
            'po': 'æŒä¹…åŒ–å¯¹è±¡',
            'entity': 'JPAå®ä½“',
            'mapper': 'MyBatisæ˜ å°„å™¨',
            'service': 'ä¸šåŠ¡æœåŠ¡',
            'controller': 'æ§åˆ¶å™¨',
            'feign': 'Feignå®¢æˆ·ç«¯'
        }
        
        for pattern, files in patterns.items():
            if files:
                chinese_name = pattern_mapping.get(pattern, pattern)
                report += f"\n### {chinese_name}æ¨¡å¼ ({len(files)}ä¸ªæ–‡ä»¶)\n"
                for file in files[:5]:
                    report += f"- {file}\n"
                if len(files) > 5:
                    report += f"- ... è¿˜æœ‰{len(files) - 5}ä¸ªæ–‡ä»¶\n"
        
        # æ·»åŠ ä¸»è¦ç±»è¯¦æƒ…
        report += "\n## ğŸ“‹ ä¸»è¦ç±»è¯¦æƒ…\n"
        displayed_files = 0
        for file_info in analysis_result.get('java_files', []):
            if displayed_files >= 20:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                break
            
            if file_info.get('classes') and file_info.get('package', '').startswith('com.yljr.crcl'):
                report += f"\n### {Path(file_info['file_path']).stem}\n"
                report += f"- **åŒ…å**: {file_info.get('package', 'N/A')}\n"
                report += f"- **å±‚çº§**: {file_info.get('layer_classification', 'unknown')}\n"
                
                annotations = file_info.get('annotations_used', [])
                if annotations:
                    report += f"- **æ³¨è§£**: {', '.join(annotations)}\n"
                
                for class_info in file_info['classes'][:2]:  # æ¯ä¸ªæ–‡ä»¶æœ€å¤šæ˜¾ç¤º2ä¸ªç±»
                    report += f"\n#### ç±»: {class_info['name']}\n"
                    if class_info.get('annotations'):
                        report += f"- **ç±»æ³¨è§£**: {', '.join(class_info['annotations'])}\n"
                    if class_info.get('extends'):
                        report += f"- **ç»§æ‰¿**: {class_info['extends']}\n"
                    if class_info.get('implements'):
                        report += f"- **å®ç°æ¥å£**: {', '.join(class_info['implements'])}\n"
                    if class_info.get('methods'):
                        report += f"- **æ–¹æ³•æ•°é‡**: {len(class_info['methods'])}\n"
                    if class_info.get('fields'):
                        report += f"- **å­—æ®µæ•°é‡**: {len(class_info['fields'])}\n"
                
                displayed_files += 1
        
        report += "\n## ğŸ’¡ æ¶æ„åˆ†æå»ºè®®\n"
        report += self._generate_enterprise_recommendations(analysis_result)
        
        return report
    
    def _generate_enterprise_recommendations(self, analysis_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¼ä¸šçº§é¡¹ç›®æ”¹è¿›å»ºè®®"""
        recommendations = []
        summary = analysis_result.get('summary', {})
        enterprise_arch = analysis_result.get('enterprise_architecture', {})
        package_analysis = analysis_result.get('package_analysis', {})
        
        # æ¶æ„åˆ†æ
        maintainability = summary.get('maintainability_index', 0)
        if maintainability >= 80:
            recommendations.append("- âœ… é¡¹ç›®æ¶æ„ä¼˜ç§€ï¼Œç¬¦åˆä¼ä¸šçº§å¾®æœåŠ¡æ ‡å‡†")
        elif maintainability >= 60:
            recommendations.append("- âš ï¸ é¡¹ç›®æ¶æ„è‰¯å¥½ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–åˆ†å±‚ç»“æ„")
        else:
            recommendations.append("- âŒ å»ºè®®é‡æ„é¡¹ç›®æ¶æ„ï¼Œæé«˜åˆ†å±‚æ¸…æ™°åº¦")
        
        # åˆ†å±‚å»ºè®®
        layers = analysis_result.get('layer_analysis', {})
        if not all([layers.get('interfaces'), layers.get('application'), layers.get('domain')]):
            recommendations.append("- ğŸ—ï¸ å»ºè®®å®Œå–„ interfaces â†’ application â†’ domain ä¸‰å±‚æ¶æ„")
        
        # DTOä½¿ç”¨å»ºè®®
        dto_usage = enterprise_arch.get('dto_usage', 0)
        if dto_usage < 30:
            recommendations.append("- ğŸ“¦ å»ºè®®å¢åŠ DTOä½¿ç”¨ï¼Œæé«˜æ•°æ®ä¼ è¾“å±‚çš„å°è£…æ€§")
        elif dto_usage > 80:
            recommendations.append("- âœ… DTOä½¿ç”¨å……åˆ†ï¼Œæ•°æ®ä¼ è¾“å±‚å°è£…è‰¯å¥½")
        
        # åŒ…å‘½åå»ºè®®
        compliance = package_analysis.get('naming_compliance', 0)
        if compliance < 80:
            recommendations.append("- ğŸ“ å»ºè®®ç»Ÿä¸€åŒ…å‘½åè§„èŒƒï¼Œéµå¾ªcom.yljr.crcl.*æ ‡å‡†")
        
        # Feignä½¿ç”¨å»ºè®®
        components = analysis_result.get('components_detected', {})
        if components.get('feign_clients', 0) == 0:
            recommendations.append("- ğŸŒ å»ºè®®ä½¿ç”¨Feign Clientå®ç°æœåŠ¡é—´è°ƒç”¨")
        
        if not recommendations:
            recommendations.append("- ğŸ‰ é¡¹ç›®æ¶æ„å®Œç¾ï¼Œç¬¦åˆä¼ä¸šçº§å¾®æœåŠ¡æœ€ä½³å®è·µ")
        
        return "\n".join(recommendations)
    
    def export_analysis_report(self, analysis_result: Dict[str, Any], output_dir: str = "outputs") -> str:
        """å¯¼å‡ºä¼ä¸šçº§åˆ†ææŠ¥å‘Š"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        service_name = analysis_result.get('service_name', 'unknown_service')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_filename = f"{service_name}_java_analysis_{timestamp}.md"
        report_path = output_path / report_filename
        
        # ç”Ÿæˆä¼ä¸šçº§MarkdownæŠ¥å‘Š
        report_content = self._generate_enterprise_markdown_report(analysis_result)
        
        # æ·»åŠ é¡¹ç›®æ•´ä½“ç»“æ„åˆ†æ
        structure_overview = self.generate_project_overview_structure(analysis_result)
        
        # æ·»åŠ å±‚çº§ç»“æ„åˆ†æ
        hierarchy_content = self.generate_project_hierarchy(analysis_result)
        
        # ç»„åˆå®Œæ•´æŠ¥å‘Š
        full_report = report_content + "\n\n" + structure_overview + "\n\n" + hierarchy_content
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(full_report)
        
        logger.info(f"ğŸ“„ ä¼ä¸šçº§åˆ†ææŠ¥å‘Šå·²å¯¼å‡º: {report_path}")
        return str(report_path)
    
    def _scan_java_files(self, project_path: Path) -> List[Path]:
        """æ‰«ææ‰€æœ‰Javaæ–‡ä»¶"""
        java_files = []
        for java_file in project_path.rglob("*.java"):
            # æ’é™¤æµ‹è¯•æ–‡ä»¶å’Œæ„å»ºç›®å½•
            if not any(part in str(java_file) for part in ['target', 'build', '.git']):
                java_files.append(java_file)
        return java_files
    
    def _scan_xml_files(self, project_path: Path) -> List[Path]:
        """æ‰«æXMLé…ç½®æ–‡ä»¶"""
        xml_files = []
        for xml_file in project_path.rglob("*.xml"):
            # åªå…³æ³¨mapperå’Œé…ç½®æ–‡ä»¶
            if any(keyword in str(xml_file).lower() for keyword in ['mapper', 'mybatis', 'config']):
                xml_files.append(xml_file)
        return xml_files
    
    def _analyze_java_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªJavaæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            with open(file_path, 'r', encoding='gbk') as f:
                content = f.read()
        
        try:
            tree = javalang.parse.parse(content)
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æJavaæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return self._create_basic_file_info(file_path, content)
        
        file_info = {
            'file_path': str(file_path),
            'relative_path': str(file_path).replace(str(file_path.parents[3]), ''),
            'package': tree.package.name if tree.package else '',
            'imports': [imp.path for imp in tree.imports] if tree.imports else [],
            'classes': [],
            'interfaces': [],
            'enums': [],
            'annotations_used': set(),
            'layer_classification': self._classify_layer(file_path),
            'naming_pattern': self._detect_naming_pattern(file_path.stem)
        }
        
        # åˆ†æç±»å‹å£°æ˜
        for type_decl in tree.types:
            if isinstance(type_decl, javalang.tree.ClassDeclaration):
                class_info = self._analyze_class(type_decl)
                file_info['classes'].append(class_info)
                file_info['annotations_used'].update(class_info['annotations'])
            elif isinstance(type_decl, javalang.tree.InterfaceDeclaration):
                interface_info = self._analyze_interface(type_decl)
                file_info['interfaces'].append(interface_info)
                file_info['annotations_used'].update(interface_info['annotations'])
            elif isinstance(type_decl, javalang.tree.EnumDeclaration):
                enum_info = self._analyze_enum(type_decl)
                file_info['enums'].append(enum_info)
        
        file_info['annotations_used'] = list(file_info['annotations_used'])
        return file_info
    
    def _create_basic_file_info(self, file_path: Path, content: str) -> Dict[str, Any]:
        """åˆ›å»ºåŸºæœ¬æ–‡ä»¶ä¿¡æ¯ï¼ˆå½“ASTè§£æå¤±è´¥æ—¶ï¼‰"""
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–åŸºæœ¬ä¿¡æ¯
        package_match = re.search(r'package\s+([\w.]+);', content)
        class_matches = re.findall(r'(?:public\s+)?class\s+(\w+)', content)
        annotation_matches = re.findall(r'@(\w+)', content)
        
        return {
            'file_path': str(file_path),
            'relative_path': str(file_path).replace(str(file_path.parents[3]), ''),
            'package': package_match.group(1) if package_match else '',
            'imports': [],
            'classes': [{'name': name, 'annotations': [], 'methods': [], 'fields': []} for name in class_matches],
            'interfaces': [],
            'enums': [],
            'annotations_used': list(set(annotation_matches)),
            'layer_classification': self._classify_layer(file_path),
            'naming_pattern': self._detect_naming_pattern(file_path.stem),
            'parse_error': True
        }
    
    def _analyze_class(self, class_decl) -> Dict[str, Any]:
        """åˆ†æç±»å£°æ˜"""
        class_info = {
            'name': class_decl.name,
            'modifiers': class_decl.modifiers or [],
            'annotations': self._extract_annotations(class_decl.annotations),
            'extends': class_decl.extends.name if class_decl.extends else None,
            'implements': [impl.name for impl in class_decl.implements] if class_decl.implements else [],
            'fields': [],
            'methods': [],
            'constructors': []
        }
        
        # åˆ†æç±»æˆå‘˜
        for member in class_decl.body:
            if isinstance(member, javalang.tree.FieldDeclaration):
                for declarator in member.declarators:
                    field_info = {
                        'name': declarator.name,
                        'type': self._get_type_name(member.type),
                        'modifiers': member.modifiers or [],
                        'annotations': self._extract_annotations(member.annotations)
                    }
                    class_info['fields'].append(field_info)
            
            elif isinstance(member, javalang.tree.MethodDeclaration):
                method_info = {
                    'name': member.name,
                    'return_type': self._get_type_name(member.return_type) if member.return_type else 'void',
                    'modifiers': member.modifiers or [],
                    'annotations': self._extract_annotations(member.annotations),
                    'parameters': [
                        {
                            'name': param.name,
                            'type': self._get_type_name(param.type)
                        } for param in member.parameters
                    ] if member.parameters else []
                }
                class_info['methods'].append(method_info)
        
        return class_info
    
    def _analyze_interface(self, interface_decl) -> Dict[str, Any]:
        """åˆ†ææ¥å£å£°æ˜"""
        interface_info = {
            'name': interface_decl.name,
            'modifiers': interface_decl.modifiers or [],
            'annotations': self._extract_annotations(interface_decl.annotations),
            'extends': [ext.name for ext in interface_decl.extends] if interface_decl.extends else [],
            'methods': []
        }
        
        # åˆ†ææ¥å£æ–¹æ³•
        for member in interface_decl.body:
            if isinstance(member, javalang.tree.MethodDeclaration):
                method_info = {
                    'name': member.name,
                    'return_type': self._get_type_name(member.return_type) if member.return_type else 'void',
                    'modifiers': member.modifiers or [],
                    'annotations': self._extract_annotations(member.annotations),
                    'parameters': [
                        {
                            'name': param.name,
                            'type': self._get_type_name(param.type)
                        } for param in member.parameters
                    ] if member.parameters else []
                }
                interface_info['methods'].append(method_info)
        
        return interface_info
    
    def _analyze_enum(self, enum_decl) -> Dict[str, Any]:
        """åˆ†ææšä¸¾å£°æ˜"""
        return {
            'name': enum_decl.name,
            'modifiers': enum_decl.modifiers or [],
            'annotations': self._extract_annotations(enum_decl.annotations),
            'constants': [const.name for const in enum_decl.body.constants] if enum_decl.body and enum_decl.body.constants else []
        }
    
    def _extract_annotations(self, annotations) -> List[str]:
        """æå–æ³¨è§£ä¿¡æ¯"""
        if not annotations:
            return []
        
        result = []
        for annotation in annotations:
            if hasattr(annotation, 'name'):
                result.append(f"@{annotation.name}")
            elif hasattr(annotation, 'type') and hasattr(annotation.type, 'name'):
                result.append(f"@{annotation.type.name}")
        
        return result
    
    def _get_type_name(self, type_obj) -> str:
        """è·å–ç±»å‹åç§°"""
        if not type_obj:
            return 'unknown'
        
        if hasattr(type_obj, 'name'):
            return type_obj.name
        elif hasattr(type_obj, 'type') and hasattr(type_obj.type, 'name'):
            return type_obj.type.name
        else:
            return str(type_obj)
    
    def _classify_layer(self, file_path: Path) -> str:
        """æ ¹æ®æ–‡ä»¶è·¯å¾„å’Œåç§°åˆ†ç±»å±‚çº§"""
        path_str = str(file_path).lower()
        file_name = file_path.stem.lower()
        
        for layer, patterns in self.layer_patterns.items():
            if any(pattern in path_str or pattern in file_name for pattern in patterns):
                return layer
        
        return 'unknown'
    
    def _detect_naming_pattern(self, class_name: str) -> str:
        """æ£€æµ‹å‘½åæ¨¡å¼"""
        for pattern_name, pattern in self.naming_patterns.items():
            if re.match(pattern, class_name):
                return pattern_name
        
        return 'unknown'
    
    def _analyze_xml_file(self, xml_path: Path) -> Dict[str, Any]:
        """åˆ†æXMLé…ç½®æ–‡ä»¶"""
        try:
            tree = ET.parse(xml_path)
            root = tree.getroot()
            
            xml_info = {
                'file_path': str(xml_path),
                'type': 'unknown',
                'namespace': root.tag,
                'content': {}
            }
            
            # æ£€æµ‹MyBatis Mapperæ–‡ä»¶
            if root.tag.endswith('mapper') or 'mapper' in str(xml_path).lower():
                xml_info['type'] = 'mybatis_mapper'
                xml_info['content'] = self._analyze_mybatis_mapper(root)
            
            return xml_info
        
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æXMLæ–‡ä»¶å¤±è´¥ {xml_path}: {e}")
            return {
                'file_path': str(xml_path),
                'type': 'unknown',
                'error': str(e)
            }
    
    def _analyze_mybatis_mapper(self, root) -> Dict[str, Any]:
        """åˆ†æMyBatis Mapper XML"""
        mapper_info = {
            'namespace': root.get('namespace', ''),
            'select_statements': [],
            'insert_statements': [],
            'update_statements': [],
            'delete_statements': [],
            'result_maps': []
        }
        
        for child in root:
            if child.tag == 'select':
                mapper_info['select_statements'].append({
                    'id': child.get('id', ''),
                    'result_type': child.get('resultType', ''),
                    'parameter_type': child.get('parameterType', '')
                })
            elif child.tag == 'insert':
                mapper_info['insert_statements'].append({
                    'id': child.get('id', ''),
                    'parameter_type': child.get('parameterType', '')
                })
            elif child.tag == 'update':
                mapper_info['update_statements'].append({
                    'id': child.get('id', ''),
                    'parameter_type': child.get('parameterType', '')
                })
            elif child.tag == 'delete':
                mapper_info['delete_statements'].append({
                    'id': child.get('id', ''),
                    'parameter_type': child.get('parameterType', '')
                })
            elif child.tag == 'resultMap':
                mapper_info['result_maps'].append({
                    'id': child.get('id', ''),
                    'type': child.get('type', '')
                })
        
        return mapper_info
    
    def _detect_spring_boot(self, java_files: List[Dict[str, Any]]) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºSpring Booté¡¹ç›®"""
        spring_boot_indicators = [
            '@SpringBootApplication',
            '@EnableAutoConfiguration',
            'SpringApplication'
        ]
        
        for file_info in java_files:
            for annotation in file_info.get('annotations_used', []):
                if any(indicator in annotation for indicator in spring_boot_indicators):
                    return True
            
            for class_info in file_info.get('classes', []):
                for annotation in class_info.get('annotations', []):
                    if any(indicator in annotation for indicator in spring_boot_indicators):
                        return True
        
        return False
    
    def _analyze_naming_patterns(self, java_files: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """åˆ†æå‘½åæ¨¡å¼"""
        patterns = {
            'request': [],
            'response': [],
            'dto': [],
            'vo': [],
            'po': [],
            'entity': [],
            'exception': [],
            'mapper': [],
            'service': [],
            'controller': [],
            'feign': [],
            'unknown': []
        }
        
        for file_info in java_files:
            pattern = file_info.get('naming_pattern', 'unknown')
            file_name = Path(file_info['file_path']).stem
            
            if pattern in patterns:
                patterns[pattern].append(file_name)
            else:
                patterns['unknown'].append(file_name)
        
        return patterns
    
    def _analyze_dependencies(self, java_files: List[Dict[str, Any]]) -> Dict[str, Set[str]]:
        """åˆ†æä¾èµ–å…³ç³»"""
        dependencies = {}
        
        for file_info in java_files:
            file_name = Path(file_info['file_path']).stem
            file_deps = set()
            
            # ä»importsä¸­æå–ä¾èµ–
            for import_path in file_info.get('imports', []):
                if not import_path.startswith('java.'):  # æ’é™¤æ ‡å‡†åº“
                    file_deps.add(import_path.split('.')[-1])
            
            dependencies[file_name] = file_deps
        
        # è½¬æ¢Setä¸ºListä»¥ä¾¿JSONåºåˆ—åŒ–
        return {k: list(v) for k, v in dependencies.items()}
    
    def _build_project_structure(self, java_files: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ„å»ºé¡¹ç›®ç»“æ„æ ‘"""
        structure = {}
        package_stats = {}
        
        for file_info in java_files:
            package = file_info.get('package', '')
            file_name = Path(file_info['file_path']).stem
            
            # æ„å»ºåŒ…ç»“æ„
            if package:
                parts = package.split('.')
                current = structure
                
                for part in parts:
                    if part not in current:
                        current[part] = {}
                    current = current[part]
                
                # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
                current[file_name] = {
                    'type': 'class',
                    'layer': file_info.get('layer_classification'),
                    'pattern': file_info.get('naming_pattern'),
                    'annotations': file_info.get('annotations_used', [])
                }
                
                # ç»Ÿè®¡åŒ…ä¿¡æ¯
                if package not in package_stats:
                    package_stats[package] = {
                        'file_count': 0,
                        'classes': [],
                        'main_layer': 'unknown',
                        'annotation_count': {}
                    }
                
                package_stats[package]['file_count'] += 1
                package_stats[package]['classes'].append(file_name)
                
                # ç»Ÿè®¡ä¸»è¦å±‚çº§
                layer = file_info.get('layer_classification', 'unknown')
                if package_stats[package]['main_layer'] == 'unknown' or layer != 'unknown':
                    package_stats[package]['main_layer'] = layer
                
                # ç»Ÿè®¡æ³¨è§£ä½¿ç”¨
                for annotation in file_info.get('annotations_used', []):
                    package_stats[package]['annotation_count'][annotation] = \
                        package_stats[package]['annotation_count'].get(annotation, 0) + 1
        
        return {
            'package_tree': structure,
            'package_statistics': package_stats
        }
    
    def _calculate_complexity_score(self, analysis_result: Dict[str, Any]) -> float:
        """è®¡ç®—å¤æ‚åº¦åˆ†æ•°ï¼ˆ1-10åˆ†ï¼‰"""
        java_files_count = len(analysis_result['java_files'])
        
        # åŸºäºæ–‡ä»¶æ•°é‡å’Œç»„ä»¶æ•°é‡è®¡ç®—å¤æ‚åº¦
        base_score = min(java_files_count / 10, 5)  # æ–‡ä»¶æ•°é‡å› å­
        
        components = analysis_result['components_detected']
        component_score = sum(components.values()) / 10  # ç»„ä»¶å› å­
        
        return round(min(base_score + component_score, 10), 1)
    
    def generate_project_hierarchy(self, analysis_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆé¡¹ç›®å±‚çº§ç»“æ„æŠ¥å‘Š"""
        project_structure = analysis_result.get('project_structure', {})
        package_stats = project_structure.get('package_statistics', {})
        
        hierarchy_report = []
        hierarchy_report.append("# é¡¹ç›®å±‚çº§ç»“æ„åˆ†æ\n")
        
        # æŒ‰åŒ…åˆ†ç»„æ˜¾ç¤º
        hierarchy_report.append("## ğŸ“¦ åŒ…ç»“æ„ç»Ÿè®¡\n")
        
        # æŒ‰æ–‡ä»¶æ•°é‡æ’åºåŒ…
        sorted_packages = sorted(package_stats.items(), key=lambda x: x[1]['file_count'], reverse=True)
        
        for package_name, stats in sorted_packages[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ªæœ€å¤§çš„åŒ…
            hierarchy_report.append(f"### {package_name}")
            hierarchy_report.append(f"- **æ–‡ä»¶æ•°é‡**: {stats['file_count']}")
            hierarchy_report.append(f"- **ä¸»è¦å±‚çº§**: {stats['main_layer']}")
            
            # æ˜¾ç¤ºä¸»è¦æ³¨è§£
            if stats['annotation_count']:
                top_annotations = sorted(stats['annotation_count'].items(), 
                                       key=lambda x: x[1], reverse=True)[:3]
                annotation_list = [f"{ann}({count})" for ann, count in top_annotations]
                hierarchy_report.append(f"- **ä¸»è¦æ³¨è§£**: {', '.join(annotation_list)}")
            
            # æ˜¾ç¤ºéƒ¨åˆ†ç±»å
            class_sample = stats['classes'][:5]
            hierarchy_report.append(f"- **ç¤ºä¾‹ç±»**: {', '.join(class_sample)}")
            if len(stats['classes']) > 5:
                hierarchy_report.append(f"  (è¿˜æœ‰{len(stats['classes']) - 5}ä¸ªç±»)")
            hierarchy_report.append("")
        
        return "\n".join(hierarchy_report)

    def _analyze_directory_structure(self, project_path: Path) -> Dict[str, Any]:
        """åˆ†æé¡¹ç›®ç›®å½•ç»“æ„"""
        directory_info = {
            'total_files': 0,
            'total_directories': 0,
            'root_level_files': [],
            'root_level_directories': [],
            'deepest_level': 0,
            'level_distribution': {}
        }
        
        # è®¡ç®—ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„å±‚çº§
        def get_relative_depth(path: Path) -> int:
            """è®¡ç®—ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„æ·±åº¦"""
            try:
                relative = path.relative_to(project_path)
                return len(relative.parts) - 1  # æ–‡ä»¶æœ¬èº«ä¸ç®—å±‚çº§
            except ValueError:
                return 0
        
        # é¦–å…ˆæ‰«ææ‰€æœ‰æ–‡ä»¶ï¼Œç¡®å®šæœ€å¤§æ·±åº¦
        max_depth = 0
        for path in project_path.rglob('*'):
            if path.is_file():
                depth = get_relative_depth(path)
                max_depth = max(max_depth, depth)
        
        directory_info['deepest_level'] = max_depth
        
        # åˆå§‹åŒ–å±‚çº§åˆ†å¸ƒå­—å…¸
        for i in range(max_depth + 1):
            directory_info['level_distribution'][i] = 0
        
        # æ‰«ææ ¹ç›®å½•ç›´æ¥å†…å®¹
        try:
            for item in project_path.iterdir():
                if item.is_file():
                    directory_info['root_level_files'].append(item.name)
                elif item.is_dir():
                    directory_info['root_level_directories'].append(item.name)
        except PermissionError:
            pass
        
        # é€’å½’ç»Ÿè®¡æ‰€æœ‰æ–‡ä»¶å’Œç›®å½•
        def count_items(path: Path):
            """é€’å½’ç»Ÿè®¡æ–‡ä»¶å’Œç›®å½•æ•°é‡"""
            try:
                for item in path.iterdir():
                    if item.is_file():
                        directory_info['total_files'] += 1
                        # è®¡ç®—æ–‡ä»¶çš„å±‚çº§åˆ†å¸ƒ
                        depth = get_relative_depth(item)
                        if depth in directory_info['level_distribution']:
                            directory_info['level_distribution'][depth] += 1
                    elif item.is_dir():
                        directory_info['total_directories'] += 1
                        count_items(item)  # é€’å½’å¤„ç†å­ç›®å½•
            except PermissionError:
                pass  # å¿½ç•¥æ— æƒé™è®¿é—®çš„ç›®å½•
        
        count_items(project_path)
        
        return directory_info

    def _analyze_file_distribution(self, project_path: Path) -> Dict[str, Any]:
        """åˆ†ææ–‡ä»¶ç±»å‹åˆ†å¸ƒ"""
        file_types = {}
        total_size = 0
        file_count = 0
        
        for file_path in project_path.rglob('*'):
            if file_path.is_file():
                file_count += 1
                file_ext = file_path.suffix.lower()
                if file_ext in file_types:
                    file_types[file_ext] += 1
                else:
                    file_types[file_ext] = 1
                
                try:
                    total_size += file_path.stat().st_size
                except (OSError, PermissionError):
                    pass  # å¿½ç•¥æ— æ³•è®¿é—®çš„æ–‡ä»¶
        
        # æŒ‰æ•°é‡æ’åº
        sorted_file_types = sorted(file_types.items(), key=lambda x: x[1], reverse=True)
        
        return {
            'total_files': file_count,
            'top_file_types': sorted_file_types[:10],
            'total_size_bytes': total_size,
            'average_file_size_bytes': total_size / file_count if file_count > 0 else 0,
            'file_extension_distribution': file_types
        }

    def generate_directory_tree(self, project_path: Path, max_depth: int = 4, exclude_patterns: List[str] = None) -> str:
        """ç”Ÿæˆé¡¹ç›®ç›®å½•æ ‘ç»“æ„"""
        if exclude_patterns is None:
            exclude_patterns = ['.git', 'target', 'build', 'node_modules', '.idea', '.vscode', '__pycache__']
        
        tree_lines = []
        tree_lines.append(f"ğŸ“ {project_path.name}/")
        
        def should_exclude(path: Path) -> bool:
            """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤è¯¥è·¯å¾„"""
            return any(pattern in str(path) for pattern in exclude_patterns)
        
        def add_tree_item(path: Path, prefix: str = "", depth: int = 0, is_last: bool = True):
            """é€’å½’æ·»åŠ ç›®å½•æ ‘é¡¹ç›®"""
            if depth > max_depth or should_exclude(path):
                return
            
            # è·å–å½“å‰å±‚çº§çš„æ‰€æœ‰é¡¹ç›®
            try:
                items = sorted([item for item in path.iterdir() if not should_exclude(item)], 
                             key=lambda x: (x.is_file(), x.name.lower()))
            except PermissionError:
                return
            
            for i, item in enumerate(items):
                is_last_item = (i == len(items) - 1)
                
                # è®¾ç½®æ ‘å½¢ç»“æ„çš„è¿æ¥ç¬¦
                if depth == 0:
                    current_prefix = ""
                    next_prefix = ""
                else:
                    current_prefix = prefix + ("â””â”€â”€ " if is_last_item else "â”œâ”€â”€ ")
                    next_prefix = prefix + ("    " if is_last_item else "â”‚   ")
                
                # æ·»åŠ å½“å‰é¡¹ç›®
                if item.is_dir():
                    # ç»Ÿè®¡ç›®å½•ä¸‹çš„æ–‡ä»¶æ•°é‡
                    try:
                        file_count = len([f for f in item.rglob('*') if f.is_file() and not should_exclude(f)])
                        tree_lines.append(f"{current_prefix}ğŸ“ {item.name}/ ({file_count} files)")
                        
                        # é€’å½’å¤„ç†å­ç›®å½•
                        if depth < max_depth:
                            add_tree_item(item, next_prefix, depth + 1, is_last_item)
                    except PermissionError:
                        tree_lines.append(f"{current_prefix}ğŸ“ {item.name}/ (permission denied)")
                else:
                    # æ–‡ä»¶å¤§å°æ ¼å¼åŒ–
                    try:
                        size = item.stat().st_size
                        if size < 1024:
                            size_str = f"{size}B"
                        elif size < 1024 * 1024:
                            size_str = f"{size/1024:.1f}KB"
                        else:
                            size_str = f"{size/(1024*1024):.1f}MB"
                        
                        # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©å›¾æ ‡
                        icon = self._get_file_icon(item.suffix.lower())
                        tree_lines.append(f"{current_prefix}{icon} {item.name} ({size_str})")
                    except (PermissionError, OSError):
                        tree_lines.append(f"{current_prefix}ğŸ“„ {item.name} (unknown size)")
        
        add_tree_item(project_path, "", 0)
        return "\n".join(tree_lines)
    
    def _get_file_icon(self, file_extension: str) -> str:
        """æ ¹æ®æ–‡ä»¶æ‰©å±•åè¿”å›ç›¸åº”çš„å›¾æ ‡"""
        icon_map = {
            '.java': 'â˜•',
            '.xml': 'ğŸ“‹',
            '.yml': 'âš™ï¸',
            '.yaml': 'âš™ï¸',
            '.properties': 'ğŸ”§',
            '.json': 'ğŸ“„',
            '.md': 'ğŸ“',
            '.txt': 'ğŸ“„',
            '.sql': 'ğŸ—ƒï¸',
            '.gitignore': 'ğŸš«',
            '.dockerfile': 'ğŸ³',
            '.sh': 'ğŸ“œ',
            '.bat': 'ğŸ“œ',
            '.jar': 'ğŸ“¦',
            '.war': 'ğŸ“¦',
            '.zip': 'ğŸ“¦',
            '.log': 'ğŸ“Š'
        }
        return icon_map.get(file_extension, 'ğŸ“„')
    
    def generate_project_overview_structure(self, analysis_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆé¡¹ç›®æ•´ä½“ç»“æ„æ¦‚è§ˆ"""
        project_path = Path(analysis_result.get('project_path', ''))
        directory_structure = analysis_result.get('directory_structure', {})
        file_distribution = analysis_result.get('file_distribution', {})
        
        overview = []
        overview.append("# ğŸ—ï¸ é¡¹ç›®æ•´ä½“ç»“æ„åˆ†æ\n")
        
        # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        overview.append("## ğŸ“Š é¡¹ç›®è§„æ¨¡ç»Ÿè®¡")
        overview.append(f"- **é¡¹ç›®æ ¹ç›®å½•**: {project_path.name}")
        overview.append(f"- **æ€»æ–‡ä»¶æ•°**: {directory_structure.get('total_files', 0)}")
        overview.append(f"- **æ€»ç›®å½•æ•°**: {directory_structure.get('total_directories', 0)}")
        overview.append(f"- **æœ€å¤§ç›®å½•æ·±åº¦**: {directory_structure.get('deepest_level', 0)} å±‚")
        
        # æ–‡ä»¶å¤§å°ä¿¡æ¯
        total_size = file_distribution.get('total_size_bytes', 0)
        if total_size > 1024 * 1024 * 1024:
            size_str = f"{total_size / (1024 * 1024 * 1024):.2f} GB"
        elif total_size > 1024 * 1024:
            size_str = f"{total_size / (1024 * 1024):.2f} MB"
        elif total_size > 1024:
            size_str = f"{total_size / 1024:.2f} KB"
        else:
            size_str = f"{total_size} bytes"
        
        overview.append(f"- **é¡¹ç›®æ€»å¤§å°**: {size_str}")
        overview.append("")
        
        # æ–‡ä»¶ç±»å‹åˆ†å¸ƒ
        overview.append("## ğŸ“ æ–‡ä»¶ç±»å‹åˆ†å¸ƒ")
        top_file_types = file_distribution.get('top_file_types', [])
        for ext, count in top_file_types[:8]:
            ext_name = ext if ext else 'æ— æ‰©å±•å'
            percentage = (count / file_distribution.get('total_files', 1)) * 100
            overview.append(f"- **{ext_name}**: {count} ä¸ªæ–‡ä»¶ ({percentage:.1f}%)")
        overview.append("")
        
        # æ ¹ç›®å½•ç»“æ„
        overview.append("## ğŸŒŸ æ ¹ç›®å½•ç»“æ„")
        root_dirs = directory_structure.get('root_level_directories', [])
        root_files = directory_structure.get('root_level_files', [])
        
        overview.append(f"### ğŸ“ æ ¹ç›®å½•æ–‡ä»¶å¤¹ ({len(root_dirs)} ä¸ª)")
        for dir_name in sorted(root_dirs)[:10]:
            overview.append(f"- {dir_name}/")
        if len(root_dirs) > 10:
            overview.append(f"- ... è¿˜æœ‰ {len(root_dirs) - 10} ä¸ªç›®å½•")
        overview.append("")
        
        overview.append(f"### ğŸ“„ æ ¹ç›®å½•æ–‡ä»¶ ({len(root_files)} ä¸ª)")
        for file_name in sorted(root_files)[:10]:
            overview.append(f"- {file_name}")
        if len(root_files) > 10:
            overview.append(f"- ... è¿˜æœ‰ {len(root_files) - 10} ä¸ªæ–‡ä»¶")
        overview.append("")
        
        # ç›®å½•æ ‘ç»“æ„
        overview.append("## ğŸŒ³ å®Œæ•´ç›®å½•æ ‘ç»“æ„")
        overview.append("```")
        directory_tree = self.generate_directory_tree(project_path, max_depth=10)
        overview.append(directory_tree)
        overview.append("```")
        overview.append("")
        
        return "\n".join(overview)

if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    analyzer = JavaCodeAnalyzer()
    
    # åˆ†ææŒ‡å®šçš„Javaé¡¹ç›®
    project_path = input("è¯·è¾“å…¥Javaé¡¹ç›®è·¯å¾„: ").strip()
    if project_path and os.path.exists(project_path):
        result = analyzer.analyze_project(project_path)
        report_path = analyzer.export_analysis_report(result)
        print(f"åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    else:
        print("é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨")