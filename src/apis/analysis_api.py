#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ™ºèƒ½æ–‡æ¡£åˆ†æAPIæ¥å£
åŸºäºRediså­˜å‚¨å’ŒHTTPè½®è¯¢çš„åˆ†æç³»ç»Ÿ
"""

import json
import time
import uuid
import logging
import os
from datetime import datetime
from typing import Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor

from flask import Flask, request, jsonify
from flask_cors import CORS
from werkzeug.utils import secure_filename

# å¯¼å…¥é…ç½®å’ŒæœåŠ¡
from ..resource.config import get_config
from ..utils.volcengine_client import VolcengineClient, VolcengineConfig
from ..analysis_services import AnalysisServiceManager
from ..utils.redis_util import get_redis_manager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DocumentAnalysisAPI:
    """æ–‡æ¡£åˆ†æAPIç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–APIæœåŠ¡"""
        self.config = get_config()
        self.logger = logger
        
        # åˆå§‹åŒ–Redisç®¡ç†å™¨
        self.redis_manager = get_redis_manager()
        
        # åˆå§‹åŒ–ç«å±±å¼•æ“å®¢æˆ·ç«¯
        self._init_volcengine_client()
        
        # åˆå§‹åŒ–åˆ†ææœåŠ¡ç®¡ç†å™¨
        self._init_analysis_service()
        
        # åˆ›å»ºFlaskåº”ç”¨
        self.app = self._create_flask_app()
        
        # çº¿ç¨‹æ± ç”¨äºåå°åˆ†æ
        self.executor = ThreadPoolExecutor(max_workers=3)
        
        # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        self.ALLOWED_EXTENSIONS = {
            'pdf', 'docx', 'doc', 'xlsx', 'xls', 
            'pptx', 'ppt', 'md', 'txt'
        }
        
        # åˆ†æé˜¶æ®µå®šä¹‰
        self.ANALYSIS_STAGES = [
            {'stage': 'document_parsing', 'name': 'æ–‡æ¡£è§£æ'},
            {'stage': 'content_analysis', 'name': 'å†…å®¹åˆ†æ'},
            {'stage': 'ai_analysis', 'name': 'AIæ™ºèƒ½åˆ†æ'}
        ]
    
    def _init_volcengine_client(self):
        """åˆå§‹åŒ–ç«å±±å¼•æ“å®¢æˆ·ç«¯"""
        try:
            volcengine_config = self.config.get_volcengine_config()
            volcano_config = VolcengineConfig(
                api_key=volcengine_config.get('api_key', ''),
                model_id=volcengine_config.get('model', 'doubao-pro-4k'),
                base_url=volcengine_config.get('endpoint', 'https://ark.cn-beijing.volces.com/api/v3'),
                temperature=volcengine_config.get('temperature', 0.7),
                max_tokens=volcengine_config.get('max_tokens', 4000)
            )
            self.volcano_client = VolcengineClient(volcano_config)
            self.logger.info("ç«å±±å¼•æ“å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"ç«å±±å¼•æ“å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.volcano_client = None
    
    def _init_analysis_service(self):
        """åˆå§‹åŒ–åˆ†ææœåŠ¡ç®¡ç†å™¨"""
        try:
            self.analysis_manager = AnalysisServiceManager(
                llm_client=self.volcano_client,
                vector_db_type="mock"
            )
            self.logger.info("åˆ†ææœåŠ¡ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"åˆ†ææœåŠ¡ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.analysis_manager = None
    
    def _create_flask_app(self):
        """åˆ›å»ºFlaskåº”ç”¨"""
        app = Flask(__name__)
        
        # é…ç½®CORS
        CORS(app, 
             origins=["http://localhost:3000", "http://127.0.0.1:3000"],
             methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
             allow_headers=["Content-Type", "Authorization"],
             supports_credentials=True)
        
        # æ³¨å†Œè·¯ç”±
        self._register_routes(app)
        
        return app
    
    def _register_routes(self, app):
        """æ³¨å†ŒAPIè·¯ç”±"""
        
        @app.route('/api/analysis', methods=['POST'])
        def start_analysis():
            """å¯åŠ¨æ–‡æ¡£åˆ†æï¼ˆä¸Šä¼ +åˆ†æï¼‰"""
            return self._start_analysis()
        
        @app.route('/api/analysis/<task_id>', methods=['GET'])
        def get_analysis_progress(task_id):
            """è·å–åˆ†æè¿›åº¦"""
            return self._get_analysis_progress(task_id)
        
        @app.route('/api/analysis/<task_id>/result', methods=['GET'])
        def get_analysis_result(task_id):
            """è·å–åˆ†æç»“æœï¼ˆMarkdownæ ¼å¼ï¼‰"""
            return self._get_analysis_result(task_id)
        
        @app.route('/api/analysis/<task_id>', methods=['DELETE'])
        def cancel_analysis(task_id):
            """å–æ¶ˆåˆ†æä»»åŠ¡"""
            return self._cancel_analysis(task_id)
        
        @app.route('/api/health', methods=['GET'])
        def health_check():
            """å¥åº·æ£€æŸ¥"""
            return self._health_check()
        
        @app.route('/api/chat', methods=['POST'])
        def chat():
            """èŠå¤©æ¥å£"""
            return self._chat()
    
    def _start_analysis(self):
        """å¯åŠ¨åˆ†æ"""
        try:
            # æ£€æŸ¥æ–‡ä»¶ä¸Šä¼ 
            if 'file' not in request.files:
                return jsonify({
                    'status': 'error',
                    'error_code': 'NO_FILE',
                    'error_message': 'æœªæ‰¾åˆ°ä¸Šä¼ æ–‡ä»¶',
                    'retry_able': False
                }), 400
            
            file = request.files['file']
            if file.filename == '':
                return jsonify({
                    'status': 'error',
                    'error_code': 'EMPTY_FILENAME',
                    'error_message': 'æ–‡ä»¶åä¸èƒ½ä¸ºç©º',
                    'retry_able': False
                }), 400
            
            # éªŒè¯æ–‡ä»¶æ ¼å¼
            filename = secure_filename(file.filename)
            file_ext = filename.rsplit('.', 1)[1].lower() if '.' in filename else ''
            
            if file_ext not in self.ALLOWED_EXTENSIONS:
                return jsonify({
                    'status': 'error',
                    'error_code': 'UNSUPPORTED_FORMAT',
                    'error_message': f'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}',
                    'retry_able': False,
                    'suggestions': [f'æ”¯æŒçš„æ ¼å¼: {", ".join(self.ALLOWED_EXTENSIONS)}']
                }), 400
            
            # éªŒè¯æ–‡ä»¶å¤§å°
            file_content = file.read()
            file_size = len(file_content)
            max_size = self.config.config.get('file_upload', {}).get('max_size', 50 * 1024 * 1024)
            
            if file_size > max_size:
                return jsonify({
                    'status': 'error',
                    'error_code': 'FILE_TOO_LARGE',
                    'error_message': f'æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶: {file_size / 1024 / 1024:.1f}MB',
                    'retry_able': False,
                    'suggestions': [f'æœ€å¤§æ–‡ä»¶å¤§å°: {max_size / 1024 / 1024:.0f}MB']
                }), 400
            
            # ç”Ÿæˆä»»åŠ¡ID
            task_id = str(uuid.uuid4())
            
            # ä¿å­˜æ–‡ä»¶
            upload_dir = self.config.config.get('directories', {}).get('uploads', 'uploads')
            os.makedirs(upload_dir, exist_ok=True)
            file_path = os.path.join(upload_dir, f"{task_id}_{filename}")
            
            with open(file_path, 'wb') as f:
                f.write(file_content)
            
            # ä¿å­˜åŸºæœ¬ä¿¡æ¯åˆ°Redis
            basic_info = {
                'task_id': task_id,
                'filename': filename,
                'filesize': f"{file_size / 1024 / 1024:.2f}MB",
                'file_type': file_ext,
                'upload_time': datetime.now().isoformat(),
                'status': 'uploaded',
                'created_at': datetime.now().isoformat()
            }
            
            self.redis_manager.set(f"analysis:{task_id}:basic_info", basic_info, ttl=24 * 3600)
            
            # åˆå§‹åŒ–è¿›åº¦ä¿¡æ¯
            progress_info = {
                'task_id': task_id,
                'status': 'started',
                'current_stage': None,
                'stages': {
                    'document_parsing': {'status': 'pending', 'progress': 0, 'message': 'ç­‰å¾…å¼€å§‹'},
                    'content_analysis': {'status': 'pending', 'progress': 0, 'message': 'ç­‰å¾…å¼€å§‹'},
                    'ai_analysis': {'status': 'pending', 'progress': 0, 'message': 'ç­‰å¾…å¼€å§‹'}
                },
                'overall_progress': 0,
                'updated_at': datetime.now().isoformat()
            }
            
            self.redis_manager.set(f"analysis:{task_id}:progress", progress_info, ttl=24 * 3600)
            
            # å¯åŠ¨åå°åˆ†æä»»åŠ¡
            self.executor.submit(self._run_full_analysis, task_id, file_path, file_content.decode('utf-8', errors='ignore'), filename)
            
            return jsonify({
                'status': 'started',
                'task_id': task_id,
                'message': 'åˆ†æå·²å¯åŠ¨',
                'basic_info': basic_info
            })
            
        except Exception as e:
            self.logger.error(f"å¯åŠ¨åˆ†æå¤±è´¥: {e}")
            return jsonify({
                'status': 'error',
                'error_code': 'INTERNAL_ERROR',
                'error_message': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯',
                'retry_able': True
            }), 500
    
    def _run_full_analysis(self, task_id: str, file_path: str, file_content: str, filename: str):
        """åå°è¿è¡Œå®Œæ•´åˆ†æ"""
        try:
            self.logger.info(f"å¼€å§‹åå°åˆ†æä»»åŠ¡: {task_id}")
            
            if not self.analysis_manager:
                raise Exception("åˆ†ææœåŠ¡ç®¡ç†å™¨æœªåˆå§‹åŒ–")
            
            # æ‰§è¡Œä¸‰é˜¶æ®µåˆ†æ
            for i, stage_info in enumerate(self.ANALYSIS_STAGES):
                stage = stage_info['stage']
                stage_name = stage_info['name']
                
                try:
                    # æ›´æ–°å½“å‰é˜¶æ®µçŠ¶æ€
                    self._update_stage_progress(task_id, stage, 'running', 0, f'å¼€å§‹{stage_name}...')
                    
                    # å‡†å¤‡è¾“å…¥æ•°æ®
                    if stage == 'document_parsing':
                        # ç¬¬ä¸€é˜¶æ®µï¼šæ–‡æ¡£è§£æ
                        input_data = {
                            "file_path": file_path,
                            "file_content": file_content,
                            "file_name": filename
                        }
                    else:
                        # åç»­é˜¶æ®µï¼šä»Redisè·å–å‰ä¸€é˜¶æ®µç»“æœ
                        prev_stage = self.ANALYSIS_STAGES[i-1]['stage']
                        prev_result = self.redis_manager.get(f"analysis:{task_id}:{prev_stage}")
                        if not prev_result:
                            raise Exception(f"æ— æ³•è·å–å‰ä¸€é˜¶æ®µç»“æœ: {prev_stage}")
                        input_data = prev_result
                    
                    # æ‰§è¡Œåˆ†æ
                    stage_result = None
                    if stage == 'document_parsing':
                        stage_result = self.analysis_manager.document_parser.analyze(task_id, input_data)
                    elif stage == 'content_analysis':
                        stage_result = self.analysis_manager.content_analyzer.analyze(task_id, input_data)
                    elif stage == 'ai_analysis':
                        stage_result = self.analysis_manager.ai_analyzer.analyze(task_id, input_data)
                    
                    # ä¿å­˜é˜¶æ®µç»“æœåˆ°Redis
                    self.redis_manager.set(f"analysis:{task_id}:{stage}", stage_result, ttl=24 * 3600)
                    
                    # æ›´æ–°é˜¶æ®µå®ŒæˆçŠ¶æ€
                    self._update_stage_progress(task_id, stage, 'completed', 100, f'{stage_name}å®Œæˆ')
                    
                    self.logger.info(f"é˜¶æ®µå®Œæˆ: {task_id} - {stage}")
                    
                except Exception as e:
                    self.logger.error(f"é˜¶æ®µæ‰§è¡Œå¤±è´¥ {task_id} - {stage}: {e}")
                    self._update_stage_progress(task_id, stage, 'error', 0, f'{stage_name}å¤±è´¥: {str(e)}')
                    return
            
            # ç»„è£…æœ€ç»ˆç»“æœ
            final_result = self._assemble_final_result(task_id)
            
            # ä¿å­˜æœ€ç»ˆç»“æœ
            self.redis_manager.set(f"analysis:{task_id}:result", final_result, ttl=24 * 3600)
            
            # æ›´æ–°æ•´ä½“çŠ¶æ€ä¸ºå®Œæˆ
            self._update_overall_progress(task_id, 'completed', 100, 'åˆ†æå®Œæˆ')
            
            self.logger.info(f"åˆ†æä»»åŠ¡å®Œæˆ: {task_id}")
            
        except Exception as e:
            self.logger.error(f"åˆ†æä»»åŠ¡å¤±è´¥ {task_id}: {e}")
            self._update_overall_progress(task_id, 'error', 0, f'åˆ†æå¤±è´¥: {str(e)}')
    
    def _update_stage_progress(self, task_id: str, stage: str, status: str, progress: int, message: str):
        """æ›´æ–°é˜¶æ®µè¿›åº¦"""
        try:
            progress_info = self.redis_manager.get(f"analysis:{task_id}:progress", default={})
            
            if 'stages' not in progress_info:
                progress_info['stages'] = {}
            
            progress_info['stages'][stage] = {
                'status': status,
                'progress': progress,
                'message': message,
                'updated_at': datetime.now().isoformat()
            }
            
            progress_info['current_stage'] = stage if status == 'running' else None
            progress_info['updated_at'] = datetime.now().isoformat()
            
            # è®¡ç®—æ•´ä½“è¿›åº¦
            completed_stages = sum(1 for s in progress_info['stages'].values() if s['status'] == 'completed')
            progress_info['overall_progress'] = int((completed_stages / len(self.ANALYSIS_STAGES)) * 100)
            
            self.redis_manager.set(f"analysis:{task_id}:progress", progress_info, ttl=24 * 3600)
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°é˜¶æ®µè¿›åº¦å¤±è´¥: {e}")
    
    def _update_overall_progress(self, task_id: str, status: str, progress: int, message: str):
        """æ›´æ–°æ•´ä½“è¿›åº¦"""
        try:
            progress_info = self.redis_manager.get(f"analysis:{task_id}:progress", default={})
            
            progress_info.update({
                'status': status,
                'overall_progress': progress,
                'message': message,
                'updated_at': datetime.now().isoformat()
            })
            
            self.redis_manager.set(f"analysis:{task_id}:progress", progress_info, ttl=24 * 3600)
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°æ•´ä½“è¿›åº¦å¤±è´¥: {e}")
    
    def _assemble_final_result(self, task_id: str) -> Dict[str, Any]:
        """ç»„è£…æœ€ç»ˆç»“æœ"""
        try:
            # è·å–åŸºæœ¬ä¿¡æ¯
            basic_info = self.redis_manager.get(f"analysis:{task_id}:basic_info", default={})
            
            # è·å–å„é˜¶æ®µç»“æœ
            document_parsing = self.redis_manager.get(f"analysis:{task_id}:document_parsing", default={})
            content_analysis = self.redis_manager.get(f"analysis:{task_id}:content_analysis", default={})
            ai_analysis = self.redis_manager.get(f"analysis:{task_id}:ai_analysis", default={})
            
            # ç»„è£…å®Œæ•´ç»“æœ
            final_result = {
                "task_id": task_id,
                "status": "completed",
                "created_at": basic_info.get('created_at'),
                "completed_at": datetime.now().isoformat(),
                "basic_info": basic_info,
                "document_parsing": document_parsing,
                "content_analysis": content_analysis,
                "ai_analysis": ai_analysis,
                "analysis_summary": self._generate_analysis_summary(document_parsing, content_analysis, ai_analysis)
            }
            
            return final_result
            
        except Exception as e:
            self.logger.error(f"ç»„è£…æœ€ç»ˆç»“æœå¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _generate_analysis_summary(self, doc_parsing: Dict, content_analysis: Dict, ai_analysis: Dict) -> str:
        """ç”Ÿæˆåˆ†ææ€»ç»“"""
        try:
            summary_parts = []
            
            # æ–‡æ¡£åŸºæœ¬ä¿¡æ¯
            if doc_parsing.get('file_info'):
                file_info = doc_parsing['file_info']
                summary_parts.append(f"æ–‡æ¡£ç±»å‹: {file_info.get('file_type', 'unknown')}")
                if file_info.get('page_count'):
                    summary_parts.append(f"é¡µæ•°: {file_info['page_count']}")
            
            # å†…å®¹åˆ†ææ‘˜è¦
            if content_analysis.get('key_changes'):
                changes_count = len(content_analysis['key_changes'])
                summary_parts.append(f"è¯†åˆ«åˆ° {changes_count} ä¸ªå…³é”®å˜æ›´")
            
            # AIåˆ†ææ‘˜è¦
            if ai_analysis.get('requirements'):
                req_count = len(ai_analysis['requirements'])
                summary_parts.append(f"æå–äº† {req_count} ä¸ªéœ€æ±‚")
            
            return "ã€".join(summary_parts) if summary_parts else "åˆ†æå®Œæˆ"
            
        except Exception as e:
            return f"ç”Ÿæˆæ‘˜è¦å¤±è´¥: {str(e)}"
    
    def _get_analysis_progress(self, task_id: str):
        """è·å–åˆ†æè¿›åº¦"""
        try:
            # è·å–åŸºæœ¬ä¿¡æ¯
            basic_info = self.redis_manager.get(f"analysis:{task_id}:basic_info")
            if not basic_info:
                return jsonify({
                    'status': 'error',
                    'error_code': 'TASK_NOT_FOUND',
                    'error_message': 'ä»»åŠ¡ä¸å­˜åœ¨'
                }), 404
            
            # è·å–è¿›åº¦ä¿¡æ¯
            progress_info = self.redis_manager.get(f"analysis:{task_id}:progress", default={
                'status': 'pending',
                'overall_progress': 0,
                'stages': {},
                'message': 'ç­‰å¾…å¼€å§‹'
            })
            
            response = {
                'task_id': task_id,
                'basic_info': basic_info,
                'progress': progress_info
            }
            
            # å¦‚æœåˆ†æå®Œæˆï¼Œæ·»åŠ ç»“æœé¢„è§ˆ
            if progress_info.get('status') == 'completed':
                result = self.redis_manager.get(f"analysis:{task_id}:result")
                if result:
                    response['result_available'] = True
                    response['summary'] = result.get('analysis_summary', 'åˆ†æå®Œæˆ')
            
            return jsonify(response)
            
        except Exception as e:
            self.logger.error(f"è·å–åˆ†æè¿›åº¦å¤±è´¥: {e}")
            return jsonify({
                'status': 'error',
                'error_code': 'INTERNAL_ERROR',
                'error_message': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'
            }), 500
    
    def _get_analysis_result(self, task_id: str):
        """è·å–åˆ†æç»“æœï¼ˆMarkdownæ ¼å¼ï¼‰"""
        try:
            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
            basic_info = self.redis_manager.get(f"analysis:{task_id}:basic_info")
            if not basic_info:
                return jsonify({
                    'status': 'error',
                    'error_code': 'TASK_NOT_FOUND',
                    'error_message': 'ä»»åŠ¡ä¸å­˜åœ¨'
                }), 404
            
            # è·å–åˆ†æç»“æœ
            result = self.redis_manager.get(f"analysis:{task_id}:result")
            if not result:
                return jsonify({
                    'status': 'error',
                    'error_code': 'RESULT_NOT_READY',
                    'error_message': 'åˆ†æç»“æœå°šæœªå‡†å¤‡å°±ç»ª'
                }), 404
            
            # è½¬æ¢ä¸ºMarkdownæ ¼å¼
            markdown_content = self._convert_to_markdown(result)
            
            return jsonify({
                'status': 'success',
                'task_id': task_id,
                'format': 'markdown',
                'content': markdown_content,
                'raw_data': result  # åŒæ—¶æä¾›åŸå§‹JSONæ•°æ®
            })
            
        except Exception as e:
            self.logger.error(f"è·å–åˆ†æç»“æœå¤±è´¥: {e}")
            return jsonify({
                'status': 'error',
                'error_code': 'INTERNAL_ERROR',
                'error_message': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'
            }), 500
    
    def _convert_to_markdown(self, result: Dict[str, Any]) -> str:
        """å°†JSONç»“æœè½¬æ¢ä¸ºMarkdownæ ¼å¼"""
        try:
            markdown_lines = []
            
            # æ ‡é¢˜
            basic_info = result.get('basic_info', {})
            filename = basic_info.get('filename', 'æœªçŸ¥æ–‡ä»¶')
            markdown_lines.append(f"# æ–‡æ¡£åˆ†ææŠ¥å‘Š - {filename}")
            markdown_lines.append("")
            
            # åŸºæœ¬ä¿¡æ¯
            markdown_lines.append("## ğŸ“‹ åŸºæœ¬ä¿¡æ¯")
            markdown_lines.append(f"- **æ–‡ä»¶å**: {filename}")
            markdown_lines.append(f"- **æ–‡ä»¶å¤§å°**: {basic_info.get('filesize', 'æœªçŸ¥')}")
            markdown_lines.append(f"- **æ–‡ä»¶ç±»å‹**: {basic_info.get('file_type', 'æœªçŸ¥')}")
            markdown_lines.append(f"- **ä¸Šä¼ æ—¶é—´**: {basic_info.get('upload_time', 'æœªçŸ¥')}")
            markdown_lines.append(f"- **åˆ†æå®Œæˆæ—¶é—´**: {result.get('completed_at', 'æœªçŸ¥')}")
            markdown_lines.append("")
            
            # æ–‡æ¡£è§£æç»“æœ
            doc_parsing = result.get('document_parsing', {})
            if doc_parsing:
                markdown_lines.append("## ğŸ“– æ–‡æ¡£è§£æ")
                
                # æ–‡ä»¶ä¿¡æ¯
                file_info = doc_parsing.get('file_info', {})
                if file_info:
                    markdown_lines.append("### æ–‡ä»¶ä¿¡æ¯")
                    for key, value in file_info.items():
                        markdown_lines.append(f"- **{key}**: {value}")
                    markdown_lines.append("")
                
                # æ–‡æ¡£ç»“æ„
                structure = doc_parsing.get('structure', {})
                if structure:
                    markdown_lines.append("### æ–‡æ¡£ç»“æ„")
                    if structure.get('title'):
                        markdown_lines.append(f"- **æ ‡é¢˜**: {structure['title']}")
                    if structure.get('sections'):
                        markdown_lines.append("- **ç« èŠ‚ç»“æ„**:")
                        for section in structure['sections'][:5]:  # é™åˆ¶æ˜¾ç¤ºå‰5ä¸ªç« èŠ‚
                            markdown_lines.append(f"  - {section.get('title', 'æœªçŸ¥ç« èŠ‚')}")
                    markdown_lines.append("")
            
            # å†…å®¹åˆ†æç»“æœ
            content_analysis = result.get('content_analysis', {})
            if content_analysis:
                markdown_lines.append("## ğŸ” å†…å®¹åˆ†æ")
                
                # æ–°å¢åŠŸèƒ½
                new_features = content_analysis.get('new_features', [])
                if new_features:
                    markdown_lines.append("### æ–°å¢åŠŸèƒ½")
                    for feature in new_features[:3]:  # é™åˆ¶æ˜¾ç¤ºå‰3ä¸ª
                        markdown_lines.append(f"- **{feature.get('feature_name', 'æœªçŸ¥åŠŸèƒ½')}**: {feature.get('description', 'æ— æè¿°')}")
                    markdown_lines.append("")
                
                # å…³é”®å˜æ›´
                key_changes = content_analysis.get('key_changes', [])
                if key_changes:
                    markdown_lines.append("### å…³é”®å˜æ›´")
                    for change in key_changes[:3]:  # é™åˆ¶æ˜¾ç¤ºå‰3ä¸ª
                        markdown_lines.append(f"- **{change.get('title', 'æœªçŸ¥å˜æ›´')}**: {change.get('impact', 'æ— å½±å“æè¿°')}")
                    markdown_lines.append("")
            
            # AIæ™ºèƒ½åˆ†æç»“æœ
            ai_analysis = result.get('ai_analysis', {})
            if ai_analysis:
                markdown_lines.append("## ğŸ¤– AIæ™ºèƒ½åˆ†æ")
                
                # éœ€æ±‚æå–
                requirements = ai_analysis.get('requirements', [])
                if requirements:
                    markdown_lines.append("### éœ€æ±‚æå–")
                    for req in requirements[:5]:  # é™åˆ¶æ˜¾ç¤ºå‰5ä¸ª
                        markdown_lines.append(f"- **{req.get('title', 'æœªçŸ¥éœ€æ±‚')}**: {req.get('description', 'æ— æè¿°')}")
                    markdown_lines.append("")
                
                # æŠ€æœ¯è®¾è®¡
                tech_design = ai_analysis.get('technical_design', '')
                if tech_design:
                    markdown_lines.append("### æŠ€æœ¯è®¾è®¡")
                    markdown_lines.append(tech_design[:500] + "..." if len(tech_design) > 500 else tech_design)
                    markdown_lines.append("")
                
                # å®ç°å»ºè®®
                implementation = ai_analysis.get('implementation_suggestions', '')
                if implementation:
                    markdown_lines.append("### å®ç°å»ºè®®")
                    markdown_lines.append(implementation[:500] + "..." if len(implementation) > 500 else implementation)
                    markdown_lines.append("")
            
            # åˆ†ææ€»ç»“
            summary = result.get('analysis_summary', '')
            if summary:
                markdown_lines.append("## ğŸ“Š åˆ†ææ€»ç»“")
                markdown_lines.append(summary)
                markdown_lines.append("")
            
            # ç”Ÿæˆæ—¶é—´æˆ³
            markdown_lines.append("---")
            markdown_lines.append(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")
            
            return "\n".join(markdown_lines)
            
        except Exception as e:
            self.logger.error(f"è½¬æ¢Markdownå¤±è´¥: {e}")
            return f"# è½¬æ¢é”™è¯¯\n\nè½¬æ¢Markdownæ ¼å¼æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
    
    def _cancel_analysis(self, task_id: str):
        """å–æ¶ˆåˆ†æä»»åŠ¡"""
        try:
            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
            basic_info = self.redis_manager.get(f"analysis:{task_id}:basic_info")
            if not basic_info:
                return jsonify({
                    'status': 'error',
                    'error_code': 'TASK_NOT_FOUND',
                    'error_message': 'ä»»åŠ¡ä¸å­˜åœ¨'
                }), 404
            
            # æ›´æ–°çŠ¶æ€ä¸ºå·²å–æ¶ˆ
            self._update_overall_progress(task_id, 'cancelled', 0, 'ä»»åŠ¡å·²å–æ¶ˆ')
            
            return jsonify({
                'status': 'success',
                'message': 'ä»»åŠ¡å·²å–æ¶ˆ'
            })
            
        except Exception as e:
            self.logger.error(f"å–æ¶ˆåˆ†æä»»åŠ¡å¤±è´¥: {e}")
            return jsonify({
                'status': 'error',
                'error_message': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'
            }), 500
    
    def _health_check(self):
        """å¥åº·æ£€æŸ¥"""
        status = {
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'services': {
                'redis': self.redis_manager.test_connection(),
                'volcengine': self.volcano_client is not None,
                'analysis_manager': self.analysis_manager is not None
            }
        }
        
        return jsonify(status)
    
    def run(self, host='0.0.0.0', port=8082, debug=False):
        """è¿è¡ŒAPIæœåŠ¡"""
        self.logger.info(f"å¯åŠ¨æ–‡æ¡£åˆ†æAPIæœåŠ¡: http://{host}:{port}")
        self.app.run(host=host, port=port, debug=debug)

# åˆ›å»ºAPIå®ä¾‹
api = DocumentAnalysisAPI()

def create_app():
    """åˆ›å»ºFlaskåº”ç”¨ï¼ˆç”¨äºå¤–éƒ¨è°ƒç”¨ï¼‰"""
    return api.app

if __name__ == '__main__':
    api.run(debug=True) 