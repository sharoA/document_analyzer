"""
æ™ºèƒ½ç»„ä»¶å¤ç”¨ç®¡ç†å™¨
å¤„ç†Controlleræ¥å£ä¹‹é—´çš„ç»„ä»¶å¤ç”¨å’Œæ¥å£é€»è¾‘åˆå¹¶
"""
import os
import re
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Set
import logging

logger = logging.getLogger(__name__)


class IntelligentComponentReuseManager:
    """æ™ºèƒ½ç»„ä»¶å¤ç”¨ç®¡ç†å™¨"""
    
    def __init__(self, llm_client=None):
        """
        åˆå§‹åŒ–æ™ºèƒ½ç»„ä»¶å¤ç”¨ç®¡ç†å™¨
        
        Args:
            llm_client: LLMå®¢æˆ·ç«¯ï¼Œç”¨äºæ™ºèƒ½åˆ†æ
        """
        self.llm_client = llm_client
        self.component_cache = {}  # ç¼“å­˜å·²åˆ†æçš„ç»„ä»¶
        self.interface_patterns = {}  # æ¥å£æ¨¡å¼ç¼“å­˜
        
    def analyze_controller_component_dependencies(self, controller_path: str) -> Dict[str, any]:
        """
        åˆ†æControllerä¸­çš„ç»„ä»¶ä¾èµ–å…³ç³»
        
        Args:
            controller_path: Controlleræ–‡ä»¶è·¯å¾„
            
        Returns:
            ç»„ä»¶ä¾èµ–åˆ†æç»“æœ
        """
        logger.info(f"ğŸ” åˆ†æControllerç»„ä»¶ä¾èµ–: {controller_path}")
        
        try:
            with open(controller_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–ç»„ä»¶ä¾èµ–ä¿¡æ¯
            dependencies = self._extract_component_dependencies(content)
            
            # åˆ†æFeign Clientä¾èµ–
            feign_clients = self._extract_feign_clients(content, controller_path)
            
            # åˆ†æServiceä¾èµ–
            service_dependencies = self._extract_service_dependencies(content)
            
            # åˆ†ææ–¹æ³•æ¨¡å¼
            method_patterns = self._analyze_method_patterns(content)
            
            return {
                'controller_path': controller_path,
                'dependencies': dependencies,
                'feign_clients': feign_clients,
                'service_dependencies': service_dependencies,
                'method_patterns': method_patterns,
                'analysis_timestamp': self._get_timestamp()
            }
            
        except Exception as e:
            logger.error(f"âŒ åˆ†æControllerç»„ä»¶ä¾èµ–å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def find_reusable_feign_clients(self, target_controller: str, api_path: str, 
                                   business_domain: str) -> List[Dict[str, any]]:
        """
        æŸ¥æ‰¾å¯å¤ç”¨çš„Feign Clientç±»
        
        Args:
            target_controller: ç›®æ ‡Controllerè·¯å¾„
            api_path: APIè·¯å¾„
            business_domain: ä¸šåŠ¡åŸŸ
            
        Returns:
            å¯å¤ç”¨çš„Feign Clientåˆ—è¡¨
        """
        logger.info(f"ğŸ” æŸ¥æ‰¾å¯å¤ç”¨çš„Feign Client: {business_domain}")
        
        reusable_clients = []
        
        # æå–ä¸šåŠ¡åŸŸå…³é”®å­—
        domain_keywords = self._extract_domain_keywords(api_path, business_domain)
        
        # æœç´¢é¡¹ç›®ä¸­çš„Feign Client
        project_root = self._find_project_root(target_controller)
        feign_clients = self._scan_feign_clients(project_root)
        
        for client in feign_clients:
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity_score = self._calculate_feign_client_similarity(
                client, domain_keywords, api_path
            )
            
            if similarity_score > 0.6:  # ç›¸ä¼¼åº¦é˜ˆå€¼
                reusable_clients.append({
                    'client_info': client,
                    'similarity_score': similarity_score,
                    'reuse_recommendation': self._generate_reuse_recommendation(client, similarity_score)
                })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        reusable_clients.sort(key=lambda x: x['similarity_score'], reverse=True)
        
        logger.info(f"âœ… æ‰¾åˆ° {len(reusable_clients)} ä¸ªå¯å¤ç”¨çš„Feign Client")
        return reusable_clients
    
    def merge_similar_interface_logic(self, interface_name: str, existing_methods: List[Dict], 
                                     new_interface_type: str) -> Dict[str, any]:
        """
        åˆå¹¶ç›¸ä¼¼æ¥å£é€»è¾‘
        
        Args:
            interface_name: æ¥å£åç§°
            existing_methods: ç°æœ‰æ–¹æ³•åˆ—è¡¨
            new_interface_type: æ–°æ¥å£ç±»å‹ (query_list, export_list, etc.)
            
        Returns:
            åˆå¹¶ç­–ç•¥ç»“æœ
        """
        logger.info(f"ğŸ”„ åˆ†ææ¥å£é€»è¾‘åˆå¹¶: {interface_name} ({new_interface_type})")
        
        # è¯†åˆ«ç›¸ä¼¼æ¥å£æ¨¡å¼
        similar_patterns = self._identify_similar_patterns(interface_name, existing_methods, new_interface_type)
        
        if similar_patterns:
            # ç”Ÿæˆåˆå¹¶ç­–ç•¥
            merge_strategy = self._generate_merge_strategy(similar_patterns, new_interface_type)
            
            return {
                'can_merge': True,
                'merge_strategy': merge_strategy,
                'similar_patterns': similar_patterns,
                'shared_logic': self._extract_shared_logic(similar_patterns),
                'special_handling': self._get_special_handling(new_interface_type)
            }
        else:
            return {
                'can_merge': False,
                'reason': 'æœªæ‰¾åˆ°ç›¸ä¼¼çš„æ¥å£æ¨¡å¼',
                'recommendation': 'åˆ›å»ºç‹¬ç«‹çš„æ¥å£å®ç°'
            }
    
    def generate_shared_service_method(self, base_method: Dict[str, any], 
                                     interface_variants: List[str]) -> Dict[str, any]:
        """
        ç”Ÿæˆå…±äº«çš„Serviceæ–¹æ³•
        
        Args:
            base_method: åŸºç¡€æ–¹æ³•ä¿¡æ¯
            interface_variants: æ¥å£å˜ä½“åˆ—è¡¨ (query, export, etc.)
            
        Returns:
            å…±äº«æ–¹æ³•ç”Ÿæˆç»“æœ
        """
        logger.info(f"ğŸ—ï¸ ç”Ÿæˆå…±äº«Serviceæ–¹æ³•: {base_method.get('name', 'unknown')}")
        
        # åˆ†ææ–¹æ³•ç­¾å
        method_signature = self._analyze_method_signature(base_method)
        
        # ç”Ÿæˆå…±äº«çš„æ ¸å¿ƒé€»è¾‘
        shared_logic = self._generate_shared_logic(method_signature, interface_variants)
        
        # ç”Ÿæˆæ¥å£ç‰¹å®šçš„å¤„ç†é€»è¾‘
        variant_handlers = {}
        for variant in interface_variants:
            variant_handlers[variant] = self._generate_variant_handler(variant, method_signature)
        
        return {
            'shared_method': {
                'name': f"{method_signature['base_name']}Data",
                'signature': self._build_shared_method_signature(method_signature),
                'logic': shared_logic,
                'return_type': 'List<Map<String, Object>>'
            },
            'variant_methods': variant_handlers,
            'dependencies': self._extract_method_dependencies(base_method)
        }
    
    def generate_export_enhanced_method(self, base_method: Dict[str, any], 
                                      export_config: Dict[str, any]) -> str:
        """
        ç”Ÿæˆå¯¼å‡ºå¢å¼ºæ–¹æ³•
        
        Args:
            base_method: åŸºç¡€æŸ¥è¯¢æ–¹æ³•
            export_config: å¯¼å‡ºé…ç½®
            
        Returns:
            å¯¼å‡ºæ–¹æ³•ä»£ç 
        """
        logger.info(f"ğŸ“„ ç”Ÿæˆå¯¼å‡ºå¢å¼ºæ–¹æ³•: {base_method.get('name', 'unknown')}")
        
        base_name = base_method.get('name', 'query')
        export_method_name = f"{base_name}Export"
        
        # ç”Ÿæˆå¯¼å‡ºæ–¹æ³•ä»£ç 
        export_method_code = f"""
    /**
     * {base_method.get('description', 'æ•°æ®')}å¯¼å‡º
     * åŸºäº{base_name}æ–¹æ³•çš„æ•°æ®ï¼Œç”ŸæˆExcelæ–‡ä»¶
     */
    @GetMapping("/{base_name}/export")
    public ResponseEntity<byte[]> {export_method_name}(@RequestParam Map<String, Object> params) {{
        try {{
            // 1. è°ƒç”¨åŸºç¡€æŸ¥è¯¢æ–¹æ³•è·å–æ•°æ®
            List<Map<String, Object>> data = {base_name}Data(params);
            
            // 2. ç”ŸæˆExcelæ–‡ä»¶
            String fileName = "{base_method.get('description', 'æ•°æ®')}å¯¼å‡º_" + 
                            LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyyMMdd_HHmmss"));
            
            byte[] excelBytes = excelExportService.exportToExcel(data, 
                "{base_method.get('description', 'æ•°æ®')}å¯¼å‡º", {self._generate_excel_columns(base_method)});
            
            // 3. è®¾ç½®å“åº”å¤´
            HttpHeaders headers = new HttpHeaders();
            headers.setContentType(MediaType.APPLICATION_OCTET_STREAM);
            headers.setContentDispositionFormData("attachment", fileName + ".xlsx");
            
            return ResponseEntity.ok()
                    .headers(headers)
                    .body(excelBytes);
                    
        }} catch (Exception e) {{
            logger.error("å¯¼å‡º{base_method.get('description', 'æ•°æ®')}å¤±è´¥", e);
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build();
        }}
    }}
    
    /**
     * {base_method.get('description', 'æ•°æ®')}æŸ¥è¯¢ - å…±äº«æ•°æ®è·å–é€»è¾‘
     */
    private List<Map<String, Object>> {base_name}Data(Map<String, Object> params) {{
        // è°ƒç”¨Feign Clientæˆ–Serviceè·å–æ•°æ®
        return {base_method.get('service_call', 'dataService.queryData(params)')};
    }}"""
        
        return export_method_code
    
    def update_controller_with_component_reuse(self, controller_path: str, 
                                             reuse_plan: Dict[str, any]) -> Dict[str, any]:
        """
        æ›´æ–°Controllerä»¥æ”¯æŒç»„ä»¶å¤ç”¨
        
        Args:
            controller_path: Controlleræ–‡ä»¶è·¯å¾„
            reuse_plan: å¤ç”¨è®¡åˆ’
            
        Returns:
            æ›´æ–°ç»“æœ
        """
        logger.info(f"ğŸ”„ æ›´æ–°Controlleræ”¯æŒç»„ä»¶å¤ç”¨: {controller_path}")
        
        try:
            # è¯»å–ç°æœ‰Controllerå†…å®¹
            with open(controller_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            updated_content = content
            added_components = []
            
            # æ·»åŠ Feign Clientä¾èµ–
            if 'feign_clients' in reuse_plan:
                for client in reuse_plan['feign_clients']:
                    if not self._is_component_already_injected(content, client['class_name']):
                        updated_content = self._inject_feign_client(updated_content, client)
                        added_components.append(f"FeignClient: {client['class_name']}")
            
            # æ·»åŠ å…±äº«æ–¹æ³•
            if 'shared_methods' in reuse_plan:
                for method in reuse_plan['shared_methods']:
                    updated_content = self._add_shared_method(updated_content, method)
                    added_components.append(f"SharedMethod: {method['name']}")
            
            # æ·»åŠ å¯¼å‡ºå¢å¼ºæ–¹æ³•
            if 'export_methods' in reuse_plan:
                for method in reuse_plan['export_methods']:
                    updated_content = self._add_export_method(updated_content, method)
                    added_components.append(f"ExportMethod: {method['name']}")
            
            # æ·»åŠ å¿…è¦çš„import
            updated_content = self._add_required_imports(updated_content, reuse_plan)
            
            # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
            with open(controller_path, 'w', encoding='utf-8') as f:
                f.write(updated_content)
            
            return {
                'success': True,
                'message': f"æˆåŠŸæ›´æ–°Controllerï¼Œæ·»åŠ äº† {len(added_components)} ä¸ªç»„ä»¶",
                'added_components': added_components
            }
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°Controllerå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    # ==================== ç§æœ‰æ–¹æ³• ====================
    
    def _extract_component_dependencies(self, content: str) -> List[Dict[str, any]]:
        """æå–ç»„ä»¶ä¾èµ–"""
        dependencies = []
        
        # æŸ¥æ‰¾@Autowiredæ³¨è§£çš„å­—æ®µ
        autowired_pattern = re.compile(r'@Autowired\s+private\s+(\w+)\s+(\w+);')
        for match in autowired_pattern.finditer(content):
            dependencies.append({
                'type': 'autowired',
                'class_name': match.group(1),
                'variable_name': match.group(2)
            })
        
        # æŸ¥æ‰¾æ„é€ å™¨æ³¨å…¥
        constructor_pattern = re.compile(r'public\s+\w+\s*\([^)]*(\w+)\s+(\w+)[^)]*\)')
        for match in constructor_pattern.finditer(content):
            dependencies.append({
                'type': 'constructor',
                'class_name': match.group(1),
                'variable_name': match.group(2)
            })
        
        return dependencies
    
    def _extract_feign_clients(self, content: str, controller_path: str) -> List[Dict[str, any]]:
        """æå–Feign Clientä¾èµ–"""
        feign_clients = []
        
        # æŸ¥æ‰¾Feign Clientæ³¨å…¥
        feign_pattern = re.compile(r'@Autowired\s+private\s+(\w+)\s+(\w+);')
        for match in feign_pattern.finditer(content):
            class_name = match.group(1)
            variable_name = match.group(2)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯Feign Clientï¼ˆé€šè¿‡å‘½åè§„åˆ™æˆ–æ³¨è§£ï¼‰
            if 'feign' in class_name.lower() or 'client' in class_name.lower():
                feign_clients.append({
                    'class_name': class_name,
                    'variable_name': variable_name,
                    'business_domain': self._extract_business_domain_from_class(class_name),
                    'controller_path': controller_path
                })
        
        return feign_clients
    
    def _extract_service_dependencies(self, content: str) -> List[Dict[str, any]]:
        """æå–Serviceä¾èµ–"""
        services = []
        
        service_pattern = re.compile(r'@Autowired\s+private\s+(\w+Service)\s+(\w+);')
        for match in service_pattern.finditer(content):
            services.append({
                'class_name': match.group(1),
                'variable_name': match.group(2)
            })
        
        return services
    
    def _analyze_method_patterns(self, content: str) -> List[Dict[str, any]]:
        """åˆ†ææ–¹æ³•æ¨¡å¼"""
        patterns = []
        
        # æŸ¥æ‰¾å…¬å…±æ–¹æ³•
        method_pattern = re.compile(r'@(\w+Mapping)\s*\([^)]*\)\s*public\s+[^{]+\s+(\w+)\s*\([^)]*\)\s*{')
        for match in method_pattern.finditer(content):
            mapping_type = match.group(1)
            method_name = match.group(2)
            
            # åˆ†ææ–¹æ³•ç±»å‹
            method_type = self._classify_method_type(method_name)
            
            patterns.append({
                'mapping_type': mapping_type,
                'method_name': method_name,
                'method_type': method_type,
                'business_operation': self._extract_business_operation(method_name)
            })
        
        return patterns
    
    def _extract_domain_keywords(self, api_path: str, business_domain: str) -> List[str]:
        """æå–ä¸šåŠ¡åŸŸå…³é”®å­—"""
        keywords = []
        
        # ä»APIè·¯å¾„æå–
        path_parts = [part for part in api_path.split('/') if part]
        keywords.extend(path_parts)
        
        # ä»ä¸šåŠ¡åŸŸæå–
        if business_domain:
            keywords.append(business_domain)
        
        return list(set(keywords))
    
    def _find_project_root(self, file_path: str) -> str:
        """æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•"""
        current_path = Path(file_path).parent
        
        while current_path.parent != current_path:
            if (current_path / 'src').exists():
                return str(current_path)
            current_path = current_path.parent
        
        return str(current_path)
    
    def _scan_feign_clients(self, project_root: str) -> List[Dict[str, any]]:
        """æ‰«æé¡¹ç›®ä¸­çš„Feign Client"""
        feign_clients = []
        
        for root, dirs, files in os.walk(project_root):
            if 'feign' in root.lower() or 'client' in root.lower():
                for file in files:
                    if file.endswith('.java'):
                        file_path = os.path.join(root, file)
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                content = f.read()
                            
                            if '@FeignClient' in content:
                                client_info = self._parse_feign_client(content, file_path)
                                if client_info:
                                    feign_clients.append(client_info)
                        except Exception as e:
                            logger.warning(f"âš ï¸ è§£æFeign Clientå¤±è´¥ {file_path}: {e}")
        
        return feign_clients
    
    def _parse_feign_client(self, content: str, file_path: str) -> Optional[Dict[str, any]]:
        """è§£æFeign Clientä¿¡æ¯"""
        # æå–ç±»å
        class_match = re.search(r'public\s+interface\s+(\w+)', content)
        if not class_match:
            return None
        
        class_name = class_match.group(1)
        
        # æå–@FeignClientæ³¨è§£ä¿¡æ¯
        feign_annotation = re.search(r'@FeignClient\s*\([^)]*\)', content)
        feign_config = feign_annotation.group(0) if feign_annotation else ""
        
        # æå–æ–¹æ³•ç­¾å
        methods = re.findall(r'@\w+Mapping\s*\([^)]*\)\s*[^;]+;', content)
        
        return {
            'class_name': class_name,
            'file_path': file_path,
            'feign_config': feign_config,
            'methods': methods,
            'business_domain': self._extract_business_domain_from_class(class_name)
        }
    
    def _calculate_feign_client_similarity(self, client: Dict[str, any], 
                                         domain_keywords: List[str], api_path: str) -> float:
        """è®¡ç®—Feign Clientç›¸ä¼¼åº¦"""
        score = 0.0
        
        client_name = client['class_name'].lower()
        business_domain = client.get('business_domain', '').lower()
        
        # å…³é”®å­—åŒ¹é…
        for keyword in domain_keywords:
            keyword_lower = keyword.lower()
            if keyword_lower in client_name:
                score += 0.3
            if keyword_lower in business_domain:
                score += 0.2
        
        # è·¯å¾„åŒ¹é…
        for keyword in domain_keywords:
            if keyword.lower() in api_path.lower():
                score += 0.1
        
        return min(score, 1.0)
    
    def _generate_reuse_recommendation(self, client: Dict[str, any], similarity_score: float) -> str:
        """ç”Ÿæˆå¤ç”¨å»ºè®®"""
        if similarity_score > 0.8:
            return f"å¼ºçƒˆæ¨èå¤ç”¨ {client['class_name']}ï¼Œä¸šåŠ¡åŸŸé«˜åº¦åŒ¹é…"
        elif similarity_score > 0.6:
            return f"æ¨èå¤ç”¨ {client['class_name']}ï¼Œéœ€è¦é€‚å½“è°ƒæ•´"
        else:
            return f"å¯ä»¥è€ƒè™‘å¤ç”¨ {client['class_name']}ï¼Œä½†éœ€è¦ä»”ç»†è¯„ä¼°"
    
    def _identify_similar_patterns(self, interface_name: str, existing_methods: List[Dict], 
                                 new_interface_type: str) -> List[Dict[str, any]]:
        """è¯†åˆ«ç›¸ä¼¼çš„æ¥å£æ¨¡å¼"""
        similar_patterns = []
        
        for method in existing_methods:
            method_name = method.get('method_name', '')
            method_type = method.get('method_type', '')
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›¸ä¼¼çš„æ“ä½œ
            if self._is_similar_operation(method_type, new_interface_type):
                similar_patterns.append({
                    'method': method,
                    'similarity_reason': f"{method_type} ä¸ {new_interface_type} æ“ä½œç›¸ä¼¼",
                    'reuse_potential': self._calculate_reuse_potential(method, new_interface_type)
                })
        
        return similar_patterns
    
    def _is_similar_operation(self, existing_type: str, new_type: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯ç›¸ä¼¼çš„æ“ä½œ"""
        # æŸ¥è¯¢å’Œå¯¼å‡ºæ˜¯ç›¸ä¼¼çš„æ“ä½œï¼ˆå¯¼å‡ºé€šå¸¸åŸºäºæŸ¥è¯¢ï¼‰
        if existing_type == 'query_list' and new_type == 'export_list':
            return True
        elif existing_type == 'export_list' and new_type == 'query_list':
            return True
        elif existing_type == new_type:
            return True
        
        # å…¶ä»–ç›¸ä¼¼æ“ä½œç»„
        similar_groups = [
            ['create', 'add', 'insert'],
            ['update', 'modify', 'edit'],
            ['delete', 'remove']
        ]
        
        for group in similar_groups:
            if existing_type in group and new_type in group:
                return True
        
        return False
    
    def _calculate_reuse_potential(self, method: Dict[str, any], new_interface_type: str) -> float:
        """è®¡ç®—å¤ç”¨æ½œåŠ›"""
        # åŸºäºæ–¹æ³•ç±»å‹å’Œä¸šåŠ¡é€»è¾‘è®¡ç®—å¤ç”¨æ½œåŠ›
        if new_interface_type == 'export_list' and method.get('method_type') == 'query_list':
            return 0.9  # å¯¼å‡ºå’ŒæŸ¥è¯¢çš„å¤ç”¨æ½œåŠ›å¾ˆé«˜
        elif method.get('method_type') == new_interface_type:
            return 0.8  # ç›¸åŒç±»å‹çš„å¤ç”¨æ½œåŠ›é«˜
        else:
            return 0.3  # å…¶ä»–æƒ…å†µå¤ç”¨æ½œåŠ›è¾ƒä½
    
    def _generate_merge_strategy(self, similar_patterns: List[Dict[str, any]], 
                               new_interface_type: str) -> Dict[str, any]:
        """ç”Ÿæˆåˆå¹¶ç­–ç•¥"""
        if not similar_patterns:
            return {'strategy': 'create_new', 'reason': 'æ— ç›¸ä¼¼æ¨¡å¼'}
        
        best_pattern = max(similar_patterns, key=lambda x: x['reuse_potential'])
        
        if best_pattern['reuse_potential'] > 0.8:
            return {
                'strategy': 'reuse_and_extend',
                'base_method': best_pattern['method'],
                'extension_type': new_interface_type,
                'shared_logic': 'extract_common_data_access',
                'specific_logic': f'add_{new_interface_type}_specific_handling'
            }
        else:
            return {
                'strategy': 'create_similar',
                'reference_method': best_pattern['method'],
                'similarity_level': best_pattern['reuse_potential']
            }
    
    def _extract_shared_logic(self, similar_patterns: List[Dict[str, any]]) -> Dict[str, any]:
        """æå–å…±äº«é€»è¾‘"""
        if not similar_patterns:
            return {}
        
        # åˆ†æå…±åŒçš„æ•°æ®è®¿é—®æ¨¡å¼
        common_data_access = []
        common_parameters = []
        
        for pattern in similar_patterns:
            method = pattern['method']
            # æå–æ•°æ®è®¿é—®é€»è¾‘
            if 'feign_call' in method:
                common_data_access.append(method['feign_call'])
            # æå–å‚æ•°æ¨¡å¼
            if 'parameters' in method:
                common_parameters.extend(method['parameters'])
        
        return {
            'data_access_patterns': list(set(common_data_access)),
            'parameter_patterns': list(set(common_parameters)),
            'shared_method_name': 'getData'
        }
    
    def _get_special_handling(self, interface_type: str) -> Dict[str, any]:
        """è·å–ç‰¹æ®Šå¤„ç†é€»è¾‘"""
        special_handling = {
            'export_list': {
                'additional_dependencies': ['ExcelExportService'],
                'additional_imports': [
                    'import org.springframework.http.MediaType;',
                    'import org.springframework.http.HttpHeaders;',
                    'import java.time.LocalDateTime;',
                    'import java.time.format.DateTimeFormatter;'
                ],
                'response_type': 'ResponseEntity<byte[]>',
                'additional_logic': 'excel_generation'
            },
            'query_list': {
                'response_type': 'ResponseEntity<List<Map<String, Object>>>',
                'additional_logic': 'pagination_support'
            }
        }
        
        return special_handling.get(interface_type, {})
    
    def _classify_method_type(self, method_name: str) -> str:
        """åˆ†ç±»æ–¹æ³•ç±»å‹"""
        method_lower = method_name.lower()
        
        # æ£€æŸ¥å¯¼å‡ºç±»å‹ï¼ˆä¼˜å…ˆæ£€æŸ¥ï¼Œé¿å…è¢«å…¶ä»–å…³é”®å­—å¹²æ‰°ï¼‰
        if any(keyword in method_lower for keyword in ['export', 'download']):
            return 'export_list'
        elif any(keyword in method_lower for keyword in ['list', 'query', 'search', 'find']):
            return 'query_list'
        elif any(keyword in method_lower for keyword in ['create', 'add', 'insert']):
            return 'create'
        elif any(keyword in method_lower for keyword in ['update', 'modify', 'edit']):
            return 'update'
        elif any(keyword in method_lower for keyword in ['delete', 'remove']):
            return 'delete'
        else:
            return 'other'
    
    def _extract_business_operation(self, method_name: str) -> str:
        """æå–ä¸šåŠ¡æ“ä½œ"""
        # ç§»é™¤å¸¸è§çš„å‰ç¼€å’Œåç¼€
        clean_name = method_name
        for prefix in ['get', 'query', 'list', 'find', 'search', 'export']:
            if clean_name.lower().startswith(prefix):
                clean_name = clean_name[len(prefix):]
                break
        
        return clean_name
    
    def _extract_business_domain_from_class(self, class_name: str) -> str:
        """ä»ç±»åæå–ä¸šåŠ¡åŸŸ"""
        # ç§»é™¤å¸¸è§çš„åç¼€
        clean_name = class_name
        suffixes = ['FeignClient', 'Client', 'Service', 'Controller', 'Mapper', 'Repository']
        for suffix in suffixes:
            if clean_name.endswith(suffix):
                clean_name = clean_name[:-len(suffix)]
                break
        
        return clean_name
    
    def _generate_excel_columns(self, base_method: Dict[str, any]) -> str:
        """ç”ŸæˆExcelåˆ—é…ç½®"""
        # è¿™é‡Œåº”è¯¥æ ¹æ®å®é™…çš„æ•°æ®ç»“æ„ç”Ÿæˆåˆ—é…ç½®
        return 'Arrays.asList("åˆ—1", "åˆ—2", "åˆ—3")'
    
    def _analyze_method_signature(self, method: Dict[str, any]) -> Dict[str, any]:
        """åˆ†ææ–¹æ³•ç­¾å"""
        method_name = method.get('name', method.get('method_name', ''))
        
        # ç›´æ¥ä½¿ç”¨æ–¹æ³•åä½œä¸ºåŸºç¡€åç§°
        base_name = method_name
        
        return {
            'base_name': base_name,
            'original_name': method_name,
            'parameters': method.get('parameters', []),
            'return_type': method.get('return_type', 'Object')
        }
    
    def _generate_shared_logic(self, method_signature: Dict[str, any], 
                             interface_variants: List[str]) -> str:
        """ç”Ÿæˆå…±äº«é€»è¾‘"""
        base_name = method_signature['base_name']
        
        return f"""
        // å…±äº«çš„æ•°æ®è·å–é€»è¾‘
        try {{
            // è°ƒç”¨Feign Clientæˆ–Serviceè·å–æ•°æ®
            List<Map<String, Object>> data = feignClient.{base_name}(params);
            
            // é€šç”¨æ•°æ®å¤„ç†é€»è¾‘
            if (data == null || data.isEmpty()) {{
                return new ArrayList<>();
            }}
            
            return data;
        }} catch (Exception e) {{
            logger.error("è·å–{base_name}æ•°æ®å¤±è´¥", e);
            throw new RuntimeException("æ•°æ®è·å–å¤±è´¥", e);
        }}
        """
    
    def _generate_variant_handler(self, variant: str, method_signature: Dict[str, any]) -> Dict[str, any]:
        """ç”Ÿæˆå˜ä½“å¤„ç†å™¨"""
        base_name = method_signature['base_name']
        
        if variant == 'export':
            return {
                'method_name': f"{base_name}Export",
                'mapping': '@GetMapping("/export")',
                'return_type': 'ResponseEntity<byte[]>',
                'logic': f'ä½¿ç”¨{base_name}Data()è·å–æ•°æ®ï¼Œç„¶åç”ŸæˆExcelæ–‡ä»¶'
            }
        elif variant == 'query':
            return {
                'method_name': f"{base_name}List",
                'mapping': '@GetMapping("/list")',
                'return_type': 'ResponseEntity<List<Map<String, Object>>>',
                'logic': f'ç›´æ¥è¿”å›{base_name}Data()è·å–çš„æ•°æ®'
            }
        else:
            return {
                'method_name': f"{base_name}{variant.capitalize()}",
                'mapping': f'@GetMapping("/{variant}")',
                'return_type': 'ResponseEntity<Object>',
                'logic': f'åŸºäº{base_name}Data()å®ç°{variant}é€»è¾‘'
            }
    
    def _build_shared_method_signature(self, method_signature: Dict[str, any]) -> str:
        """æ„å»ºå…±äº«æ–¹æ³•ç­¾å"""
        base_name = method_signature['base_name']
        return f"private List<Map<String, Object>> {base_name}Data(Map<String, Object> params)"
    
    def _extract_method_dependencies(self, method: Dict[str, any]) -> List[str]:
        """æå–æ–¹æ³•ä¾èµ–"""
        dependencies = []
        
        # åŸºç¡€ä¾èµ–
        dependencies.extend([
            'logger',
            'feignClient'
        ])
        
        # æ ¹æ®æ–¹æ³•ç±»å‹æ·»åŠ ç‰¹å®šä¾èµ–
        method_type = method.get('method_type', '')
        if method_type == 'export_list':
            dependencies.append('excelExportService')
        
        return dependencies
    
    def _is_component_already_injected(self, content: str, class_name: str) -> bool:
        """æ£€æŸ¥ç»„ä»¶æ˜¯å¦å·²ç»æ³¨å…¥"""
        return class_name in content
    
    def _inject_feign_client(self, content: str, client: Dict[str, any]) -> str:
        """æ³¨å…¥Feign Client"""
        class_name = client['class_name']
        variable_name = client.get('variable_name', class_name.lower())
        
        # æŸ¥æ‰¾ç±»çš„å¼€å§‹ä½ç½®
        class_start = content.find('public class')
        if class_start == -1:
            return content
        
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå­—æ®µæˆ–æ–¹æ³•çš„ä½ç½®
        injection_point = content.find('{', class_start) + 1
        
        # æ·»åŠ Feign Clientæ³¨å…¥
        injection_code = f"""
    
    @Autowired
    private {class_name} {variable_name};
"""
        
        return content[:injection_point] + injection_code + content[injection_point:]
    
    def _add_shared_method(self, content: str, method: Dict[str, any]) -> str:
        """æ·»åŠ å…±äº«æ–¹æ³•"""
        # åœ¨ç±»çš„ç»“å°¾å‰æ·»åŠ æ–¹æ³•
        last_brace = content.rfind('}')
        if last_brace == -1:
            return content
        
        method_code = method.get('code', '')
        return content[:last_brace] + f"\n{method_code}\n" + content[last_brace:]
    
    def _add_export_method(self, content: str, method: Dict[str, any]) -> str:
        """æ·»åŠ å¯¼å‡ºæ–¹æ³•"""
        return self._add_shared_method(content, method)
    
    def _add_required_imports(self, content: str, reuse_plan: Dict[str, any]) -> str:
        """æ·»åŠ å¿…è¦çš„import"""
        required_imports = []
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¯¼å‡ºç›¸å…³çš„import
        if 'export_methods' in reuse_plan:
            required_imports.extend([
                'import org.springframework.http.MediaType;',
                'import org.springframework.http.HttpHeaders;',
                'import java.time.LocalDateTime;',
                'import java.time.format.DateTimeFormatter;'
            ])
        
        # æŸ¥æ‰¾packageå£°æ˜çš„ä½ç½®
        package_end = content.find(';', content.find('package')) + 1
        if package_end == -1:
            return content
        
        # æ·»åŠ import
        for import_stmt in required_imports:
            if import_stmt not in content:
                content = content[:package_end] + f"\n{import_stmt}" + content[package_end:]
        
        return content
    
    def _get_timestamp(self) -> str:
        """è·å–æ—¶é—´æˆ³"""
        import datetime
        return datetime.datetime.now().isoformat()
    
    def _build_shared_method_signature(self, method_signature: Dict[str, any]) -> str:
        """æ„å»ºå…±äº«æ–¹æ³•ç­¾å"""
        base_name = method_signature['base_name']
        return f"private List<Map<String, Object>> {base_name}Data(Map<String, Object> params)"
    
    def _generate_variant_handler(self, variant: str, method_signature: Dict[str, any]) -> Dict[str, any]:
        """ç”Ÿæˆå˜ä½“å¤„ç†å™¨"""
        base_name = method_signature['base_name']
        
        if variant == 'query':
            return {
                'type': 'query',
                'method_name': f"{base_name}",
                'description': f"æŸ¥è¯¢{base_name}æ¥å£"
            }
        elif variant == 'export':
            return {
                'type': 'export',
                'method_name': f"{base_name}Export",
                'description': f"å¯¼å‡º{base_name}æ¥å£"
            }
        else:
            return {
                'type': 'other',
                'method_name': f"{base_name}",
                'description': f"å¤„ç†{base_name}æ¥å£"
            }
    
    def _extract_method_dependencies(self, base_method: Dict[str, any]) -> Dict[str, any]:
        """æå–æ–¹æ³•ä¾èµ–"""
        return {
            'logger': 'private static final Logger logger = LoggerFactory.getLogger(this.getClass());',
            'feignClient': 'Feign Client dependency',
            'excelService': 'Excel service dependency for export operations'
        }