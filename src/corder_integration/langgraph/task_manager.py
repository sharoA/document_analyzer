#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»»åŠ¡ç®¡ç†å·¥å…· - ç”¨äºå„ä¸ªèŠ‚ç‚¹é¢†å–å’Œæ›´æ–°ä»»åŠ¡çŠ¶æ€
"""

import sqlite3
import json
import logging
import time
import os
from pathlib import Path
from typing import Dict, Any, List

logger = logging.getLogger(__name__)

class NodeTaskManager:
    """èŠ‚ç‚¹ä»»åŠ¡ç®¡ç†å™¨ - ä¸“é—¨ç”¨äºèŠ‚ç‚¹ä»»åŠ¡æ“ä½œ"""
    
    def __init__(self, db_path: str = None):
        # ğŸ”§ ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œé¿å…ç›¸å¯¹è·¯å¾„é—®é¢˜
        if db_path is None:
            # ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„æ•°æ®åº“æ–‡ä»¶
            project_root = Path(__file__).parent.parent.parent.parent  # å›åˆ°é¡¹ç›®æ ¹ç›®å½•
            db_path = project_root / "coding_agent_workflow.db"
        
        self.db_path = str(db_path)
        self.max_retries = 3
        self.retry_delay = 1.0
        
        # ğŸ”§ ç¡®ä¿æ•°æ®åº“æ–‡ä»¶å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»º
        if not os.path.exists(self.db_path):
            logger.info(f"ğŸ“‹ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†è‡ªåŠ¨åˆ›å»º: {self.db_path}")
            # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
            # åˆ›å»ºç©ºçš„æ•°æ®åº“æ–‡ä»¶ï¼ˆSQLiteä¼šè‡ªåŠ¨åˆ›å»ºï¼‰
            try:
                conn = sqlite3.connect(self.db_path)
                conn.close()
                logger.info(f"âœ… æ•°æ®åº“æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {self.db_path}")
            except Exception as e:
                logger.error(f"âŒ åˆ›å»ºæ•°æ®åº“æ–‡ä»¶å¤±è´¥: {e}")
                raise e
        
        logger.info(f"ğŸ“‚ ä½¿ç”¨æ•°æ®åº“: {self.db_path}")
    
    def _get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        conn = sqlite3.connect(
            self.db_path, 
            timeout=30.0,
            isolation_level=None
        )
        conn.execute("PRAGMA synchronous=NORMAL") 
        conn.execute("PRAGMA cache_size=10000")
        conn.execute("PRAGMA temp_store=memory")
        return conn
    
    def _execute_with_retry(self, operation_func, *args, **kwargs):
        """å¸¦é‡è¯•æœºåˆ¶çš„æ•°æ®åº“æ“ä½œ"""
        last_error = None
        
        for attempt in range(self.max_retries):
            try:
                return operation_func(*args, **kwargs)
            except sqlite3.OperationalError as e:
                last_error = e
                if "database is locked" in str(e):
                    logger.warning(f"ğŸ”„ æ•°æ®åº“é”å®šï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯•...")
                    time.sleep(self.retry_delay * (2 ** attempt))
                    continue
                else:
                    raise e
            except Exception as e:
                logger.error(f"âŒ æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
                raise e
        
        logger.error(f"âŒ æ•°æ®åº“æ“ä½œé‡è¯•{self.max_retries}æ¬¡åä»ç„¶å¤±è´¥: {last_error}")
        raise last_error
    
    def get_node_tasks(self, task_types: List[str], project_task_id: str = None) -> List[Dict[str, Any]]:
        """è·å–æŒ‡å®šç±»å‹çš„å¯æ‰§è¡Œä»»åŠ¡ï¼ˆæ£€æŸ¥ä¾èµ–å…³ç³»ï¼‰ï¼Œå¯æŒ‰é¡¹ç›®IDè¿‡æ»¤"""
        def _get_operation():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # ğŸ†• ç¡®ä¿è¡¨ç»“æ„å­˜åœ¨ï¼ˆé˜²æ­¢æ—§æ•°æ®åº“æ²¡æœ‰project_task_idåˆ—ï¼‰
                try:
                    cursor.execute("SELECT project_task_id FROM execution_tasks LIMIT 1")
                except Exception:
                    # åˆ—ä¸å­˜åœ¨ï¼Œæ·»åŠ å®ƒ
                    logger.info("ğŸ”§ åœ¨æŸ¥è¯¢å‰æ·»åŠ project_task_idåˆ—...")
                    cursor.execute("ALTER TABLE execution_tasks ADD COLUMN project_task_id TEXT")
                
                # æ„å»ºæŸ¥è¯¢æ¡ä»¶
                task_type_placeholders = ','.join(['?' for _ in task_types])
                
                # æ ¹æ®æ˜¯å¦æä¾›project_task_idå†³å®šæŸ¥è¯¢æ¡ä»¶
                if project_task_id:
                    where_clause = f"WHERE task_type IN ({task_type_placeholders}) AND project_task_id = ? AND status != 'expired'"
                    query_params = task_types + [project_task_id]
                else:
                    where_clause = f"WHERE task_type IN ({task_type_placeholders}) AND status != 'expired'"
                    query_params = task_types
                
                cursor.execute(f"""
                    SELECT task_id, project_task_id, service_name, task_type, priority, dependencies,
                           estimated_duration, description, deliverables,
                           implementation_details, completion_criteria, parameters,
                           status
                    FROM execution_tasks 
                    {where_clause}
                    ORDER BY priority ASC, created_at ASC
                """, query_params)
                
                all_tasks = []
                executable_tasks = []
                
                for row in cursor.fetchall():
                    # å®‰å…¨è§£æJSONå­—æ®µ
                    def safe_json_loads(json_str, default_value):
                        try:
                            if not json_str:
                                return default_value
                            return json.loads(json_str)
                        except json.JSONDecodeError as e:
                            logger.warning(f"âš ï¸ JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
                            return default_value
                    
                    task = {
                        'task_id': row[0],
                        'project_task_id': row[1],  # ğŸ†• é¡¹ç›®å”¯ä¸€æ ‡è¯†
                        'service_name': row[2],
                        'task_type': row[3],
                        'priority': row[4],
                        'dependencies': safe_json_loads(row[5], []),
                        'estimated_duration': row[6],
                        'description': row[7],
                        'deliverables': safe_json_loads(row[8], []),
                        'implementation_details': row[9],
                        'completion_criteria': row[10],
                        'parameters': safe_json_loads(row[11], {}),
                        'status': row[12]
                    }
                    all_tasks.append(task)
                
                # è·å–æ‰€æœ‰å·²å®Œæˆçš„ä»»åŠ¡IDï¼ˆæŒ‰é¡¹ç›®è¿‡æ»¤ï¼‰
                if project_task_id:
                    cursor.execute("SELECT task_id FROM execution_tasks WHERE status = 'completed' AND project_task_id = ?", [project_task_id])
                else:
                    cursor.execute("SELECT task_id FROM execution_tasks WHERE status = 'completed'")
                completed_task_ids = set(row[0] for row in cursor.fetchall())
                
                # æ£€æŸ¥ä¾èµ–å…³ç³»ï¼Œç­›é€‰å¯æ‰§è¡Œä»»åŠ¡ - ä½¿ç”¨å¤šè½®æ£€æŸ¥ç¡®ä¿é¡ºåºæ— å…³æ€§
                pending_tasks = [t for t in all_tasks if t['status'] == 'pending']
                
                while True:
                    newly_executable_found_this_round = False
                    remaining_pending = []
                    
                    for task in pending_tasks:
                        dependencies = task.get('dependencies', [])
                        
                        # æ£€æŸ¥æ‰€æœ‰ä¾èµ–æ˜¯å¦å·²å®Œæˆ (completed_task_ids åŒ…å«å·²å®Œæˆå’Œæœ¬è½®åˆšè¯†åˆ«ä¸ºå¯æ‰§è¡Œçš„ä»»åŠ¡)
                        all_deps_met = all(dep_id in completed_task_ids for dep_id in dependencies)
                        
                        if all_deps_met:
                            executable_tasks.append(task)
                            completed_task_ids.add(task['task_id']) # å…³é”®ï¼šå°†æ–°è¯†åˆ«çš„ä»»åŠ¡ä¹Ÿè§†ä¸ºâ€œå·²å®Œæˆâ€ï¼Œä¾›åç»­ä¾èµ–æ£€æŸ¥
                            newly_executable_found_this_round = True
                        else:
                            remaining_pending.append(task)
                    
                    # å¦‚æœæœ¬è½®æ²¡æœ‰å‘ç°æ–°çš„å¯æ‰§è¡Œä»»åŠ¡ï¼Œæˆ–è€…å¾…å¤„ç†ä»»åŠ¡å·²ç©ºï¼Œåˆ™ç»“æŸå¾ªç¯
                    if not newly_executable_found_this_round or not remaining_pending:
                        break
                    
                    # æ›´æ–°å¾…å¤„ç†ä»»åŠ¡åˆ—è¡¨ï¼Œå‡†å¤‡ä¸‹ä¸€è½®æ£€æŸ¥
                    pending_tasks = remaining_pending
                
                return executable_tasks
        
        try:
            return self._execute_with_retry(_get_operation)
        except Exception as e:
            logger.error(f"âŒ è·å–èŠ‚ç‚¹ä»»åŠ¡å¤±è´¥: {e}")
            return []
    
    def claim_task(self, task_id: str, node_name: str) -> bool:
        """é¢†å–ä»»åŠ¡ï¼ˆå°†çŠ¶æ€è®¾ç½®ä¸ºin_progressï¼‰"""
        def _claim_operation():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦ä»ä¸ºpendingçŠ¶æ€
                cursor.execute("SELECT status FROM execution_tasks WHERE task_id = ?", (task_id,))
                result = cursor.fetchone()
                
                if not result:
                    logger.warning(f"âš ï¸ ä»»åŠ¡ {task_id} ä¸å­˜åœ¨")
                    return False
                
                if result[0] != 'pending':
                    logger.warning(f"âš ï¸ ä»»åŠ¡ {task_id} çŠ¶æ€ä¸º {result[0]}ï¼Œæ— æ³•é¢†å–")
                    return False
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºin_progress
                cursor.execute("""
                    UPDATE execution_tasks 
                    SET status = 'in_progress', 
                        updated_at = CURRENT_TIMESTAMP
                    WHERE task_id = ?
                """, (task_id,))
                
                logger.info(f"âœ… ä»»åŠ¡ {task_id} å·²è¢« {node_name} é¢†å–")
                return True
        
        try:
            return self._execute_with_retry(_claim_operation)
        except Exception as e:
            logger.error(f"âŒ é¢†å–ä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def update_task_status(self, task_id: str, status: str, result_data: Dict[str, Any] = None) -> bool:
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        def _update_operation():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # å‡†å¤‡æ›´æ–°æ•°æ®
                update_params = [status]
                update_sql = "UPDATE execution_tasks SET status = ?, updated_at = CURRENT_TIMESTAMP"
                
                # å¦‚æœæœ‰ç»“æœæ•°æ®ï¼Œæ›´æ–°parameterså­—æ®µ
                if result_data:
                    # è·å–å½“å‰å‚æ•°
                    cursor.execute("SELECT parameters FROM execution_tasks WHERE task_id = ?", (task_id,))
                    result = cursor.fetchone()
                    
                    if result:
                        try:
                            current_params = json.loads(result[0] or '{}')
                        except json.JSONDecodeError as e:
                            logger.warning(f"âš ï¸ è§£æç°æœ‰å‚æ•°å¤±è´¥ï¼Œä½¿ç”¨ç©ºå­—å…¸: {e}")
                            current_params = {}
                        
                        # åˆå¹¶ç»“æœæ•°æ®
                        current_params.update(result_data)
                        
                        update_sql += ", parameters = ?"
                        update_params.append(json.dumps(current_params))
                
                update_sql += " WHERE task_id = ?"
                update_params.append(task_id)
                
                cursor.execute(update_sql, update_params)
                
                if cursor.rowcount > 0:
                    logger.info(f"âœ… ä»»åŠ¡ {task_id} çŠ¶æ€æ›´æ–°ä¸º {status}")
                    return True
                else:
                    logger.warning(f"âš ï¸ ä»»åŠ¡ {task_id} çŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œä»»åŠ¡ä¸å­˜åœ¨")
                    return False
        
        try:
            return self._execute_with_retry(_update_operation)
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def get_task_statistics(self) -> Dict[str, int]:
        """è·å–ä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        def _stats_operation():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    SELECT status, COUNT(*) 
                    FROM execution_tasks 
                    GROUP BY status
                """)
                
                stats = {}
                for row in cursor.fetchall():
                    stats[row[0]] = row[1]
                
                return stats
        
        try:
            return self._execute_with_retry(_stats_operation)
        except Exception as e:
            logger.error(f"âŒ è·å–ä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {e}")
            return {}

    
    def _save_single_task(self, task_data: Dict[str, Any]) -> bool:
        """ä¿å­˜å•ä¸ªä»»åŠ¡åˆ°æ•°æ®åº“"""
        def _save_operation():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # ç¡®ä¿execution_tasksè¡¨å­˜åœ¨ï¼Œå¹¶æ·»åŠ project_task_idåˆ—
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS execution_tasks (
                        task_id TEXT PRIMARY KEY,
                        project_task_id TEXT,  -- ğŸ†• é¡¹ç›®å”¯ä¸€æ ‡è¯†
                        service_name TEXT NOT NULL,
                        task_type TEXT NOT NULL,
                        priority INTEGER DEFAULT 0,
                        dependencies TEXT DEFAULT '[]',
                        estimated_duration INTEGER DEFAULT 0,
                        description TEXT,
                        deliverables TEXT DEFAULT '[]',
                        implementation_details TEXT,
                        completion_criteria TEXT,
                        parameters TEXT DEFAULT '{}',
                        status TEXT DEFAULT 'pending',
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # ğŸ†• æ£€æŸ¥å¹¶æ·»åŠ project_task_idåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                try:
                    cursor.execute("SELECT project_task_id FROM execution_tasks LIMIT 1")
                except Exception:
                    # åˆ—ä¸å­˜åœ¨ï¼Œæ·»åŠ å®ƒ
                    logger.info("ğŸ”§ æ·»åŠ project_task_idåˆ—åˆ°ç°æœ‰è¡¨...")
                    cursor.execute("ALTER TABLE execution_tasks ADD COLUMN project_task_id TEXT")
                
                # æ’å…¥ä»»åŠ¡
                cursor.execute("""
                    INSERT OR REPLACE INTO execution_tasks (
                        task_id, project_task_id, service_name, task_type, priority, dependencies,
                        estimated_duration, description, deliverables,
                        implementation_details, completion_criteria, parameters, status
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    task_data['task_id'],
                    task_data.get('project_task_id'),  # ğŸ†• é¡¹ç›®å”¯ä¸€æ ‡è¯†
                    task_data['service_name'],
                    task_data['task_type'],
                    task_data['priority'],
                    json.dumps(task_data['dependencies']),
                    task_data['estimated_duration'],
                    task_data['description'],
                    json.dumps(task_data['deliverables']),
                    task_data['implementation_details'],
                    task_data['completion_criteria'],
                    json.dumps(task_data['parameters']),
                    task_data['status']
                ))
                
                return True
        
        try:
            return self._execute_with_retry(_save_operation)
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ä»»åŠ¡å¤±è´¥: {e}")
            return False 