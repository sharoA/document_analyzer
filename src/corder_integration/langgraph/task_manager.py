#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
‰ªªÂä°ÁÆ°ÁêÜÂ∑•ÂÖ∑ - Áî®‰∫éÂêÑ‰∏™ËäÇÁÇπÈ¢ÜÂèñÂíåÊõ¥Êñ∞‰ªªÂä°Áä∂ÊÄÅ
"""

import sqlite3
import json
import logging
import time
import os
from pathlib import Path
from typing import Dict, Any, List

logger = logging.getLogger(__name__)

class NodeTaskManager:
    """ËäÇÁÇπ‰ªªÂä°ÁÆ°ÁêÜÂô® - ‰∏ìÈó®Áî®‰∫éËäÇÁÇπ‰ªªÂä°Êìç‰Ωú"""
    
    def __init__(self, db_path: str = None):
        # üîß ‰ΩøÁî®ÁªùÂØπË∑ØÂæÑÔºåÈÅøÂÖçÁõ∏ÂØπË∑ØÂæÑÈóÆÈ¢ò
        if db_path is None:
            # ‰ΩøÁî®È°πÁõÆÊ†πÁõÆÂΩïÁöÑÊï∞ÊçÆÂ∫ìÊñá‰ª∂
            project_root = Path(__file__).parent.parent.parent.parent  # ÂõûÂà∞È°πÁõÆÊ†πÁõÆÂΩï
            db_path = project_root / "coding_agent_workflow.db"
        
        self.db_path = str(db_path)
        self.max_retries = 3
        self.retry_delay = 1.0
        
        # Á°Æ‰øùÊï∞ÊçÆÂ∫ìÊñá‰ª∂Â≠òÂú®
        if not os.path.exists(self.db_path):
            logger.error(f"‚ùå Êï∞ÊçÆÂ∫ìÊñá‰ª∂‰∏çÂ≠òÂú®: {self.db_path}")
            raise FileNotFoundError(f"Êï∞ÊçÆÂ∫ìÊñá‰ª∂‰∏çÂ≠òÂú®: {self.db_path}")
        
        logger.info(f"üìÇ ‰ΩøÁî®Êï∞ÊçÆÂ∫ì: {self.db_path}")
    
    def _get_connection(self):
        """Ëé∑ÂèñÊï∞ÊçÆÂ∫ìËøûÊé•"""
        conn = sqlite3.connect(
            self.db_path, 
            timeout=30.0,
            isolation_level=None
        )
        conn.execute("PRAGMA synchronous=NORMAL") 
        conn.execute("PRAGMA cache_size=10000")
        conn.execute("PRAGMA temp_store=memory")
        return conn
    
    def _execute_with_retry(self, operation_func, *args, **kwargs):
        """Â∏¶ÈáçËØïÊú∫Âà∂ÁöÑÊï∞ÊçÆÂ∫ìÊìç‰Ωú"""
        last_error = None
        
        for attempt in range(self.max_retries):
            try:
                return operation_func(*args, **kwargs)
            except sqlite3.OperationalError as e:
                last_error = e
                if "database is locked" in str(e):
                    logger.warning(f"üîÑ Êï∞ÊçÆÂ∫ìÈîÅÂÆöÔºåÁ¨¨{attempt + 1}Ê¨°ÈáçËØï...")
                    time.sleep(self.retry_delay * (2 ** attempt))
                    continue
                else:
                    raise e
            except Exception as e:
                logger.error(f"‚ùå Êï∞ÊçÆÂ∫ìÊìç‰ΩúÂ§±Ë¥•: {e}")
                raise e
        
        logger.error(f"‚ùå Êï∞ÊçÆÂ∫ìÊìç‰ΩúÈáçËØï{self.max_retries}Ê¨°Âêé‰ªçÁÑ∂Â§±Ë¥•: {last_error}")
        raise last_error
    
    def get_node_tasks(self, task_types: List[str]) -> List[Dict[str, Any]]:
        """Ëé∑ÂèñÊåáÂÆöÁ±ªÂûãÁöÑÂèØÊâßË°å‰ªªÂä°ÔºàÊ£ÄÊü•‰æùËµñÂÖ≥Á≥ªÔºâ"""
        def _get_operation():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # ÊûÑÂª∫Êü•ËØ¢Êù°‰ª∂
                task_type_placeholders = ','.join(['?' for _ in task_types])
                
                cursor.execute(f"""
                    SELECT task_id, service_name, task_type, priority, dependencies,
                           estimated_duration, description, deliverables,
                           implementation_details, completion_criteria, parameters,
                           status
                    FROM execution_tasks 
                    WHERE task_type IN ({task_type_placeholders})
                    ORDER BY priority ASC, created_at ASC
                """, task_types)
                
                all_tasks = []
                executable_tasks = []
                
                for row in cursor.fetchall():
                    # ÂÆâÂÖ®Ëß£ÊûêJSONÂ≠óÊÆµ
                    def safe_json_loads(json_str, default_value):
                        try:
                            if not json_str:
                                return default_value
                            return json.loads(json_str)
                        except json.JSONDecodeError as e:
                            logger.warning(f"‚ö†Ô∏è JSONËß£ÊûêÂ§±Ë¥•Ôºå‰ΩøÁî®ÈªòËÆ§ÂÄº: {e}")
                            return default_value
                    
                    task = {
                        'task_id': row[0],
                        'service_name': row[1],
                        'task_type': row[2],
                        'priority': row[3],
                        'dependencies': safe_json_loads(row[4], []),
                        'estimated_duration': row[5],
                        'description': row[6],
                        'deliverables': safe_json_loads(row[7], []),
                        'implementation_details': row[8],
                        'completion_criteria': row[9],
                        'parameters': safe_json_loads(row[10], {}),
                        'status': row[11]
                    }
                    all_tasks.append(task)
                
                # Ëé∑ÂèñÊâÄÊúâÂ∑≤ÂÆåÊàêÁöÑ‰ªªÂä°ID
                cursor.execute("SELECT task_id FROM execution_tasks WHERE status = 'completed'")
                completed_task_ids = set(row[0] for row in cursor.fetchall())
                
                # Ê£ÄÊü•‰æùËµñÂÖ≥Á≥ªÔºåÁ≠õÈÄâÂèØÊâßË°å‰ªªÂä°
                for task in all_tasks:
                    if task['status'] == 'pending':
                        # Ê£ÄÊü•ÊâÄÊúâ‰æùËµñÊòØÂê¶Â∑≤ÂÆåÊàê
                        dependencies = task['dependencies']
                        if not dependencies:  # Ê≤°Êúâ‰æùËµñÁöÑ‰ªªÂä°ÂèØ‰ª•Áõ¥Êé•ÊâßË°å
                            executable_tasks.append(task)
                        else:
                            # Êúâ‰æùËµñÁöÑ‰ªªÂä°ÔºåÊ£ÄÊü•‰æùËµñÊòØÂê¶ÈÉΩÂ∑≤ÂÆåÊàê
                            dependencies_met = all(dep_id in completed_task_ids for dep_id in dependencies)
                            if dependencies_met:
                                executable_tasks.append(task)
                
                return executable_tasks
        
        try:
            return self._execute_with_retry(_get_operation)
        except Exception as e:
            logger.error(f"‚ùå Ëé∑ÂèñËäÇÁÇπ‰ªªÂä°Â§±Ë¥•: {e}")
            return []
    
    def claim_task(self, task_id: str, node_name: str) -> bool:
        """È¢ÜÂèñ‰ªªÂä°ÔºàÂ∞ÜÁä∂ÊÄÅËÆæÁΩÆ‰∏∫in_progressÔºâ"""
        def _claim_operation():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # Ê£ÄÊü•‰ªªÂä°ÊòØÂê¶‰ªç‰∏∫pendingÁä∂ÊÄÅ
                cursor.execute("SELECT status FROM execution_tasks WHERE task_id = ?", (task_id,))
                result = cursor.fetchone()
                
                if not result:
                    logger.warning(f"‚ö†Ô∏è ‰ªªÂä° {task_id} ‰∏çÂ≠òÂú®")
                    return False
                
                if result[0] != 'pending':
                    logger.warning(f"‚ö†Ô∏è ‰ªªÂä° {task_id} Áä∂ÊÄÅ‰∏∫ {result[0]}ÔºåÊó†Ê≥ïÈ¢ÜÂèñ")
                    return False
                
                # Êõ¥Êñ∞‰ªªÂä°Áä∂ÊÄÅ‰∏∫in_progress
                cursor.execute("""
                    UPDATE execution_tasks 
                    SET status = 'in_progress', 
                        updated_at = CURRENT_TIMESTAMP
                    WHERE task_id = ?
                """, (task_id,))
                
                logger.info(f"‚úÖ ‰ªªÂä° {task_id} Â∑≤Ë¢´ {node_name} È¢ÜÂèñ")
                return True
        
        try:
            return self._execute_with_retry(_claim_operation)
        except Exception as e:
            logger.error(f"‚ùå È¢ÜÂèñ‰ªªÂä°Â§±Ë¥•: {e}")
            return False
    
    def update_task_status(self, task_id: str, status: str, result_data: Dict[str, Any] = None) -> bool:
        """Êõ¥Êñ∞‰ªªÂä°Áä∂ÊÄÅ"""
        def _update_operation():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # ÂáÜÂ§áÊõ¥Êñ∞Êï∞ÊçÆ
                update_params = [status]
                update_sql = "UPDATE execution_tasks SET status = ?, updated_at = CURRENT_TIMESTAMP"
                
                # Â¶ÇÊûúÊúâÁªìÊûúÊï∞ÊçÆÔºåÊõ¥Êñ∞parametersÂ≠óÊÆµ
                if result_data:
                    # Ëé∑ÂèñÂΩìÂâçÂèÇÊï∞
                    cursor.execute("SELECT parameters FROM execution_tasks WHERE task_id = ?", (task_id,))
                    result = cursor.fetchone()
                    
                    if result:
                        try:
                            current_params = json.loads(result[0] or '{}')
                        except json.JSONDecodeError as e:
                            logger.warning(f"‚ö†Ô∏è Ëß£ÊûêÁé∞ÊúâÂèÇÊï∞Â§±Ë¥•Ôºå‰ΩøÁî®Á©∫Â≠óÂÖ∏: {e}")
                            current_params = {}
                        
                        # ÂêàÂπ∂ÁªìÊûúÊï∞ÊçÆ
                        current_params.update(result_data)
                        
                        update_sql += ", parameters = ?"
                        update_params.append(json.dumps(current_params))
                
                update_sql += " WHERE task_id = ?"
                update_params.append(task_id)
                
                cursor.execute(update_sql, update_params)
                
                if cursor.rowcount > 0:
                    logger.info(f"‚úÖ ‰ªªÂä° {task_id} Áä∂ÊÄÅÊõ¥Êñ∞‰∏∫ {status}")
                    return True
                else:
                    logger.warning(f"‚ö†Ô∏è ‰ªªÂä° {task_id} Áä∂ÊÄÅÊõ¥Êñ∞Â§±Ë¥•Ôºå‰ªªÂä°‰∏çÂ≠òÂú®")
                    return False
        
        try:
            return self._execute_with_retry(_update_operation)
        except Exception as e:
            logger.error(f"‚ùå Êõ¥Êñ∞‰ªªÂä°Áä∂ÊÄÅÂ§±Ë¥•: {e}")
            return False
    
    def get_task_statistics(self) -> Dict[str, int]:
        """Ëé∑Âèñ‰ªªÂä°ÁªüËÆ°‰ø°ÊÅØ"""
        def _stats_operation():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    SELECT status, COUNT(*) 
                    FROM execution_tasks 
                    GROUP BY status
                """)
                
                stats = {}
                for row in cursor.fetchall():
                    stats[row[0]] = row[1]
                
                return stats
        
        try:
            return self._execute_with_retry(_stats_operation)
        except Exception as e:
            logger.error(f"‚ùå Ëé∑Âèñ‰ªªÂä°ÁªüËÆ°Â§±Ë¥•: {e}")
            return {}
    
    def _save_single_task(self, task_data: Dict[str, Any]) -> bool:
        """‰øùÂ≠òÂçï‰∏™‰ªªÂä°Âà∞Êï∞ÊçÆÂ∫ì"""
        def _save_operation():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # Á°Æ‰øùexecution_tasksË°®Â≠òÂú®
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS execution_tasks (
                        task_id TEXT PRIMARY KEY,
                        service_name TEXT NOT NULL,
                        task_type TEXT NOT NULL,
                        priority INTEGER DEFAULT 0,
                        dependencies TEXT DEFAULT '[]',
                        estimated_duration INTEGER DEFAULT 0,
                        description TEXT,
                        deliverables TEXT DEFAULT '[]',
                        implementation_details TEXT,
                        completion_criteria TEXT,
                        parameters TEXT DEFAULT '{}',
                        status TEXT DEFAULT 'pending',
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # ÊèíÂÖ•‰ªªÂä°
                cursor.execute("""
                    INSERT OR REPLACE INTO execution_tasks (
                        task_id, service_name, task_type, priority, dependencies,
                        estimated_duration, description, deliverables,
                        implementation_details, completion_criteria, parameters, status
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    task_data['task_id'],
                    task_data['service_name'],
                    task_data['task_type'],
                    task_data['priority'],
                    json.dumps(task_data['dependencies']),
                    task_data['estimated_duration'],
                    task_data['description'],
                    json.dumps(task_data['deliverables']),
                    task_data['implementation_details'],
                    task_data['completion_criteria'],
                    json.dumps(task_data['parameters']),
                    task_data['status']
                ))
                
                return True
        
        try:
            return self._execute_with_retry(_save_operation)
        except Exception as e:
            logger.error(f"‚ùå ‰øùÂ≠ò‰ªªÂä°Â§±Ë¥•: {e}")
            return False 