#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆä»»åŠ¡æ‹†åˆ†èŠ‚ç‚¹ - ä½¿ç”¨ç«å±±å¼•æ“LLMå°†è®¾è®¡æ–‡æ¡£æ‹†è§£æˆSQLæ ¼å¼çš„æ‰§è¡Œä»»åŠ¡
"""

import logging
import json
import re
import uuid
import yaml
import os
from datetime import datetime
from typing import Dict, Any, List, Optional

# å¯¼å…¥LLMå®¢æˆ·ç«¯
from src.utils.volcengine_client import VolcengineClient, VolcengineConfig

logger = logging.getLogger(__name__)

class TaskSimpleSplittingNode:
    """ç®€åŒ–ç‰ˆä»»åŠ¡æ‹†åˆ†èŠ‚ç‚¹ - ä½¿ç”¨LLMæ™ºèƒ½è§£æ"""
    
    def __init__(self):
        self.task_types = [
            'git_extraction',   # æå–Gitåœ°å€
            'git_clone',        # ä¸‹è½½ä»£ç   
            'code_analysis',    # åˆ†æç»“æ„
            'config',           # é…ç½®ç¯å¢ƒ
            'database',         # å»ºè¡¨
            'api',              # å¼€å‘æ¥å£
            'integration_test', # é›†æˆæµ‹è¯•
            'deployment'        # ä»£ç æäº¤
        ]
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self.llm_client = None
        self.llm_provider = None
        self._init_llm_client()
        
    def _init_llm_client(self):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        config = {}
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„é…ç½®æ–‡ä»¶è·¯å¾„
        config_paths = [
            'config.yaml',
            os.path.join(os.getcwd(), 'config.yaml'),
            os.path.join(os.path.dirname(os.path.abspath(__file__)), '../../../config.yaml'),
            '/Users/renyu/Documents/ai_project/document_analyzer/config.yaml'
        ]
        
        config_loaded = False
        for config_path in config_paths:
            try:
                if os.path.exists(config_path):
                    with open(config_path, 'r', encoding='utf-8') as f:
                        config = yaml.safe_load(f) or {}
                    logger.info(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
                    config_loaded = True
                    break
            except Exception as e:
                logger.warning(f"âš ï¸ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥ {config_path}: {e}")
        
        if not config_loaded:
            logger.error(f"âŒ æ‰€æœ‰é…ç½®æ–‡ä»¶è·¯å¾„éƒ½åŠ è½½å¤±è´¥: {config_paths}")
        
        # ä¼˜å…ˆä½¿ç”¨ç«å±±å¼•æ“
        if config and config.get('volcengine', {}).get('api_key'):
            try:
                volcengine_config = VolcengineConfig(
                    api_key=config['volcengine']['api_key'],
                    model_id=config['volcengine']['model'],
                    base_url=config['volcengine']['endpoint'],
                    temperature=config['volcengine'].get('temperature', 0.1),
                    max_tokens=config['volcengine'].get('max_tokens', 4000)
                )
                self.llm_client = VolcengineClient(volcengine_config)
                self.llm_provider = "volcengine"
                logger.info(f"âœ… ä½¿ç”¨ç«å±±å¼•æ“LLMå®¢æˆ·ç«¯ï¼š{config['volcengine']['model']}")
            except Exception as e:
                logger.error(f"âŒ ç«å±±å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # æœ€ç»ˆæ£€æŸ¥
        if not self.llm_client:
            logger.error("âŒ LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼å°†ä½¿ç”¨è§„åˆ™åŒ–è§£æ")
            self.llm_provider = "none"
        else:
            logger.info(f"âœ… LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {self.llm_provider}")
        
    def __call__(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """èŠ‚ç‚¹ä¸»å…¥å£"""
        logger.info("ğŸš€ å¼€å§‹ç®€åŒ–ç‰ˆä»»åŠ¡æ‹†åˆ†")
        
        try:
            # è·å–è®¾è®¡æ–‡æ¡£
            design_doc = state.get('design_doc', '')
            project_name = state.get('project_name', 'default_project')
            
            logger.info(f"ğŸ“„ è®¾è®¡æ–‡æ¡£é•¿åº¦: {len(design_doc)}")
            logger.info(f"ğŸ“‹ é¡¹ç›®åç§°: {project_name}")
            
            # æ™ºèƒ½è§£æè®¾è®¡æ–‡æ¡£
            if self.llm_client:
                parsed_info = self._llm_parse_design_document(design_doc)
            else:
                parsed_info = self._rule_parse_design_document(design_doc)
            
            # ç”Ÿæˆä»»åŠ¡åºåˆ—
            tasks = self._generate_task_sequence(parsed_info, project_name)
            
            # ç”ŸæˆSQLæ–‡ä»¶
            sql_content = self._generate_sql_content(tasks)
            output_file = self._save_sql_file(sql_content, project_name)
            
            logger.info(f"âœ… ä»»åŠ¡æ‹†åˆ†å®Œæˆï¼Œç”Ÿæˆ {len(tasks)} ä¸ªä»»åŠ¡")
            logger.info(f"ğŸ“ SQLæ–‡ä»¶ä¿å­˜åˆ°: {output_file}")
            
            # åŒæ—¶ä¿å­˜åˆ°SQLiteæ•°æ®åº“ç”¨äºå·¥ä½œæµ
            self._save_to_database(tasks)
            
            return {
                'identified_services': parsed_info.get('services', []),
                'service_dependencies': parsed_info.get('dependencies', {}),
                'task_execution_plan': {'total_tasks': len(tasks), 'sql_file': output_file},
                'parallel_tasks': [{'task_id': task['task_id'], 'task_type': task['task_type']} for task in tasks]
            }
            
        except Exception as e:
            logger.error(f"âŒ ä»»åŠ¡æ‹†åˆ†å¤±è´¥: {e}")
            return {
                'identified_services': [],
                'service_dependencies': {},
                'task_execution_plan': {},
                'parallel_tasks': []
            }
    
    def _llm_parse_design_document(self, design_doc: str) -> Dict[str, Any]:
        """ä½¿ç”¨LLMæ™ºèƒ½è§£æè®¾è®¡æ–‡æ¡£"""
        logger.info("ğŸ¤– ä½¿ç”¨LLMæ™ºèƒ½è§£æè®¾è®¡æ–‡æ¡£...")
        
        # ä½¿ç”¨å¢å¼ºç‰ˆJinja2é£æ ¼çš„ç»“æ„åŒ–æç¤ºè¯æ¨¡æ¿ï¼ˆåŸºäºä½ çš„ä¿®æ”¹ä¼˜åŒ–ï¼‰
        prompt = f"""ä½ æ˜¯ä»»åŠ¡ç®¡ç†ä¸“å®¶ï¼ŒåŸºäºè®¾è®¡æ–‡æ¡£ç”Ÿæˆå…·ä½“çš„å¼€å‘ä»»åŠ¡ä¿¡æ¯ã€‚

è®¾è®¡æ–‡æ¡£å†…å®¹ï¼š
{design_doc}

**é‡è¦çº¦æŸï¼šä¸¥æ ¼ä½¿ç”¨è®¾è®¡æ–‡æ¡£ä¸­çš„çœŸå®å†…å®¹ï¼Œç¦æ­¢ç¼–é€ ã€‚**

**è®¾è®¡æ–‡æ¡£å…³é”®ä¿¡æ¯å‚è€ƒï¼ˆJinja2æ¨¡æ¿é£æ ¼ï¼‰ï¼š**
- GitLabä»“åº“ï¼šç”¨æˆ·æœåŠ¡ http://localhost:30000/ls/zqyl-user-center-service.gitï¼Œç¡®æƒå¼€ç«‹æœåŠ¡ http://localhost:30000/ls/crcl-open.git
- æ¥å£è·¯å¾„ï¼š/general/multiorgManage/queryCompanyUnitListï¼Œ/crcl-open-api/lsLimit/listUnitLimitByCompanyIdï¼Œ/crcl-open-api/lsLimit/listUnitLimitByCompanyIdExport
- è¡¨åï¼št_cust_multiorg_unit
- æ•°æ®åº“ï¼šjdbc:mysql://localhost:6446/dbwebappdbï¼Œç”¨æˆ·åå¯†ç ï¼šdbwebapp/dbwebapp

è¯·ä»¥JSONæ ¼å¼è¿”å›ä»¥ä¸‹ä¿¡æ¯ï¼š

{{
    "services": [
        {{
            "name": "æœåŠ¡åç§°ï¼ˆå¦‚ï¼šç”¨æˆ·æœåŠ¡ã€ç¡®æƒå¼€ç«‹æœåŠ¡ï¼‰",
            "description": "æœåŠ¡åŠŸèƒ½æè¿°",
            "git_repository": "Gitä»“åº“å®Œæ•´åœ°å€",
            "controller_name": "ä¸»è¦æ§åˆ¶å™¨åç§°",
            "repo_name": "ä»“åº“ç›®å½•å"
        }}
    ],
    "git_repositories": [
        "http://localhost:30000/ls/zqyl-user-center-service.git",
        "http://localhost:30000/ls/crcl-open.git"
    ],
    "apis": [
        {{
            "path": "å®Œæ•´APIè·¯å¾„",
            "method": "HTTPæ–¹æ³•ï¼ˆGET/POSTï¼‰",
            "service": "æ‰€å±æœåŠ¡åç§°",
            "description": "æ¥å£åŠŸèƒ½æè¿°",
            "request_params": {{
                "å‚æ•°å1": "å‚æ•°è¯´æ˜(å¿…å¡«/å¯é€‰)",
                "å‚æ•°å2": "å‚æ•°è¯´æ˜(å¿…å¡«/å¯é€‰)"
            }},
            "response_params": {{
                "å­—æ®µå1": "å­—æ®µè¯´æ˜",
                "å­—æ®µå2": "å­—æ®µè¯´æ˜"
            }},
            "business_logic": "è¯¦ç»†çš„ä¸šåŠ¡é€»è¾‘æè¿°",
            "data_source": "æ•°æ®æ¥æºå’Œè·å–æ–¹å¼",
            "content_type": "æ•°æ®æ ¼å¼ï¼ˆapplication/jsonæˆ–å…¶ä»–ï¼‰",
            "validation_rules": {{
                "å‚æ•°å1": "æ ¡éªŒè§„åˆ™æè¿°",
                "å‚æ•°å2": "æ ¡éªŒè§„åˆ™æè¿°"
            }},
            "dependencies": ["ä¾èµ–çš„å…¶ä»–æ¥å£è·¯å¾„"]
        }}
    ],
    "databases": [
        {{
            "table_name": "t_cust_multiorg_unit",
            "database_url": "jdbc:mysql://localhost:6446/dbwebappdb",
            "username": "dbwebapp", 
            "password": "dbwebapp",
            "description": "è¡¨åŠŸèƒ½æè¿°",
            "fields": ["ä¸»è¦å­—æ®µåˆ—è¡¨"]
        }}
    ],
    "service_dependencies": {{
        "ç¡®æƒå¼€ç«‹æœåŠ¡": ["ç”¨æˆ·æœåŠ¡"]
    }},
    "technical_stack": ["Spring Boot", "MySQL", "Feign", "MyBatis"],
    "main_features": ["ä¸»è¦åŠŸèƒ½ç‰¹æ€§æè¿°"]
}}

**APIå‚æ•°è¯¦ç»†ç»“æ„ç¤ºä¾‹ï¼ˆæŒ‰ç…§ä½ çš„ä¿®æ”¹è§„èŒƒï¼‰ï¼š**
å¯¹äºå¯¼å‡ºç±»æ¥å£ï¼Œåº”åŒ…å«ï¼š
- project_path: é¡¹ç›®è·¯å¾„
- api_path: APIå®Œæ•´è·¯å¾„  
- http_method: HTTPæ–¹æ³•
- content_type: å†…å®¹ç±»å‹ï¼ˆç‰¹åˆ«æ˜¯Excelå¯¼å‡ºçš„application/vnd.openxmlformats-officedocument.spreadsheetml.sheetï¼‰
- request_params: è¯·æ±‚å‚æ•°è¯¦ç»†è¯´æ˜
- response_params: å“åº”å‚æ•°è¯¦ç»†è¯´æ˜
- business_logic: ä¸šåŠ¡é€»è¾‘æè¿°
- data_source: æ•°æ®æ¥æºè¯´æ˜
- export_format: å¯¼å‡ºæ ¼å¼ï¼ˆå¦‚xlsxï¼‰
- export_headers: å¯¼å‡ºè¡¨å¤´
- validation_rules: å‚æ•°æ ¡éªŒè§„åˆ™

**å¿…é¡»ä¸¥æ ¼æŒ‰ç…§æ–‡æ¡£å†…å®¹æå–ï¼š**
1. çœŸå®çš„GitLabä»“åº“åœ°å€ï¼ˆç«¯å£30000ï¼‰
2. å…·ä½“çš„APIæ¥å£è·¯å¾„ï¼ˆä¸‰ä¸ªæ¥å£ï¼‰
3. æ•°æ®åº“è¿æ¥ä¿¡æ¯ï¼ˆlocalhost:6446ï¼‰
4. è¡¨åt_cust_multiorg_unit
5. æœåŠ¡é—´è°ƒç”¨å…³ç³»ï¼ˆç¡®æƒå¼€ç«‹æœåŠ¡è°ƒç”¨ç”¨æˆ·æœåŠ¡ï¼‰
6. æœåŠ¡åˆ’åˆ†ä¸¥æ ¼æŒ‰ç…§æ–‡æ¡£å†…å®¹ï¼Œä¸è¦åˆå¹¶æˆ–æ‹†åˆ†æœåŠ¡
7. å…³æ³¨æ¥å£ç‰¹æ®Šè¦æ±‚ä¸­çš„ä¾èµ–å…³ç³»æè¿°

**è¾“å‡ºè¦æ±‚ï¼š**
- åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦å…¶ä»–è§£é‡Šæ–‡å­—
- ä¸¥æ ¼ä½¿ç”¨æ–‡æ¡£ä¸­çš„çœŸå®URLå’Œè·¯å¾„
- APIsæ•°ç»„ä¸­æ¯ä¸ªæ¥å£éƒ½è¦åŒ…å«å®Œæ•´çš„å‚æ•°ç»“æ„
- ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„ä¿¡æ¯"""
        
        try:
            response = self.llm_client.chat(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ç³»ç»Ÿæ¶æ„ä¸“å®¶ï¼Œä¸“é—¨åˆ†æè½¯ä»¶è®¾è®¡æ–‡æ¡£ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§Jinja2æ¨¡æ¿é£æ ¼æå–ä¿¡æ¯ï¼Œä¸è¦ç¼–é€ ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=4000  # å¢åŠ tokené™åˆ¶ä»¥æ”¯æŒæ›´è¯¦ç»†çš„APIå‚æ•°ç»“æ„
            )
            
            # æå–JSONå†…å®¹
            json_str = self._extract_json_from_response(response)
            parsed_info = json.loads(json_str)
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼Œå…¼å®¹æ–°çš„è¯¦ç»†ç»“æ„åŒ–è¾“å‡º
            standardized_info = {
                # æœåŠ¡ä¿¡æ¯å¤„ç†ï¼ˆæ”¯æŒæ–°çš„è¯¦ç»†ç»“æ„ï¼‰
                'services': [service['name'] if isinstance(service, dict) else service for service in parsed_info.get('services', [])],
                'git_repositories': parsed_info.get('git_repositories', []),
                
                # APIä¿¡æ¯å¤„ç†ï¼ˆæ”¯æŒæ–°çš„è¯¦ç»†å‚æ•°ç»“æ„ï¼‰
                'apis': [api.get('path', api) if isinstance(api, dict) else api for api in parsed_info.get('apis', [])], 
                
                # æ•°æ®åº“ä¿¡æ¯å¤„ç†ï¼ˆæ”¯æŒæ–°çš„è¯¦ç»†ç»“æ„ï¼‰
                'databases': [db.get('table_name', db) if isinstance(db, dict) else db for db in parsed_info.get('databases', [])],
                
                'dependencies': parsed_info.get('service_dependencies', {}),
                'technical_stack': parsed_info.get('technical_stack', []),
                'main_features': parsed_info.get('main_features', []),
                
                # ä¿å­˜è¯¦ç»†ä¿¡æ¯ç”¨äºåç»­ä»»åŠ¡ç”Ÿæˆ
                'detailed_services': parsed_info.get('services', []),
                'detailed_apis': parsed_info.get('apis', []),
                'detailed_databases': parsed_info.get('databases', [])
            }
            
            logger.info(f"âœ… ä¼˜åŒ–ç‰ˆLLMè§£æå®Œæˆ - æœåŠ¡: {len(standardized_info.get('services', []))}, API: {len(standardized_info.get('apis', []))}")
            logger.info(f"ğŸ“‹ è¯†åˆ«çš„æœåŠ¡: {standardized_info.get('services', [])}")
            logger.info(f"ğŸ”— Gitä»“åº“: {len(standardized_info.get('git_repositories', []))}ä¸ª")
            logger.info(f"ğŸŒ APIè¯¦æƒ…: {len(standardized_info.get('detailed_apis', []))}ä¸ªæ¥å£åŒ…å«å®Œæ•´å‚æ•°")
            
            return standardized_info
            
        except Exception as e:
            logger.error(f"âŒ ä¼˜åŒ–ç‰ˆLLMè§£æå¤±è´¥: {e}")
            # å›é€€åˆ°è§„åˆ™åŒ–è§£æ
            return self._rule_parse_design_document(design_doc)
    
    def _extract_json_from_response(self, response: str) -> str:
        """ä»LLMå“åº”ä¸­æå–JSONå†…å®¹"""
        # æŸ¥æ‰¾JSONä»£ç å—
        json_patterns = [
            r'```json\s*(\{.*?\})\s*```',
            r'```\s*(\{.*?\})\s*```',
            r'(\{.*?\})'
        ]
        
        for pattern in json_patterns:
            match = re.search(pattern, response, re.DOTALL)
            if match:
                return match.group(1).strip()
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œè¿”å›æ•´ä¸ªå“åº”
        return response.strip()
    
    def _rule_parse_design_document(self, design_doc: str) -> Dict[str, Any]:
        """è§„åˆ™åŒ–è§£æè®¾è®¡æ–‡æ¡£ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        logger.info("ğŸ“‹ ä½¿ç”¨è§„åˆ™åŒ–æ–¹å¼è§£æè®¾è®¡æ–‡æ¡£...")
        
        parsed_info = {
            'services': [],
            'git_repositories': [],
            'apis': [],
            'databases': [],
            'dependencies': {}
        }
        
        # ğŸ”§ ä¼˜åŒ–æœåŠ¡åç§°æå–
        service_patterns = [
            r'(ç”¨æˆ·æœåŠ¡|ç¡®æƒå¼€ç«‹æœåŠ¡)',  # ç›´æ¥åŒ¹é…æ ¸å¿ƒæœåŠ¡
            r'æœåŠ¡[:ï¼š]\s*(zqyl-user-center-service|crcl-open)',  # æ˜ç¡®çš„æœåŠ¡å
        ]
        
        found_services = set()
        for pattern in service_patterns:
            matches = re.findall(pattern, design_doc, re.IGNORECASE)
            for match in matches:
                service_name = match if isinstance(match, str) else match[-1]
                if service_name and len(service_name) > 2:
                    found_services.add(service_name.strip())
        
        # æ ‡å‡†åŒ–æœåŠ¡åç§°
        standardized_services = []
        for service in found_services:
            if 'user' in service.lower() or 'ç”¨æˆ·' in service:
                if 'ç”¨æˆ·æœåŠ¡' not in standardized_services:
                    standardized_services.append('ç”¨æˆ·æœåŠ¡')
            elif 'crcl' in service.lower() or 'ç¡®æƒ' in service or 'å¼€ç«‹' in service:
                if 'ç¡®æƒå¼€ç«‹æœåŠ¡' not in standardized_services:
                    standardized_services.append('ç¡®æƒå¼€ç«‹æœåŠ¡')
        
        # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°æ ‡å‡†æœåŠ¡ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not standardized_services:
            standardized_services = ['ç”¨æˆ·æœåŠ¡', 'ç¡®æƒå¼€ç«‹æœåŠ¡']
        
        parsed_info['services'] = standardized_services
        
        # æå–Gitä»“åº“åœ°å€
        git_patterns = [
            r'http[s]?://[^\s]+\.git',
            r'git@[^\s]+\.git',
        ]
        
        for pattern in git_patterns:
            matches = re.findall(pattern, design_doc)
            for match in matches:
                if match and match not in parsed_info['git_repositories']:
                    parsed_info['git_repositories'].append(match)
        
        # æå–APIæ¥å£
        api_patterns = [
            r'GET\s+(/[^\s\[\]]+)',
            r'POST\s+(/[^\s\[\]]+)',
            r'æ¥å£[:ï¼š]\s*(/[^\s\[\]]+)',
            r'(/[\w\-]+/[\w\-]+/[\w\-]+)',
        ]
        
        found_apis = set()
        for pattern in api_patterns:
            matches = re.findall(pattern, design_doc)
            for match in matches:
                if match and match.startswith('/') and len(match) > 5:
                    found_apis.add(match)
        
        parsed_info['apis'] = list(found_apis)
        
        logger.info(f"âœ… è§„åˆ™è§£æå®Œæˆ - æœåŠ¡: {len(parsed_info['services'])}, API: {len(parsed_info['apis'])}")
        return parsed_info
    
    def _generate_task_sequence(self, parsed_info: Dict[str, Any], project_name: str) -> List[Dict[str, Any]]:
        """ç”Ÿæˆä»»åŠ¡åºåˆ—"""
        logger.info("ğŸ”„ å¼€å§‹ç”Ÿæˆä»»åŠ¡åºåˆ—...")
        
        tasks = []
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        base_path = f"/Users/renyu/Documents/create_project/{project_name}"
        
        services = parsed_info.get('services', ['ç”¨æˆ·æœåŠ¡', 'ç¡®æƒå¼€ç«‹æœåŠ¡'])
        if not services:
            services = ['ç”¨æˆ·æœåŠ¡', 'ç¡®æƒå¼€ç«‹æœåŠ¡']  # é»˜è®¤æœåŠ¡
        
        task_counter = 1
        
        # 1. git_extraction - ç³»ç»Ÿçº§ä»»åŠ¡
        tasks.append({
            'task_id': f'task_{task_counter:03d}',
            'service_name': 'ç³»ç»Ÿ',
            'task_type': 'git_extraction',
            'priority': task_counter,
            'status': 'pending',
            'dependencies': '[]',
            'estimated_duration': '5åˆ†é’Ÿ',
            'description': 'ä»è®¾è®¡æ–‡æ¡£æå–GitLabä»“åº“åœ°å€',
            'deliverables': json.dumps(['GitLabä»“åº“åœ°å€æ¸…å•', 'ä»“åº“è®¿é—®éªŒè¯æŠ¥å‘Š'], ensure_ascii=False),
            'implementation_details': f'è§£æè®¾è®¡æ–‡æ¡£ï¼Œæå–ä»“åº“åœ°å€: {", ".join(parsed_info.get("git_repositories", []))}',
            'completion_criteria': 'æˆåŠŸæå–å¹¶éªŒè¯GitLabä»“åº“åœ°å€å¯è®¿é—®æ€§',
            'parameters': json.dumps({
                'repositories': parsed_info.get('git_repositories', []),
                'extraction_method': 'llm_enhanced' if self.llm_client else 'regex_pattern'
            }, ensure_ascii=False),
            'created_at': current_time,
            'updated_at': current_time
        })
        task_counter += 1
        
        # 2. git_clone - ä¸ºæ¯ä¸ªæœåŠ¡ç”Ÿæˆ
        for service in services:
            service_repo = self._get_service_repo_name(service)
            tasks.append({
                'task_id': f'task_{task_counter:03d}',
                'service_name': service,
                'task_type': 'git_clone',
                'priority': task_counter,
                'status': 'pending',
                'dependencies': '["task_001"]',
                'estimated_duration': '10åˆ†é’Ÿ',
                'description': f'ä¸‹è½½{service}ä»£ç åˆ°{base_path}/{service_repo}',
                'deliverables': json.dumps([f'{service}æºç ç›®å½•'], ensure_ascii=False),
                'implementation_details': f'ä½¿ç”¨git cloneå‘½ä»¤ä¸‹è½½{service}ä»£ç åˆ°æŒ‡å®šç›®å½•ï¼Œç¡®ä¿é¡¹ç›®ç»“æ„å®Œæ•´å¯ç¼–è¯‘',
                'completion_criteria': 'ä»£ç ä¸‹è½½å®Œæˆï¼Œé¡¹ç›®ç›®å½•å­˜åœ¨ä¸”åŒ…å«pom.xmlæ–‡ä»¶',
                'parameters': json.dumps({
                    'repo_name': service_repo,
                    'target_path': f'{base_path}/{service_repo}',
                    'branch': 'master'
                }, ensure_ascii=False),
                'created_at': current_time,
                'updated_at': current_time
            })
            task_counter += 1
        
        # 3. code_analysis - ä¸ºæ¯ä¸ªæœåŠ¡ç”Ÿæˆ
        clone_dependencies = [f'task_{i:03d}' for i in range(2, 2 + len(services))]
        for i, service in enumerate(services):
            service_repo = self._get_service_repo_name(service)
            controller_name = self._get_controller_name(service)
            
            tasks.append({
                'task_id': f'task_{task_counter:03d}',
                'service_name': service,
                'task_type': 'code_analysis',
                'priority': task_counter,
                'status': 'pending',
                'dependencies': json.dumps([clone_dependencies[i]]),
                'estimated_duration': '20åˆ†é’Ÿ',
                'description': f'åˆ†æ{service}ä»£ç ç»“æ„ï¼Œç¡®å®š{controller_name}æ·»åŠ ä½ç½®',
                'deliverables': json.dumps(['ä»£ç ç»“æ„ä»Controllerå±‚å¼€å§‹åˆ°æ•°æ®è·å–çš„å®Œæ•´è·¯å¾„'], ensure_ascii=False),
                'implementation_details': f'åˆ†æé¡¹ç›®packageç»“æ„å’Œcontrollerå±‚ï¼Œæ‰¾åˆ°æˆ–åˆ›å»º{controller_name}ç±»çš„æœ€ä½³ä½ç½®',
                'completion_criteria': f'ç¡®å®š{controller_name}çš„åŒ…è·¯å¾„å’Œæ–‡ä»¶ä½ç½®ï¼Œæ˜ç¡®ä¾èµ–çš„Serviceå±‚ç»“æ„',
                'parameters': json.dumps({
                    'project_path': f'{base_path}/{service_repo}',
                    'target_controller': controller_name,
                    'analysis_scope': 'controller,service,mapper'
                }, ensure_ascii=False),
                'created_at': current_time,
                'updated_at': current_time
            })
            task_counter += 1
        
        # 4. config - ä¸ºæ¯ä¸ªæœåŠ¡ç”Ÿæˆæ•°æ®åº“é…ç½®
        analysis_dependencies = [f'task_{i:03d}' for i in range(2 + len(services), 2 + 2*len(services))]
        for i, service in enumerate(services):
            tasks.append({
                'task_id': f'task_{task_counter:03d}',
                'service_name': service,
                'task_type': 'config',
                'priority': task_counter,
                'status': 'pending',
                'dependencies': json.dumps([analysis_dependencies[i]]),
                'estimated_duration': '15åˆ†é’Ÿ',
                'description': f'é…ç½®{service}æ•°æ®åº“è¿æ¥ï¼šjdbc:mysql://localhost:6446/dbwebappdb',
                'deliverables': json.dumps(['æ•°æ®åº“é…ç½®æ–‡ä»¶', 'è¿æ¥æµ‹è¯•æŠ¥å‘Š'], ensure_ascii=False),
                'implementation_details': 'ä¿®æ”¹application.ymlæ–‡ä»¶ï¼Œé…ç½®æ•°æ®åº“è¿æ¥ä¿¡æ¯åŒ…æ‹¬URLã€ç”¨æˆ·åå¯†ç å’Œè¿æ¥æ± è®¾ç½®',
                'completion_criteria': 'application.ymlæ–‡ä»¶å·²æ›´æ–°ï¼Œæ•°æ®åº“è¿æ¥é…ç½®æ­£ç¡®ä¸”å¯è¿é€š',
                'parameters': json.dumps({
                    'database_url': 'jdbc:mysql://localhost:6446/dbwebappdb',
                    'username': 'dbwebapp',
                    'password': 'dbwebapp'
                }, ensure_ascii=False),
                'created_at': current_time,
                'updated_at': current_time
            })
            task_counter += 1
        
        # 5. database - å»ºè¡¨ä»»åŠ¡
        config_dependencies = [f'task_{i:03d}' for i in range(2 + 2*len(services), 2 + 3*len(services))]
        for i, service in enumerate(services):
            table_name = 't_cust_multiorg_unit' if 'ç”¨æˆ·' in service else 't_limit_info'
            
            tasks.append({
                'task_id': f'task_{task_counter:03d}',
                'service_name': service,
                'task_type': 'database',
                'priority': task_counter,
                'status': 'pending',
                'dependencies': json.dumps([config_dependencies[i]]),
                'estimated_duration': '15åˆ†é’Ÿ',
                'description': f'åˆ›å»º{table_name}è¡¨ï¼ŒåŒ…å«ä¸šåŠ¡å­—æ®µå’Œç´¢å¼•',
                'deliverables': json.dumps(['å»ºè¡¨SQLè„šæœ¬', 'Entityå®ä½“ç±»', 'Mapperæ¥å£æ–‡ä»¶'], ensure_ascii=False),
                'implementation_details': 'ç¼–å†™å»ºè¡¨SQLè„šæœ¬ï¼Œå®šä¹‰ä¸»é”®ã€ç´¢å¼•å’Œå­—æ®µçº¦æŸï¼Œåˆ›å»ºå¯¹åº”çš„Entityå’ŒMapperæ–‡ä»¶',
                'completion_criteria': 'è¡¨ç»“æ„åˆ›å»ºæˆåŠŸï¼ŒEntityå’ŒMapperæ–‡ä»¶å¯æ­£å¸¸ç¼–è¯‘ï¼Œæ”¯æŒåŸºæœ¬CRUDæ“ä½œ',
                'parameters': json.dumps({
                    'table_name': table_name,
                    'sql_location': f'src/main/resources/sql/{table_name}.sql'
                }, ensure_ascii=False),
                'created_at': current_time,
                'updated_at': current_time
            })
            task_counter += 1
        
        # 6. api - æ¥å£å¼€å‘ä»»åŠ¡
        database_dependencies = [f'task_{i:03d}' for i in range(2 + 3*len(services), 2 + 4*len(services))]
        apis = parsed_info.get('apis', [])
        if not apis:
            apis = ['/general/multiorgManage/queryCompanyUnitList', 
                   '/crcl-open-api/lsLimit/listUnitLimitByCompanyId',
                   '/crcl-open-api/lsLimit/listUnitLimitByCompanyIdExport']
        
        for i, api in enumerate(apis):
            service = services[i % len(services)]
            dep_task = database_dependencies[i % len(database_dependencies)]
            
            tasks.append({
                'task_id': f'task_{task_counter:03d}',
                'service_name': service,
                'task_type': 'api',
                'priority': task_counter,
                'status': 'pending',
                'dependencies': json.dumps([dep_task]),
                'estimated_duration': '60åˆ†é’Ÿ',
                'description': f'å®ç°GET {api}æ¥å£',
                'deliverables': json.dumps(['Controllerç±»', 'Serviceä¸šåŠ¡é€»è¾‘å±‚', 'æ¥å£æ–‡æ¡£'], ensure_ascii=False),
                'implementation_details': f'åœ¨Controllerä¸­å®ç°{api}æ¥å£ï¼Œæ”¯æŒæ¡ä»¶æŸ¥è¯¢å’Œåˆ†é¡µï¼Œè¿”å›è§„å®šçš„å­—æ®µæ ¼å¼',
                'completion_criteria': 'æ¥å£å¯æ­£å¸¸è®¿é—®ï¼Œè¿”å›æ•°æ®æ ¼å¼ç¬¦åˆè§„èŒƒï¼Œæ”¯æŒæ¡ä»¶æŸ¥è¯¢å’Œåˆ†é¡µåŠŸèƒ½',
                'parameters': json.dumps({
                    'api_path': api,
                    'http_method': 'GET',
                    'content_type': 'application/json'
                }, ensure_ascii=False),
                'created_at': current_time,
                'updated_at': current_time
            })
            task_counter += 1
        
        # 7. integration_test - é›†æˆæµ‹è¯•
        api_dependencies = [f'task_{i:03d}' for i in range(2 + 4*len(services), task_counter)]
        tasks.append({
            'task_id': f'task_{task_counter:03d}',
            'service_name': 'ç³»ç»Ÿ',
            'task_type': 'integration_test',
            'priority': task_counter,
            'status': 'pending',
            'dependencies': json.dumps(api_dependencies),
            'estimated_duration': '30åˆ†é’Ÿ',
            'description': 'æµ‹è¯•æœåŠ¡é—´è°ƒç”¨çš„å®Œæ•´æµç¨‹',
            'deliverables': json.dumps(['é›†æˆæµ‹è¯•ç”¨ä¾‹', 'æµ‹è¯•æ•°æ®è„šæœ¬', 'æµ‹è¯•æŠ¥å‘Š'], ensure_ascii=False),
            'implementation_details': 'ç¼–å†™é›†æˆæµ‹è¯•ç”¨ä¾‹ï¼ŒéªŒè¯æœåŠ¡é—´è°ƒç”¨æ­£ç¡®æ€§å’Œæ•°æ®å®Œæ•´æ€§',
            'completion_criteria': 'æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹é€šè¿‡ï¼Œæ¥å£è°ƒç”¨é“¾è·¯æ­£å¸¸ï¼Œæ•°æ®è¿”å›æ ¼å¼æ­£ç¡®',
            'parameters': json.dumps({
                'test_scenarios': ['ç»„ç»‡å•å…ƒé¢åº¦æŸ¥è¯¢æµ‹è¯•'],
                'test_data': {'gwCompanyId': 1, 'unitName': 'æµ‹è¯•å•å…ƒ', 'bizType': 80}
            }, ensure_ascii=False),
            'created_at': current_time,
            'updated_at': current_time
        })
        task_counter += 1
        
        # 8. deployment - ä»£ç æäº¤
        tasks.append({
            'task_id': f'task_{task_counter:03d}',
            'service_name': 'ç³»ç»Ÿ',
            'task_type': 'deployment',
            'priority': task_counter,
            'status': 'pending',
            'dependencies': json.dumps([f'task_{task_counter-1:03d}']),
            'estimated_duration': '20åˆ†é’Ÿ',
            'description': 'æäº¤ä»£ç åˆ°GitLabä»“åº“ï¼Œcommit message: feat: æ–°å¢ç»„ç»‡å•å…ƒé¢åº¦ç®¡ç†åŠŸèƒ½',
            'deliverables': json.dumps(['Gitæäº¤è®°å½•', 'ä»£ç åˆå¹¶æŠ¥å‘Š', 'éƒ¨ç½²æ–‡æ¡£'], ensure_ascii=False),
            'implementation_details': 'æ‰§è¡Œgit addã€git commitå’Œgit pushå‘½ä»¤ï¼Œæäº¤æ‰€æœ‰æ–°å¢å’Œä¿®æ”¹çš„ä»£ç æ–‡ä»¶',
            'completion_criteria': 'ä»£ç æˆåŠŸæäº¤åˆ°GitLabä»“åº“ï¼Œcommitä¿¡æ¯æ¸…æ™°ï¼Œæ— å†²çª',
            'parameters': json.dumps({
                'repositories': [{'path': f'{base_path}/{self._get_service_repo_name(s)}', 'changes': f'æ–°å¢{s}ç›¸å…³åŠŸèƒ½'} for s in services]
            }, ensure_ascii=False),
            'created_at': current_time,
            'updated_at': current_time
        })
        
        logger.info(f"âœ… ç”Ÿæˆä»»åŠ¡åºåˆ—å®Œæˆï¼Œå…± {len(tasks)} ä¸ªä»»åŠ¡")
        return tasks
    
    def _get_service_repo_name(self, service_name: str) -> str:
        """æ ¹æ®æœåŠ¡åç§°è·å–ä»“åº“å"""
        if 'ç”¨æˆ·' in service_name:
            return 'zqyl-user-center-service'
        elif 'ç¡®æƒ' in service_name or 'å¼€ç«‹' in service_name:
            return 'crcl-open'
        else:
            return service_name.replace('æœåŠ¡', '-service').lower()
    
    def _get_controller_name(self, service_name: str) -> str:
        """æ ¹æ®æœåŠ¡åç§°è·å–Controllerå"""
        if 'ç”¨æˆ·' in service_name:
            return 'MultiorgManageController'
        elif 'ç¡®æƒ' in service_name or 'å¼€ç«‹' in service_name:
            return 'LsLimitController'
        else:
            return f'{service_name.replace("æœåŠ¡", "")}Controller'
    
    def _generate_sql_content(self, tasks: List[Dict[str, Any]]) -> str:
        """ç”ŸæˆSQLæ’å…¥è¯­å¥"""
        logger.info("ğŸ”„ ç”ŸæˆSQLå†…å®¹...")
        
        sql_lines = []
        sql_lines.append("INSERT INTO execution_tasks (task_id,service_name,task_type,priority,status,dependencies,estimated_duration,description,deliverables,implementation_details,completion_criteria,parameters,created_at,updated_at) VALUES")
        
        task_values = []
        for task in tasks:
            # è½¬ä¹‰SQLå­—ç¬¦ä¸²
            def escape_sql_string(s):
                if s is None:
                    return 'NULL'
                return "'" + str(s).replace("'", "''").replace("\\", "\\\\") + "'"
            
            values = [
                escape_sql_string(task['task_id']),
                escape_sql_string(task['service_name']),
                escape_sql_string(task['task_type']),
                str(task['priority']),
                escape_sql_string(task['status']),
                escape_sql_string(task['dependencies']),
                escape_sql_string(task['estimated_duration']),
                escape_sql_string(task['description']),
                escape_sql_string(task['deliverables']),
                escape_sql_string(task['implementation_details']),
                escape_sql_string(task['completion_criteria']),
                escape_sql_string(task['parameters']),
                escape_sql_string(task['created_at']),
                escape_sql_string(task['updated_at'])
            ]
            
            task_values.append(f"\t ({','.join(values)})")
        
        sql_lines.append(',\n'.join(task_values) + ';')
        
        return '\n'.join(sql_lines)
    
    def _save_sql_file(self, sql_content: str, project_name: str) -> str:
        """ä¿å­˜SQLæ–‡ä»¶"""
        timestamp = datetime.now().strftime('%Y%m%d%H%M')
        filename = f"execution_tasks_{timestamp}.sql"
        filepath = f"/Users/renyu/{filename}"
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(sql_content)
            logger.info(f"âœ… SQLæ–‡ä»¶ä¿å­˜æˆåŠŸ: {filepath}")
            return filepath
        except Exception as e:
            logger.error(f"âŒ SQLæ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")
            return ""
    
    def _save_to_database(self, tasks: List[Dict[str, Any]]):
        """ä¿å­˜ä»»åŠ¡åˆ°SQLiteæ•°æ®åº“"""
        try:
            from src.corder_integration.langgraph.task_manager import TaskManager
            task_manager = TaskManager()
            
            for task in tasks:
                task_manager.create_task(
                    task_id=task['task_id'],
                    task_type=task['task_type'],
                    status=task['status'],
                    description=task['description'],
                    parameters=json.loads(task['parameters']),
                    dependencies=json.loads(task['dependencies']),
                    priority=task['priority']
                )
            
            logger.info(f"âœ… ä»»åŠ¡å·²ä¿å­˜åˆ°æ•°æ®åº“ï¼Œå…± {len(tasks)} ä¸ª")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")

# åˆ›å»ºèŠ‚ç‚¹å®ä¾‹
task_simple_splitting_node = TaskSimpleSplittingNode()