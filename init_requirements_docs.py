#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éœ€æ±‚æ–‡æ¡£å‘é‡åŒ–åˆå§‹åŒ–è„šæœ¬
ä¸“é—¨ç”¨äºå¤„ç† /Users/renyu/Documents/knowledge_base/é“¾æ•°_LS/éœ€æ±‚æ–‡æ¡£ ç›®å½•ä¸‹çš„DOCXæ–‡ä»¶
æŒ‰æ ‡é¢˜åˆ†æ®µè¿›è¡Œå‘é‡åŒ–å­˜å‚¨
"""

import os
import re
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime

# æ–‡ä»¶å¤„ç†ç›¸å…³
import docx
from sentence_transformers import SentenceTransformer

# Weaviate å’Œ LangChain
import weaviate
import weaviate.classes as wvc
from langchain.schema import Document

# é¡¹ç›®é…ç½®
try:
    from src.utils.weaviate_helper import get_weaviate_client
except ImportError:
    import sys
    project_root = os.path.dirname(os.path.abspath(__file__))
    sys.path.insert(0, project_root)
    from src.utils.weaviate_helper import get_weaviate_client

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class RequirementsDocsInitializer:
    """éœ€æ±‚æ–‡æ¡£åˆå§‹åŒ–å™¨ - ç®€åŒ–ç‰ˆ"""
    
    def __init__(self, requirements_docs_path: str = "/Users/renyu/Documents/knowledge_base/é“¾æ•°_LS/éœ€æ±‚æ–‡æ¡£"):
        """
        åˆå§‹åŒ–éœ€æ±‚æ–‡æ¡£å¤„ç†å™¨
        
        Args:
            requirements_docs_path: éœ€æ±‚æ–‡æ¡£ç›®å½•è·¯å¾„
        """
        self.requirements_docs_path = Path(requirements_docs_path)
        self.weaviate_client = None
        self.embeddings_model = None
        
        # åªå¤„ç†DOCXæ–‡ä»¶
        self.supported_extensions = {'.docx'}
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._initialize_components()
    
    def _initialize_components(self):
        """åˆå§‹åŒ–å„ç§ç»„ä»¶"""
        try:
            # åˆå§‹åŒ– Weaviate å®¢æˆ·ç«¯
            self.weaviate_client = get_weaviate_client()
            logger.info("âœ… Weaviate å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ - ä½¿ç”¨bge-large-zhï¼ˆ1024ç»´ï¼Œä¸­æ–‡ä¼˜åŒ–ï¼‰
            self.embeddings_model = SentenceTransformer('BAAI/bge-large-zh')
            logger.info("âœ… åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ (bge-large-zh, 1024ç»´ï¼Œä¸­æ–‡ä¼˜åŒ–)")
            
            logger.info("âœ… ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _clear_weaviate_database(self):
        """æ¸…ç©ºWeaviateæ•°æ®åº“ä¸­çš„éœ€æ±‚æ–‡æ¡£æ•°æ®"""
        try:
            logger.info("ğŸ—‘ï¸ å¼€å§‹æ¸…ç©ºéœ€æ±‚æ–‡æ¡£ç›¸å…³æ•°æ®...")
            
            collection_name = "Document"
            if self.weaviate_client.collections.exists(collection_name):
                # åˆ é™¤é¡¹ç›®ä¸ºLSçš„æ–‡æ¡£
                collection = self.weaviate_client.collections.get(collection_name)
                
                # æŸ¥è¯¢æ‰€æœ‰LSé¡¹ç›®çš„æ–‡æ¡£
                results = collection.query.fetch_objects(
                    filters=wvc.query.Filter.by_property("project").equal("LS"),
                    limit=10000
                )
                
                # åˆ é™¤è¿™äº›æ–‡æ¡£
                deleted_count = 0
                for obj in results.objects:
                    try:
                        collection.data.delete_by_id(obj.uuid)
                        deleted_count += 1
                    except Exception as e:
                        logger.warning(f"âš ï¸ åˆ é™¤æ–‡æ¡£å¤±è´¥ {obj.uuid}: {e}")
                
                logger.info(f"âœ… åˆ é™¤äº† {deleted_count} ä¸ªéœ€æ±‚æ–‡æ¡£ç›¸å…³è®°å½•")
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç©ºéœ€æ±‚æ–‡æ¡£æ•°æ®å¤±è´¥: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç»§ç»­æ‰§è¡Œ
    
    def _docx_to_markdown(self, doc, file_path: Path) -> str:
        """å°†DOCXè½¬æ¢ä¸ºMarkdownæ ¼å¼"""
        markdown_content = []
        
        try:
            # å¤„ç†æ®µè½æ–‡æœ¬
            for paragraph in doc.paragraphs:
                text = paragraph.text.strip()
                if not text:
                    continue
                
                # æ£€æµ‹æ ‡é¢˜
                if self._is_heading(paragraph, text):
                    # æ ¹æ®æ ‡é¢˜çº§åˆ«æ·»åŠ markdownæ ‡è®°
                    level = self._get_heading_level(paragraph, text)
                    markdown_content.append(f"{'#' * level} {text}")
                else:
                    # æ™®é€šæ®µè½
                    markdown_content.append(text)
            
            return "\n\n".join(markdown_content)
            
        except Exception as e:
            logger.error(f"DOCXè½¬Markdownå¤±è´¥ {file_path}: {e}")
            return ""
    
    def _is_heading(self, paragraph, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ ‡é¢˜"""
        # æ£€æŸ¥æ®µè½æ ·å¼
        if paragraph.style.name.startswith('Heading'):
            return True
        
        # æ£€æŸ¥æ–‡æœ¬æ ¼å¼ï¼ˆæ•°å­—å¼€å¤´çš„æ ‡é¢˜ï¼‰
        if re.match(r'^\d+\.?\d*\s+', text):
            return True
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºçŸ­æ–‡æœ¬ä¸”å¯èƒ½æ˜¯æ ‡é¢˜
        if len(text) < 100 and any(keyword in text for keyword in [
            'ç³»ç»Ÿ', 'æ¨¡å—', 'åŠŸèƒ½', 'æ¥å£', 'è®¾è®¡', 'æ¶æ„', 'éœ€æ±‚', 'èƒŒæ™¯', 'ç›®æ ‡', 'èŒƒå›´',
            'æµç¨‹', 'æ–¹æ¡ˆ', 'å®ç°', 'æµ‹è¯•', 'éƒ¨ç½²', 'è¿ç»´', 'æ€»ç»“', 'é™„å½•'
        ]):
            return True
        
        return False
    
    def _get_heading_level(self, paragraph, text: str) -> int:
        """è·å–æ ‡é¢˜çº§åˆ«"""
        if paragraph.style.name.startswith('Heading'):
            try:
                return int(paragraph.style.name.replace('Heading ', ''))
            except:
                return 1
        
        # æ ¹æ®æ•°å­—æ ¼å¼åˆ¤æ–­çº§åˆ«
        match = re.match(r'^(\d+)\.?(\d*)\s+', text)
        if match:
            if match.group(2):  # æœ‰äºŒçº§æ•°å­—ï¼Œå¦‚ 3.1
                return 2
            else:  # åªæœ‰ä¸€çº§æ•°å­—ï¼Œå¦‚ 3
                return 1
        
        return 1
    
    def _split_markdown_by_sections(self, markdown_content: str, file_path: Path) -> List[Dict[str, Any]]:
        """æŒ‰æ ‡é¢˜åˆ†å‰²Markdownå†…å®¹"""
        sections = []
        lines = markdown_content.split('\n')
        
        current_section = file_path.stem  # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºé»˜è®¤æ ‡é¢˜
        current_content = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # æ£€æµ‹æ ‡é¢˜è¡Œ
            if line.startswith('#'):
                # ä¿å­˜ä¹‹å‰çš„æ®µè½
                if current_content:
                    sections.append({
                        'section': current_section,
                        'content': '\n'.join(current_content)
                    })
                
                # å¼€å§‹æ–°æ®µè½
                current_section = line.lstrip('#').strip()
                current_content = []
            else:
                # æ™®é€šå†…å®¹
                current_content.append(line)
        
        # å¤„ç†æœ€åä¸€ä¸ªæ®µè½
        if current_content:
            sections.append({
                'section': current_section,
                'content': '\n'.join(current_content)
            })
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ®µè½ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤æ®µè½
        if not sections:
            sections.append({
                'section': file_path.stem,
                'content': markdown_content
            })
        
        return sections
    
    def _process_docx_file(self, file_path: Path) -> List[Document]:
        """å¤„ç† DOCX æ–‡ä»¶ - è¿”å›LangChain Documentå¯¹è±¡"""
        documents = []
        
        try:
            logger.info(f"ğŸ“„ å¤„ç†æ–‡æ¡£: {file_path.name}")
            
            # æ‰“å¼€DOCXæ–‡ä»¶
            try:
                doc = docx.Document(file_path)
            except Exception as docx_error:
                logger.error(f"âŒ æ— æ³•æ‰“å¼€DOCXæ–‡ä»¶ {file_path}: {docx_error}")
                return documents
            
            # å°†DOCXè½¬æ¢ä¸ºMarkdown
            markdown_content = self._docx_to_markdown(doc, file_path)
            
            if not markdown_content:
                logger.warning(f"âš ï¸ æ–‡æ¡£å†…å®¹ä¸ºç©º: {file_path.name}")
                return documents
            
            # æŒ‰æ ‡é¢˜åˆ†å‰²å†…å®¹
            sections = self._split_markdown_by_sections(markdown_content, file_path)
            
            for i, section in enumerate(sections):
                if len(section['content'].strip()) < 20:  # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
                    continue
                    
                # åˆ›å»ºLangChain Documentå¯¹è±¡
                document = Document(
                    page_content=section['content'],
                    metadata={
                        # ç§»é™¤ file_path å…ƒæ•°æ®ï¼Œåªä¿ç•™ file_name
                        'file_name': file_path.name,
                        'project': 'LS',  # å›ºå®šä¸ºLSé¡¹ç›®
                        'file_type': 'docx',
                        'source_type': 'requirement_doc',
                        'title': section['section'],  # ä½¿ç”¨titleå­—æ®µåŒ¹é…é¡¹ç›®æœŸæœ›
                        'chunk_index': i,
                        'total_chunks': len(sections),
                        'created_at': datetime.now().strftime('%Y-%m-%dT%H:%M:%SZ')  # RFC3339æ ¼å¼
                    }
                )
                documents.append(document)
            
            logger.info(f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆ: {file_path.name} ({len(documents)} ä¸ªæ®µè½)")
            
        except Exception as e:
            logger.error(f"âŒ DOCX æ–‡ä»¶å¤„ç†å¤±è´¥ {file_path}: {e}")
        
        return documents
    
    def _create_weaviate_schema(self):
        """åˆ›å»º Weaviate æ¨¡å¼"""
        try:
            collection_name = "Document"
            
            # æ£€æŸ¥é›†åˆæ˜¯å¦å·²å­˜åœ¨
            if self.weaviate_client.collections.exists(collection_name):
                logger.info(f"ğŸ“‹ é›†åˆ {collection_name} å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
                return collection_name
            
            # åˆ›å»ºé›†åˆ
            self.weaviate_client.collections.create(
                name=collection_name,
                vectorizer_config=wvc.config.Configure.Vectorizer.none(),
                properties=[
                    wvc.config.Property(name="content", data_type=wvc.config.DataType.TEXT),
                    # ç§»é™¤ file_path å±æ€§ï¼Œåªä¿ç•™ file_name
                    wvc.config.Property(name="file_name", data_type=wvc.config.DataType.TEXT),
                    wvc.config.Property(name="project", data_type=wvc.config.DataType.TEXT),
                    wvc.config.Property(name="file_type", data_type=wvc.config.DataType.TEXT),
                    wvc.config.Property(name="source_type", data_type=wvc.config.DataType.TEXT),
                    wvc.config.Property(name="title", data_type=wvc.config.DataType.TEXT),
                    wvc.config.Property(name="chunk_index", data_type=wvc.config.DataType.INT),
                    wvc.config.Property(name="total_chunks", data_type=wvc.config.DataType.INT),
                    wvc.config.Property(name="created_at", data_type=wvc.config.DataType.DATE)
                ]
            )
            
            logger.info(f"âœ… Weaviate é›†åˆåˆ›å»ºæˆåŠŸ: {collection_name}")
            return collection_name
            
        except Exception as e:
            logger.error(f"âŒ Weaviate é›†åˆåˆ›å»ºå¤±è´¥: {e}")
            raise
    
    def _insert_documents_batch(self, documents: List[Document], collection_name: str):
        """æ‰¹é‡æ’å…¥æ–‡æ¡£åˆ°Weaviate"""
        try:
            collection = self.weaviate_client.collections.get(collection_name)
            
            # å‡†å¤‡æ‰¹é‡æ’å…¥çš„æ•°æ®
            with collection.batch.dynamic() as batch:
                for doc in documents:
                    # ç”Ÿæˆå‘é‡
                    vector = self.embeddings_model.encode(doc.page_content).tolist()
                    
                    # å‡†å¤‡å…ƒæ•°æ®
                    properties = {
                        "content": doc.page_content,
                        **doc.metadata
                    }
                    
                    # æ·»åŠ åˆ°æ‰¹æ¬¡
                    batch.add_object(
                        properties=properties,
                        vector=vector
                    )
            
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡æ’å…¥æ–‡æ¡£å¤±è´¥: {e}")
            raise
    
    def scan_requirements_docs(self) -> List[Path]:
        """æ‰«æéœ€æ±‚æ–‡æ¡£ç›®å½•ï¼Œè·å–æ‰€æœ‰DOCXæ–‡ä»¶"""
        files = []
        
        try:
            if not self.requirements_docs_path.exists():
                logger.error(f"âŒ éœ€æ±‚æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {self.requirements_docs_path}")
                return files
            
            for file_path in self.requirements_docs_path.glob("*.docx"):
                if file_path.is_file() and not file_path.name.startswith('~'):  # æ’é™¤ä¸´æ—¶æ–‡ä»¶
                    files.append(file_path)
            
            logger.info(f"ğŸ“ æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(files)} ä¸ªDOCXæ–‡ä»¶")
            
            # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
            for file_path in files:
                logger.info(f"   ğŸ“„ {file_path.name}")
            
        except Exception as e:
            logger.error(f"âŒ æ‰«æéœ€æ±‚æ–‡æ¡£ç›®å½•å¤±è´¥: {e}")
        
        return files
    
    def process_all_files(self, files: List[Path]) -> List[Document]:
        """å¤„ç†æ‰€æœ‰æ–‡ä»¶"""
        all_documents = []
        
        for i, file_path in enumerate(files, 1):
            logger.info(f"ğŸ”„ å¤„ç†æ–‡ä»¶ {i}/{len(files)}: {file_path.name}")
            
            try:
                documents = self._process_docx_file(file_path)
                all_documents.extend(documents)
                
            except Exception as e:
                logger.error(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        logger.info(f"ğŸ“Š æ–‡ä»¶å¤„ç†å®Œæˆï¼Œæ€»è®¡ç”Ÿæˆ {len(all_documents)} ä¸ªæ–‡æ¡£æ®µè½")
        return all_documents
    
    def initialize_requirements_docs(self):
        """åˆå§‹åŒ–éœ€æ±‚æ–‡æ¡£å‘é‡åº“"""
        try:
            logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–éœ€æ±‚æ–‡æ¡£å‘é‡åº“...")
            
            # 1. æ¸…ç©ºç°æœ‰çš„éœ€æ±‚æ–‡æ¡£æ•°æ®
            self._clear_weaviate_database()
            
            # 2. æ‰«æéœ€æ±‚æ–‡æ¡£æ–‡ä»¶
            files = self.scan_requirements_docs()
            if not files:
                logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°DOCXæ–‡ä»¶")
                return
            
            # 3. åˆ›å»º Weaviate æ¨¡å¼
            collection_name = self._create_weaviate_schema()
            
            # 4. å¤„ç†æ–‡ä»¶
            documents = self.process_all_files(files)
            if not documents:
                logger.warning("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•æ–‡æ¡£")
                return
            
            # 5. æ‰¹é‡æ’å…¥åˆ°Weaviate
            logger.info("ğŸ“¤ å¼€å§‹æ‰¹é‡æ’å…¥æ–‡æ¡£åˆ°Weaviate...")
            batch_size = 50  # è¾ƒå°çš„æ‰¹æ¬¡å¤§å°ï¼Œç¡®ä¿ç¨³å®šæ€§
            
            for i in range(0, len(documents), batch_size):
                batch = documents[i:i + batch_size]
                try:
                    self._insert_documents_batch(batch, collection_name)
                    logger.info(f"âœ… æ‰¹æ¬¡ {i//batch_size + 1}/{(len(documents) + batch_size - 1)//batch_size} æ’å…¥æˆåŠŸ ({len(batch)} ä¸ªæ–‡æ¡£)")
                except Exception as e:
                    logger.error(f"âŒ æ‰¹æ¬¡ {i//batch_size + 1} æ’å…¥å¤±è´¥: {e}")
            
            logger.info("ğŸ‰ éœ€æ±‚æ–‡æ¡£å‘é‡åº“åˆå§‹åŒ–å®Œæˆï¼")
            
            # éªŒè¯ç»“æœ
            collection = self.weaviate_client.collections.get(collection_name)
            total_docs = collection.query.fetch_objects(limit=1).objects
            if total_docs:
                logger.info(f"ğŸ“‹ éªŒè¯ï¼šæ•°æ®åº“ä¸­ç°æœ‰æ–‡æ¡£æ•°é‡ > 0")
            
        except Exception as e:
            logger.error(f"âŒ éœ€æ±‚æ–‡æ¡£å‘é‡åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def query_test(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½"""
        try:
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_vector = self.embeddings_model.encode(query).tolist()
            
            # ä½¿ç”¨Weaviateè¿›è¡Œå‘é‡æœç´¢
            collection = self.weaviate_client.collections.get("Document")
            
            results = collection.query.near_vector(
                near_vector=query_vector,
                limit=k,
                return_metadata=["distance"]
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            for obj in results.objects:
                formatted_results.append({
                    'content': obj.properties.get('content', ''),
                    # ç§»é™¤ file_pathï¼Œä½¿ç”¨ file_name
                    'file_name': obj.properties.get('file_name', ''),
                    'title': obj.properties.get('title', ''),
                    'similarity_score': 1 - obj.metadata.distance,
                    'distance': obj.metadata.distance
                })
            
            return formatted_results
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")
            return []
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.weaviate_client:
            self.weaviate_client.close()

def main():
    """ä¸»å‡½æ•°"""
    initializer = None
    
    try:
        # åˆ›å»ºåˆå§‹åŒ–å™¨
        initializer = RequirementsDocsInitializer()
        
        # åˆå§‹åŒ–éœ€æ±‚æ–‡æ¡£å‘é‡åº“
        initializer.initialize_requirements_docs()
        
        # æµ‹è¯•æŸ¥è¯¢
        print("\nğŸ” æµ‹è¯•æŸ¥è¯¢...")
        test_queries = [
            "éœ€æ±‚èƒŒæ™¯",
            "ç³»ç»Ÿæ¶æ„",
            "æ¥å£è®¾è®¡",
            "ç”¨æˆ·æƒé™"
        ]
        
        for query in test_queries:
            print(f"\næŸ¥è¯¢: {query}")
            results = initializer.query_test(query, k=3)
            for i, result in enumerate(results, 1):
                # æ›´æ–°ä¸ºä½¿ç”¨ file_name è€Œä¸æ˜¯ file_path
                print(f"{i}. æ–‡ä»¶: {result['file_name']}")
                print(f"   æ ‡é¢˜: {result['title']}")
                print(f"   ç›¸ä¼¼åº¦: {result['similarity_score']:.3f}")
                print(f"   å†…å®¹é¢„è§ˆ: {result['content'][:100]}...")
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        if initializer:
            initializer.close()

if __name__ == "__main__":
    main()